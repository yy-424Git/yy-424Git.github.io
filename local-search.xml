<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>手把手教你使用ChatGPT写论文；如何使用ChatGPT写论文？</title>
    <link href="/how-to-write-dissertation.html"/>
    <url>/how-to-write-dissertation.html</url>
    
    <content type="html"><![CDATA[<h1 id="手把手教你使用ChatGPT写论文；如何使用ChatGPT写论文？"><a href="#手把手教你使用ChatGPT写论文；如何使用ChatGPT写论文？" class="headerlink" title="手把手教你使用ChatGPT写论文；如何使用ChatGPT写论文？"></a>手把手教你使用ChatGPT写论文；如何使用ChatGPT写论文？</h1><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>在写作论文过程中，使用人工智能工具如ChatGPT可以提供有效的辅助，但需注意AI工具并不能完全取代我们的思考能力。本指南将详细介绍使用ChatGPT进行论文写作的全流程。<br>还没有注册ChatGPT的可以参考这篇文章：<a href="https://anyubenyu.com/chatgpt-update-guide.html">国内升级ChatGPT-Plus教程，订阅GTP4.0（2024年3月更新）</a></p><h2 id="使用ChatGPT写论文的步骤"><a href="#使用ChatGPT写论文的步骤" class="headerlink" title="使用ChatGPT写论文的步骤"></a>使用ChatGPT写论文的步骤</h2><p>注意如果是理工科，推荐使用ChatGPT4.0，更专业</p><ol><li><p><strong>论文主题选择</strong></p><ul><li>登录ChatGPT并打开交互窗口。</li><li>输入相关信息，例如专业、论文类型等，请求ChatGPT提供论文选题建议。</li></ul><p> <img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403232108887.png" alt="image-20240323210803795"></p><p> <img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403232117017.png" alt="image-20240323211715947"> </p></li><li><p><strong>生成论文摘要</strong></p><ul><li>请求ChatGPT生成论文摘要，指定摘要字数和内容要点。</li></ul><p> <img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403232119467.png" alt="image-20240323211909408"></p></li><li><p><strong>生成论文大纲</strong></p><ul><li>根据生成的摘要，查询相关文献并让ChatGPT生成论文大纲。</li></ul><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403232121688.png" alt="image-20240323212117635"></p><p> <em>备注：也可让ChatGPT生成多个大纲供选择。</em></p></li><li><p><strong>逐一生成论文内容</strong></p><ul><li>让ChatGPT根据大纲逐一生成论文内容，并添加必要的限制。</li></ul><p> <img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403232122227.png" alt="image-20240323212225172"></p><p> <em>备注：重复此步骤直至论文所有部分内容生成完毕。</em></p></li><li><p><strong>论文内容排版</strong></p><ul><li>将生成的内容逐一复制到文本编辑器中，并进行排版。</li></ul></li></ol><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ul><li>ChatGPT虽然功能强大，但在使用过程中需注意审慎，AI生成的内容可能不符合人类文明的属性，需逐一检查修改。</li><li>文献部分无法由ChatGPT自动生成，需要人工查询和补充。</li></ul><hr><p>原文链接：<a href="https://anyubenyu.com/how-to-write-dissertation.html">手把手教你使用ChatGPT写论文；如何使用ChatGPT写论文？</a></p>]]></content>
    
    
    <categories>
      
      <category>ChatGPT</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>一文了解AI长文本工具：Kimi Chat；与ChatGPT比较对比</title>
    <link href="/kimi-wiki.html"/>
    <url>/kimi-wiki.html</url>
    
    <content type="html"><![CDATA[<h2 id="一文了解AI长文本工具：Kimi-Chat；与ChatGPT比较对比"><a href="#一文了解AI长文本工具：Kimi-Chat；与ChatGPT比较对比" class="headerlink" title="一文了解AI长文本工具：Kimi Chat；与ChatGPT比较对比"></a>一文了解AI长文本工具：Kimi Chat；与ChatGPT比较对比</h2><p>在人工智能领域，ChatGPT、Claude2.1和Kimi Chat都是备受关注的大型模型。它们在文本生成、理解和处理方面展现了强大的能力。本文将深入探讨这三个工具的核心功能、优劣势以及适用场景，帮助读者更好地了解它们并选择最适合自己需求的工具。</p><p>有想使用ChatGPT4.0的可以参考这篇文章：<a href="https://anyubenyu.com/chatgpt-update-guide.html">国内升级ChatGPT-Plus教程，订阅GTP4.0（2024年3月更新） </a></p><h3 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h3><ul><li><a href="#kimi%E6%A0%B8%E5%BF%83%E5%8A%9F%E8%83%BD">Kimi核心功能</a><ul><li><a href="#%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86">文件处理</a></li><li><a href="#%E7%BD%91%E9%A1%B5%E9%98%85%E8%AF%BB">网页阅读</a></li><li><a href="#%E4%BF%A1%E6%81%AF%E6%90%9C%E7%B4%A2">信息搜索</a></li></ul></li><li><a href="#kimi%E4%B8%8Egpt%E7%9A%84%E6%AF%94%E8%BE%83">Kimi与GPT的比较</a><ul><li><a href="#kimi">Kimi</a></li><li><a href="#gpt-4">GPT-4</a></li></ul></li><li><a href="#%E4%B8%89%E4%B8%AA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BC%98%E5%8A%A3">三个大模型的优劣</a><ul><li><a href="#kimi-1">Kimi</a></li><li><a href="#gpt-35">GPT-3.5</a></li><li><a href="#gpt-4-1">GPT-4</a></li></ul></li><li><a href="#%E6%80%BB%E7%BB%93">总结</a></li></ul><hr><p>近期，国产AI模型Kimi频频出现在人们的视野中，各行业大佬都在赞扬它。但是在国产AI模型繁荣的背景下，很少有能够与之匹敌的。今天我们就来探讨一下Kimi与GPT在哪些方面表现出色。</p><h2 id="Kimi核心功能"><a href="#Kimi核心功能" class="headerlink" title="Kimi核心功能"></a>Kimi核心功能</h2><h3 id="文件处理"><a href="#文件处理" class="headerlink" title="文件处理"></a>文件处理</h3><p>根据Kimi Chat官方介绍，它最多支持20万字的上下文输入，这意味着可以轻松处理包括PDF小说、书籍等在内的文档。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403181932393.png" alt="Kimi文件处理"></p><h3 id="网页阅读"><a href="#网页阅读" class="headerlink" title="网页阅读"></a>网页阅读</h3><p>我曾用Kimi阅读过一篇公众号文章，仅用了10多秒就将文章总结得头头是道。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403181932326.png" alt="Kimi网页阅读"></p><h3 id="信息搜索"><a href="#信息搜索" class="headerlink" title="信息搜索"></a>信息搜索</h3><p>Kimi还擅长搜索资料，并能够将搜索结果整合为更全面的回答。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403181932059.png" alt="Kimi信息搜索"></p><h2 id="Kimi与GPT的比较"><a href="#Kimi与GPT的比较" class="headerlink" title="Kimi与GPT的比较"></a>Kimi与GPT的比较</h2><h3 id="Kimi"><a href="#Kimi" class="headerlink" title="Kimi"></a>Kimi</h3><p>Kimi结合了GPT系列模型的文本处理能力，并增加了文件解析和网页内容提取的功能。</p><h3 id="GPT-4"><a href="#GPT-4" class="headerlink" title="GPT-4"></a>GPT-4</h3><p>GPT-4是OpenAI推出的最新一代语言模型，它在处理复杂问题和创造性任务方面表现出更高的能力。</p><h2 id="三个大模型的优劣"><a href="#三个大模型的优劣" class="headerlink" title="三个大模型的优劣"></a>三个大模型的优劣</h2><h3 id="Kimi-1"><a href="#Kimi-1" class="headerlink" title="Kimi"></a>Kimi</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ol><li>文件和网页解析功能。</li><li>搜索能力。</li><li>多语言对话能力。</li></ol><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ol><li>通用性相对有限。</li><li>适应性较弱。</li><li>知识更新频率较低。</li></ol><h3 id="GPT-3-5"><a href="#GPT-3-5" class="headerlink" title="GPT-3.5"></a>GPT-3.5</h3><h4 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h4><ol><li>广泛的知识覆盖。</li><li>强大的语言理解能力。</li><li>多样的应用场景。</li></ol><h4 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h4><ol><li>信息时效性有限。</li><li>可能出现误解和错误。</li><li>资源消耗较大。</li></ol><h3 id="GPT-4-1"><a href="#GPT-4-1" class="headerlink" title="GPT-4"></a>GPT-4</h3><h4 id="优点-2"><a href="#优点-2" class="headerlink" title="优点"></a>优点</h4><ol><li>更先进的算法。</li><li>更广泛的知识和理解。</li><li>更好的上下文理解。</li><li>丰富的插件。</li></ol><h4 id="缺点-2"><a href="#缺点-2" class="headerlink" title="缺点"></a>缺点</h4><ol><li>信息更新限制。</li><li>潜在的偏见问题。</li><li>复杂性和资源需求较高。</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Kimi、GPT-3.5和GPT-4在不同方面都有各自的优势和劣势。用户应根据自己的需求选择最合适的工具。</p><p>作为先进的语言模型，GPT-3.5和GPT-4.0在文本创作和理解方面展现了卓越的能力。然而，它们在实时信息获取和文件处理方面存在一定的局限性。但GPT-4.0，可以通过强大的插件库来增强其功能。相比之下，Kimi其专业知识的深度和广度可能不及GPT-4.0。</p><p>原文链接：<a href="https://anyubenyu.com/kimi-wiki.html">一文了解AI长文本工具：Kimi Chat；与ChatGPT比较对比</a></p>]]></content>
    
    
    <categories>
      
      <category>ChatGPT资讯</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>马斯克打脸OpenAI，全球最大巨无霸模型Grok-1开源！</title>
    <link href="/grok-wiki.html"/>
    <url>/grok-wiki.html</url>
    
    <content type="html"><![CDATA[<h2 id="一文了解AI长文本工具：马斯克打脸OpenAI，全球最大巨无霸模型Grok-1开源！"><a href="#一文了解AI长文本工具：马斯克打脸OpenAI，全球最大巨无霸模型Grok-1开源！" class="headerlink" title="一文了解AI长文本工具：马斯克打脸OpenAI，全球最大巨无霸模型Grok-1开源！"></a>一文了解AI长文本工具：马斯克打脸OpenAI，全球最大巨无霸模型Grok-1开源！</h2><p><strong>介绍</strong></p><p>近日，xAI的Grok按时开源了！这一动作不仅让马斯克成功地反击了OpenAI，还展现了其在AI领域的强大实力。Grok-1拥有3140亿参数和8个MoE，其权重和架构已完全开放，并已在GitHub上获得了超过6k颗星。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403181926800.png" alt="image-20240318192619555"></p><p><strong>Grok-1的特点</strong></p><p>Grok-1是迄今为止参数最多的开源LLM，其参数量是Llama 2的4倍。虽然xAI对Grok-1的详细信息尚未透露，但官网公布的一些信息包括：</p><ul><li>基础模型在大量文本数据上训练，未进行任何特定任务的微调。</li><li>拥有314B参数的MoE，其中25%的权重处于激活状态。</li><li>在2023年10月，xAI使用JAX和Rust构建了自定义训练堆栈。</li></ul><p>Grok一经在GitHub上发布，便迅速获得了6k颗星，同时被Fork了586次。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403181929390.png" alt="image-20240318192914291"></p><h3 id="马斯克的嘲讽和反应"><a href="#马斯克的嘲讽和反应" class="headerlink" title="马斯克的嘲讽和反应"></a>马斯克的嘲讽和反应</h3><p>马斯克对OpenAI进行了一番嘲讽，称其为“CloseAI”，并在Grok开源后再次讽刺道：“告诉我们更多关于OpenAI的「open」部分…”这一行为再次凸显了他对开源的支持态度。</p><h3 id="Grok的架构和细节"><a href="#Grok的架构和细节" class="headerlink" title="Grok的架构和细节"></a>Grok的架构和细节</h3><p>通过对model.py的分析，可以了解更多关于Grok的架构信息。Grok-1拥有8个混合专家（其中2个是活跃专家），总共有860B的活跃参数。它使用旋转嵌入代替固定位置嵌入，tokenizer词汇量为131,072，嵌入大小为6144等。</p><h3 id="Grok的影响和展望"><a href="#Grok的影响和展望" class="headerlink" title="Grok的影响和展望"></a>Grok的影响和展望</h3><p>Grok的开源引发了AI社区的热烈讨论，其前向反馈层中使用的GeGLU和归一化方法等技术受到了广泛关注。即便是OpenAI的员工也表达了对Grok的浓厚兴趣。</p><h3 id="对开源的反思"><a href="#对开源的反思" class="headerlink" title="对开源的反思"></a>对开源的反思</h3><p>一些专家对于AI模型是否应该开源存在不同看法。虽然一些人担心开源会导致技术滥用，但另一些人认为开源的利大于弊。马斯克一直是开源技术的支持者，这次开源Grok也是他的一次尝试。</p><h3 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h3><p>Grok-1的开源不仅是对OpenAI的一次挑战，也为xAI在AI领域的地位和影响力增添了新的底气。未来，Grok的开源版本可能会鼓励更多的开发者和客户采用该模型，同时也将加速xAI的发展和创新。</p><p>原文链接：<a href="https://anyubenyu.com/grok-wiki.html">马斯克打脸OpenAI，全球最大巨无霸模型Grok-1开源！</a></p>]]></content>
    
    
    <categories>
      
      <category>ChatGPT资讯</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Midjourney 重大更新！深度解析「角色一致性」命令</title>
    <link href="/midjourney-consistency.html"/>
    <url>/midjourney-consistency.html</url>
    
    <content type="html"><![CDATA[<h1 id="Midjourney-重大更新！深度解析「角色一致性」命令"><a href="#Midjourney-重大更新！深度解析「角色一致性」命令" class="headerlink" title="Midjourney 重大更新！深度解析「角色一致性」命令"></a>Midjourney 重大更新！深度解析「角色一致性」命令</h1><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403171140316.jpeg" alt="Midjourney 重大更新！深度解析「角色一致性」命令"></p><p>大家期待已久的 MJ 角色一致性功能终于来啦！全新的命令“–cref”现已推出，与之前的样式参考“–sref”功能相似，但不同的是，它不是匹配参考样式，而是试图让角色与“角色参考”图像相匹配。目前，“–cref”仅适用于 niji 6 和 v6 模型。如果不知道怎么使用Midjourney可以参考这篇文章：<a href="https://anyubenyu.com/midjourney-register-guide.html">Midjourney最新注册、订阅教程（新手小白） - OpenAI-ChatGPT导航-ChatGPT账号注册、升级指南，最新资讯 </a></p><p>让我们来看看官方文档的说明：</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403171142161.png" alt="image-20240317114208082"></p><h2 id="一、基础使用方法"><a href="#一、基础使用方法" class="headerlink" title="一、基础使用方法"></a>一、基础使用方法</h2><p>只需在提示符后输入“–cref URL”，并输入角色图像的 URL 地址，然后使用“–cw”来修改参考强度。</p><p>默认强度为 100（–cw 100），包括脸部、头发和衣服。</p><p>当强度为 0（–cw 0）时，它只会关注脸部（适用于更换服装&#x2F;头发等）。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403171142415.png" alt="image-20240317114256324"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403171143296.png" alt="image-20240317114314209"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403171143949.png" alt="image-20240317114324864"></p><h2 id="二、提示词编写"><a href="#二、提示词编写" class="headerlink" title="二、提示词编写"></a>二、提示词编写</h2><p>官方指出，此功能并非针对真人&#x2F;照片设计，可能会像普通图像提示一样使其变形，但经过体验后，效果还不错，至少对亚洲人脸孔的参考表现良好。使用“–cref”处理提示有三种主要方法：</p><h3 id="1-锚定重要角色详细信息的提示"><a href="#1-锚定重要角色详细信息的提示" class="headerlink" title="1. 锚定重要角色详细信息的提示"></a>1. 锚定重要角色详细信息的提示</h3><p>可以锚定细节（姿势、表情、情感、服装、道具、场景、动作），以便能够控制它们，让“–cref”处理大部分工作，或者可以只提供角色的场景并让“–cref”完成所有工作。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403171140825.jpeg" alt="Midjourney 重大更新！深度解析「角色一致性」命令"></p><h3 id="2-允许“–cref”完成工作不干涉提示"><a href="#2-允许“–cref”完成工作不干涉提示" class="headerlink" title="2. 允许“–cref”完成工作不干涉提示"></a>2. 允许“–cref”完成工作不干涉提示</h3><p>对于关键角色，可以不做任何描述，提示不会尝试强化参考图像中的任何细节，它只是“傀儡”或“摆出”角色的姿势。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403171140678.jpeg" alt="Midjourney 重大更新！深度解析「角色一致性」命令"></p><h3 id="3-仅使用场景提示"><a href="#3-仅使用场景提示" class="headerlink" title="3. 仅使用场景提示"></a>3. 仅使用场景提示</h3><p>如果“–cref”图像已包含想要的姿势和其他细节，可以仅描述设置、周围环境、上下文或背景，MJ 将努力将角色融入场景中，但可能会出现一些不连贯的结果，因此需要使用更高的样式值（–s）重试，以便让“–cref”图像更好地融入场景。例如，使用–s 800 之后的图片明显融合得更好。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403171140254.jpeg" alt="Midjourney 重大更新！深度解析「角色一致性」命令"></p><p>“Cref”适用于 Niji 和普通 MJ 模型，并可与“–sref”结合使用。</p><p>我们可以拿刚生成的一组图，并加上“–sref”参考样式，生成的图片将保持参考角色不变，但风格会发生改变。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403171140369.jpeg" alt="Midjourney 重大更新！深度解析「角色一致性」命令"></p><h2 id="三、高级功能"><a href="#三、高级功能" class="headerlink" title="三、高级功能"></a>三、高级功能</h2><h3 id="1-在一个画布上放置多个角色"><a href="#1-在一个画布上放置多个角色" class="headerlink" title="1. 在一个画布上放置多个角色"></a>1. 在一个画布上放置多个角色</h3><p>想要在一个画面中出现多个角色，可以直接使用 pan 功能，并对提示词进行微调。例如，在已有图片上加上一个男性角色，这需要对男性角色进行描述。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403171140331.jpeg" alt="Midjourney 重大更新！深度解析「角色一致性」命令"></p><h3 id="2-使用多个-URL-来混合多张图片中的信息-字符"><a href="#2-使用多个-URL-来混合多张图片中的信息-字符" class="headerlink" title="2. 使用多个 URL 来混合多张图片中的信息&#x2F;字符"></a>2. 使用多个 URL 来混合多张图片中的信息&#x2F;字符</h3><p>可以使用多个 URL 来混合多张图片中的信息&#x2F;字符，例如“–cref URL1 URL2”（类似于多张图片或样式提示）。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403171140492.jpeg" alt="Midjourney 重大更新！深度解析「角色一致性」命令"></p><h3 id="3-与“–sref”结合使用"><a href="#3-与“–sref”结合使用" class="headerlink" title="3. 与“–sref”结合使用"></a>3. 与“–sref”结合使用</h3><p>使用多个 URL 来混合图片，也可以同时与“–sref”结合使用，效果也是很不错的。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403171140562.jpeg" alt="Midjourney 重大更新！深度解析「角色一致性」命令"></p><h3 id="4-“–cw”参数的作用"><a href="#4-“–cw”参数的作用" class="headerlink" title="4. “–cw”参数的作用"></a>4. “–cw”参数的作用</h3><p>Midjourney 能够从参考图像中识别的角色属性将与提示混合，从而创建出新的角色。</p><p>可以通过使用“–cw N”参数（cref 权重）来控制，其中 N 的值可以从 1 到 100。默认值为 100。</p><p>“–cw”参数不会改变角色参考图像的强度&#x2F;影响力。“–cw”参数的作用如下：</p><ul><li>“–cw 100”（默认值）将捕捉整个角色；</li><li>“–cw 99”到“–cw 1”之间的值将开始捕捉较少的整个角色，仅集中于参考面部；</li><li>“–cw 0”将仅捕捉面部，类似于面部替换，但你无法关闭面部的参考。</li></ul><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403171140694.jpeg" alt="Midjourney 重大更新！深度解析「角色一致性」命令"></p><h2 id="四、如何在-Web-alpha-上工作"><a href="#四、如何在-Web-alpha-上工作" class="headerlink" title="四、如何在 Web alpha 上工作"></a>四、如何在 Web alpha 上工作</h2><p>许多人已经升级到 Web 端的 alpha 版本，也就是 Midjourney 官网上可以直接出图，而不需要在 Discord 上进行操作，官方也提供了详细的操作说明。</p><p>只需将图片拖动或粘贴到 Imagine 想象栏中，它有三个图标，分别对应着图片提示、样式参考和字符参考。点击对应图标即可生效。</p><p>通过设置图标右上角的按钮，可以设置图片的尺寸、风格化参数、怪异值、chaos 值、模型等参数，回车之后即可开始生成图片。</p><p>生成的图片依然是以四张为一组，清晰地展示了样式参考和角色参考的结果。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403171140807.jpeg" alt="Midjourney 重大更新！深度解析「角色一致性」命令"></p><p>还可以对图片提示、样式参考和字符参考进行多选，通过按住 Shift 键点击图标，即可进行多选。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403171140774.jpeg" alt="Midjourney 重大更新！深度解析「角色一致性」命令"></p><h2 id="五、CREF-故障排除提示"><a href="#五、CREF-故障排除提示" class="headerlink" title="五、CREF 故障排除提示"></a>五、CREF 故障排除提示</h2><blockquote><p>我无法为角色赋予新的姿势、风格或细节。</p></blockquote><p>首先，请确保你写了一个强烈的提示来建议姿势、风格或细节。如果提示看起来很强烈，则问题可能是 cref 图像主导了提示。这可以通过使用“–cw”参数来解决。尝试使用较低的“–cw”值，例如“–cw 60”，这将稍微释放 cref 的控制，并允许提示更自由地操纵角色。</p><p>如果这种方法损害了相似性，特别是如果“–cw”必须低于 40，那么请确保你处于[Low Variation]模式并将 Remix 设置为 ON。然后对你最喜欢的图像进行变体（V），可以逐渐增加“–cw”的值，直到恢复相似性。如果此方法开始消除姿势，可以使用[Vary Region]来恢复具有较高“–cw”值的面部区域。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403171140860.jpeg" alt="Midjourney 重大更新！深度解析「角色一致性」命令"></p><p>今天的分享到这里就结束了，总的来说，新功能还是非常强大的，需要大家多多尝试，才能灵活运用到自己的工作场景中~</p><p>原文链接：<a href="https://anyubenyu.com/midjourney-consistency.html">Midjourney-重大更新！深度解析「角色一致性」命令</a></p>]]></content>
    
    
    <categories>
      
      <category>Midjourney</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【新手小白】苹果注册美区apple-id下载ChatGPT，以及绑卡教程</title>
    <link href="/appleid-register-guide.html"/>
    <url>/appleid-register-guide.html</url>
    
    <content type="html"><![CDATA[<h1 id="美区-Apple-ID-注册和绑卡教程"><a href="#美区-Apple-ID-注册和绑卡教程" class="headerlink" title="美区 Apple ID 注册和绑卡教程"></a>美区 Apple ID 注册和绑卡教程</h1><p>成功率100%</p><h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a><a href="#1-%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C" title="1. 准备工作"></a><strong>1. 准备工作</strong></h2><p>在开始之前，请确保你准备好以下条件：</p><ul><li>一个能接收短信的国内手机号</li><li>一个全新邮箱，最好是从未用于注册过Apple ID的邮箱。目前，QQ邮箱不适用，但163邮箱和Gmail是可行的选择。</li></ul><p>以下四点可以避免很多问题：</p><ol><li><p><strong>出生日期</strong>：务必设置成大于18周岁的日期，否则可能会导致部分应用由于年龄限制而无法使用。</p></li><li><p><strong>电子邮件</strong>：建议使用一个全新的、之前未曾用于注册过Apple ID的邮箱。目前QQ邮箱不可用，但163邮箱和Gmail是可行的选择。</p></li><li><p><strong>密码</strong>：在设置密码时，避免使用姓名、生日或邮箱中的信息。否则，在验证码验证步骤可能会遇到问题。</p></li><li><p><strong>支付方式</strong>：如果在美国地区注册Apple ID时要求填写支付方式，可以选择“无”选项，这样避免了提供信用卡信息的烦扰。</p></li></ol><h2 id="2-注册步骤"><a href="#2-注册步骤" class="headerlink" title="2. 注册步骤"></a><a href="#2-%E6%B3%A8%E5%86%8C%E6%AD%A5%E9%AA%A4" title="2. 注册步骤"></a><strong>2. 注册步骤</strong></h2><p>注册方法全程都可以在手机中操作，也可以使用电脑操作。</p><h2 id="2-1-创建-Apple-ID"><a href="#2-1-创建-Apple-ID" class="headerlink" title="2.1 创建 Apple ID"></a><a href="#2-1-%E5%88%9B%E5%BB%BA-Apple-ID" title="2.1 创建 Apple ID"></a>2.1 创建 Apple ID</h2><p>首先进入美国 Apple ID 注册页面，复制 <a href="https://appleid.apple.com/account">https://appleid.apple.com/account</a> 至 Safari 浏览器中打开即可进入。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403111223203.png" alt="img"></p><h2 id="2-2-电子邮件-手机号码-进行验证"><a href="#2-2-电子邮件-手机号码-进行验证" class="headerlink" title="2.2 电子邮件+手机号码 进行验证"></a><a href="#2-2-%E7%94%B5%E5%AD%90%E9%82%AE%E4%BB%B6-%E6%89%8B%E6%9C%BA%E5%8F%B7%E7%A0%81-%E8%BF%9B%E8%A1%8C%E9%AA%8C%E8%AF%81" title="2.2 电子邮件+手机号码 进行验证"></a>2.2 <strong>电子邮件+手机号码</strong> 进行验证</h2><p>接着需要对 <strong>电子邮件+手机号码</strong> 进行双重验证。把收到的验证码输入进去，依次点击 <strong>下一步</strong> 就行了。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403111223746.png" alt="img"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403111223374.png" alt="img"></p><h2 id="2-3-修改个人信息"><a href="#2-3-修改个人信息" class="headerlink" title="2.3 修改个人信息"></a><a href="#2-3-%E4%BF%AE%E6%94%B9%E4%B8%AA%E4%BA%BA%E4%BF%A1%E6%81%AF" title="2.3 修改个人信息"></a>2.3 修改个人信息</h2><p>注册成功后，账号会自动登录，如果没登录的话重新登录一遍刚注册的账号即可。 然后点击 <strong>个人信息</strong>，接着再点击 <strong>国家或地区</strong>。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403111223997.png" alt="img"></p><h2 id="2-4-更改国家并填写-WildCard-卡片信息"><a href="#2-4-更改国家并填写-WildCard-卡片信息" class="headerlink" title="2.4 更改国家并填写 WildCard 卡片信息"></a><a href="#2-4-%E6%9B%B4%E6%94%B9%E5%9B%BD%E5%AE%B6%E5%B9%B6%E5%A1%AB%E5%86%99-WildCard-%E5%8D%A1%E7%89%87%E4%BF%A1%E6%81%AF" title="2.4 更改国家并填写 WildCard 卡片信息"></a>2.4 更改国家并填写 WildCard 卡片信息</h2><p>在添加付款方式的页面里，把国家或地区更改成 美国，付款方式按标注的提示，填写在 WildCard 官网: <a href="https://bewildcard.com/i/GPT009">https://bewildcard.com/i/GPT009</a>申请的消费卡的具体卡号，有效期，CVV和账单地址即可。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403111223943.png" alt="img"></p><p>Expiration Date （有效期） 和 CVV 在卡上的对应位置在这里：</p><p><a href="https://downloads.intercomcdn.com/i/o/872516070/58b58bde4f6843518c86e4b1/screenshot-20231101-233050.png"><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403111223818.png" alt="img"></a></p><p>美国电话是一定要填写的，这个电话不用验证，您可以随便填一个，美国电话一共10位，前3位的区号一定要对，建议您填跟账单地址同一地区的区号：</p><p>Delaware 302<br>Montana 406</p><p>Oregon 541</p><p>New Hampshire 603</p><p>后面7位可以随便填。</p><p>您也可以访问这个<a href="https://www.generatormix.com/random-phone-numbers">生成随机美国手机号的网站</a>，复制一个随机生成一个手机号，即可填写。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403111223995.png" alt="img"></p><p>点击更新 Save Changes，这个时候 apple id 已经更换到美区</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403111223662.png" alt="img"></p><h2 id="2-5-再次验证卡片信息"><a href="#2-5-再次验证卡片信息" class="headerlink" title="2.5 再次验证卡片信息"></a><a href="#2-5-%E5%86%8D%E6%AC%A1%E9%AA%8C%E8%AF%81%E5%8D%A1%E7%89%87%E4%BF%A1%E6%81%AF" title="2.5 再次验证卡片信息"></a>2.5 再次验证卡片信息</h2><p>点击 <strong>付款与配送</strong>，卡片已经添加成功，不过还需要再次验证下卡片信息，点击卡片输入CVV，点击存储更改即可</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403111223210.png" alt="img"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403111223433.png" alt="img"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403111223054.png" alt="img"></p><p>到这里我们的美区 Apple ID 就注册完成了。下面教大家如何登录。</p><h2 id="3-登录美区-ID"><a href="#3-登录美区-ID" class="headerlink" title="3. 登录美区 ID"></a><a href="#3-%E7%99%BB%E5%BD%95%E7%BE%8E%E5%8C%BA-ID" title="3. 登录美区 ID"></a><strong>3. 登录美区 ID</strong></h2><h2 id="3-1-退出原有账户"><a href="#3-1-退出原有账户" class="headerlink" title="3.1 退出原有账户"></a><a href="#3-1-%E9%80%80%E5%87%BA%E5%8E%9F%E6%9C%89%E8%B4%A6%E6%88%B7" title="3.1 退出原有账户"></a>3.1 退出原有账户</h2><p>打开 App Store，首先退出当前账号。点击右上角的头像，然后拉到末尾，点击 <strong>退出登录</strong> 即可。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403111223838.png" alt="app-store-exit1"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403111223381.png" alt="app-store-exit2"></p><h2 id="3-2-登录新账户"><a href="#3-2-登录新账户" class="headerlink" title="3.2 登录新账户"></a><a href="#3-2-%E7%99%BB%E5%BD%95%E6%96%B0%E8%B4%A6%E6%88%B7" title="3.2 登录新账户"></a>3.2 登录新账户</h2><p>接着再次点击 App Store 中右上角的头像，输入前面注册的美区账号&amp;密码，点击 <strong>登录</strong> 即可。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403111223602.png" alt="app-store-login"></p><p>点击付款方式，可以看到绑定成功的卡。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403111223932.png" alt="app-store-payment"></p><h2 id="4-下载-ChatGPT-App-并订阅-ChatGPT-Plus"><a href="#4-下载-ChatGPT-App-并订阅-ChatGPT-Plus" class="headerlink" title="4. 下载 ChatGPT App 并订阅 ChatGPT Plus"></a><a href="#4-%E4%B8%8B%E8%BD%BD-ChatGPT-App-%E5%B9%B6%E8%AE%A2%E9%98%85-ChatGPT-Plus" title="4. 下载 ChatGPT App 并订阅 ChatGPT Plus"></a><strong>4. 下载 ChatGPT App 并订阅 ChatGPT Plus</strong></h2><h2 id="4-1-下载-ChatGPT-App"><a href="#4-1-下载-ChatGPT-App" class="headerlink" title="4.1 下载 ChatGPT App"></a><a href="#4-1-%E4%B8%8B%E8%BD%BD-ChatGPT-App" title="4.1 下载 ChatGPT App"></a>4.1 <strong>下载 ChatGPT App</strong></h2><p>在 App Store 里搜索 ChatGPT 或 点击访问 <a href="https://apps.apple.com/us/app/chatgpt/id6448311069">https://apps.apple.com/us/app/chatgpt/id6448311069</a> 安装 ChatGPT App</p><h2 id="4-2-进入-Settings"><a href="#4-2-进入-Settings" class="headerlink" title="4.2 进入 Settings"></a><a href="#4-2-%E8%BF%9B%E5%85%A5-Settings" title="4.2 进入 Settings"></a><strong>4.2 进入 Settings</strong></h2><p>打开 ChatGPT App，点击左上菜单，点击 Settings 进入设置页面</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403111223668.png" alt="gpt-ios"></p><h2 id="4-3-订阅"><a href="#4-3-订阅" class="headerlink" title="4.3 订阅"></a><a href="#4-3-%E8%AE%A2%E9%98%85" title="4.3 订阅"></a>4.3 订阅</h2><p>点击 Upgrade to ChatGPT Plus，然后点击弹出的页面底部的 Subscribe 按钮，即可完成订阅。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403111223137.png" alt="gpt-ios"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403111223605.png" alt="gpt-ios"></p><h2 id="wildcard开卡地址：https-bewildcard-com-i-GPT009-官网填写邀请码，可以减免2美刀～如果没有邀请码的话，直接填写官方字段：GPT009-就行。"><a href="#wildcard开卡地址：https-bewildcard-com-i-GPT009-官网填写邀请码，可以减免2美刀～如果没有邀请码的话，直接填写官方字段：GPT009-就行。" class="headerlink" title="wildcard开卡地址：https://bewildcard.com/i/GPT009 , 官网填写邀请码，可以减免2美刀～如果没有邀请码的话，直接填写官方字段：GPT009 就行。"></a><a href="#wildcard%E5%BC%80%E5%8D%A1%E5%9C%B0%E5%9D%80%EF%BC%9Ahttps-bewildcard-com-i-GPT009-%E5%AE%98%E7%BD%91%E5%A1%AB%E5%86%99%E9%82%80%E8%AF%B7%E7%A0%81%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%87%8F%E5%85%8D2%E7%BE%8E%E5%88%80%EF%BD%9E%E5%A6%82%E6%9E%9C%E6%B2%A1%E6%9C%89%E9%82%80%E8%AF%B7%E7%A0%81%E7%9A%84%E8%AF%9D%EF%BC%8C%E7%9B%B4%E6%8E%A5%E5%A1%AB%E5%86%99%E5%AE%98%E6%96%B9%E5%AD%97%E6%AE%B5%EF%BC%9AGPT009-%E5%B0%B1%E8%A1%8C%E3%80%82" title="wildcard开卡地址：https://bewildcard.com/i/GPT009 , 官网填写邀请码，可以减免2美刀～如果没有邀请码的话，直接填写官方字段：GPT009 就行。"></a>wildcard开卡地址：<a href="https://bewildcard.com/i/GPT009">https://bewildcard.com/i/GPT009</a> , 官网填写邀请码，可以减免2美刀～如果没有邀请码的话，直接填写官方字段：<strong>GPT009</strong> 就行。</h2>]]></content>
    
    
    <categories>
      
      <category>ChatGPT</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Onlyfans目前支持哪些付费方式？Onlyfans如何订阅博主？</title>
    <link href="/onlyfans-pay-guide.html"/>
    <url>/onlyfans-pay-guide.html</url>
    
    <content type="html"><![CDATA[<h1 id="OnlyFans支付方式及内容介绍（2024年更新）"><a href="#OnlyFans支付方式及内容介绍（2024年更新）" class="headerlink" title="OnlyFans支付方式及内容介绍（2024年更新）"></a>OnlyFans支付方式及内容介绍（2024年更新）</h1><p>OnlyFans是一个总部位于英国伦敦的热门付费内容订阅平台，让内容创作者可以发布原创视频、图片等内容，并从订阅他们的粉丝那里赚取收入。近年来，它已经成为了一个方便的网赚及内容变现渠道，在受欢迎程度上甚至与一些顶流视频网站相媲美，如[P站]</p><h2 id="支持的支付方式"><a href="#支持的支付方式" class="headerlink" title="支持的支付方式"></a>支持的支付方式</h2><p>根据我的调查，截至2024年第一季度，OnlyFans支持以下主要支付方式：</p><ul><li>Visa（维萨）信用卡和借记卡</li><li>万事达（Mastercard）信用卡和借记卡</li><li>发现（Discover）信用卡和借记卡</li><li>Maestro（万事顺）借记卡</li><li>部分预付费&#x2F;预存Visa卡（prepaid visa cards）</li></ul><p>尽管PayPal在国外广受欢迎，但遗憾的是，目前OnlyFans官方尚未支持PayPal付款方式。此外，礼品卡和加密货币也不在OnlyFans支持范围内。</p><h3 id="推荐使用虚拟卡进行支付"><a href="#推荐使用虚拟卡进行支付" class="headerlink" title="推荐使用虚拟卡进行支付"></a>推荐使用虚拟卡进行支付</h3><p>你想订阅一些付费的明星，可以点击按以下步骤来</p><ol><li>注册一张虚拟信用卡：<a href="https://bewildcard.com/i/GPT009">WildCard | 一分钟开卡，轻松订阅海外软件服务</a></li></ol><p>（PS：大家可以使用上面我的邀请链接，或者邀请码：GPT009，这样你能有 88 折优惠）<br><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403122003648.png" alt="image-20240312200316575"></p><ol start="2"><li><p>添加信用卡</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403101207981.png" alt="image-20240202225058253"><br>需要的每一项信息，都可以直接在虚拟卡网页上看到，直接复制过去即可：</p></li></ol><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403101207076.png" alt="image-20240202225912838"></p><p>绑定支付信用卡后，就可以去订阅喜欢的博主啦。很方便，而且信用卡里的余额可以随时提取出来。</p><h2 id="订阅内容与特权"><a href="#订阅内容与特权" class="headerlink" title="订阅内容与特权"></a>订阅内容与特权</h2><p>付费订阅价格在OnlyFans上可以从每月4.99美元到49.99美元不等，具体价格由内容主自行确定。付费会员将获得以下特权和服务：</p><ul><li>查看频道主上传的专有内容，通常是原创个人视频或私照（部分可能有较大尺度），且未在其他平台公开。</li><li>频道主可以根据用户的特殊需求拍摄定制的视频。</li></ul><p>虽然各种内容创作者都可以利用OnlyFans，但据英文主流权威媒体报道，OnlyFans上最受欢迎的是针对成年人的多媒体内容。</p><p>原文链接：<a href="https://anyubenyu.com/onlyfans-pay-guide.html">Onlyfans目前支持哪些付费方式？Onlyfans如何订阅博主？</a></p>]]></content>
    
    
    <categories>
      
      <category>Onlyfans</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>一文教你如何解决ChatGPT消息发不出去，ChatGPT 点击无响应？ChatGPT无法使用？(Oops, an error occurred!)</title>
    <link href="/chatgpt-settle-send.html"/>
    <url>/chatgpt-settle-send.html</url>
    
    <content type="html"><![CDATA[<h2 id="一文教你如何解决ChatGPT消息发不出去，ChatGPT无法使用？-Oops-an-error-occurred"><a href="#一文教你如何解决ChatGPT消息发不出去，ChatGPT无法使用？-Oops-an-error-occurred" class="headerlink" title="一文教你如何解决ChatGPT消息发不出去，ChatGPT无法使用？(Oops, an error occurred!)"></a>一文教你如何解决ChatGPT消息发不出去，ChatGPT无法使用？(Oops, an error occurred!)</h2><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><a href="#%E5%89%8D%E8%A8%80" title="前言"></a>前言</h2><p>今天在工作的过程中，我正准备登陆ChatGPT咨询一些关于代码的问题，但突然发现自己无法发送消息了。</p><p>“ChatGPT消息发送故障，但历史对话仍可查看。为了解决问题，您可以先访问OpenAI官方网站：<a href="https://link.zhihu.com/?target=https://status.openai.com/">https://status.openai.com/</a>。 这个网站提供了Open AI系统的实时状态监控，非常方便实用。”</p><h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a><a href="#%E5%8E%9F%E5%9B%A0" title="原因"></a><strong>原因</strong></h2><p>主要原因：可能是<strong>加入了最新的多语言内测的人，也可能是其他情况。</strong></p><p>查看在登录后是否点击了顶部弹窗邀请 <strong>[加入多语言 alpha 测试]</strong> ，以及<strong>语言选择了中文。</strong></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403092237618.webp" alt="img"></p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a><a href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95" title="解决方法"></a><strong>解决方法</strong></h2><h3 id="方法一：清除网站的缓存"><a href="#方法一：清除网站的缓存" class="headerlink" title="方法一：清除网站的缓存"></a><a href="#%E6%96%B9%E6%B3%95%E4%B8%80%EF%BC%9A%E6%B8%85%E9%99%A4%E7%BD%91%E7%AB%99%E7%9A%84%E7%BC%93%E5%AD%98" title="方法一：清除网站的缓存"></a>方法一：清除网站的缓存</h3><p><strong>可以先清除网站的cookie，在chatgpt官网下，按F12，打开网页控制台，或者右键点击查看。</strong></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403092237607.webp" alt="img"></p><p><strong>在控制台窗口，点击Application（如果你用了翻译的话，就是“应用”的意思）</strong></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403092237682.webp" alt="img"></p><p><strong>然后点击cookies，把<a href="https://link.zhihu.com/?target=http://chat.openai.com">http://chat.openai.com</a>网站的cookies、session、localstorage等缓存信息清除掉。</strong></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403092237667.webp" alt="img"></p><p>之后，刷新网页，重新登陆你的ChatGPT账号。就可以解决掉这个问题了。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403092237622.webp" alt="img"></p><p>最后就可以继续使用你的chatGPT啦～</p><p>如果你要升级为GPT-4的话，可以参考这篇教程：<a href="https://anyubenyu.com/chatgpt-update-guide.html">国内升级ChatGPT-Plus教程，订阅GTP4.0（2024年3月更新）</a></p><p>或者直接用虚拟卡进行订阅升级也可以哈，简单方便：</p><p><a href="https://bewildcard.com/i/GPT009">WildCard | 一分钟注册，轻松订阅海外软件服务</a></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403092237719.png" alt="img"><strong>建议用来升级自己的账号哈，不要选择拼车的那个功能呢</strong></p><h2 id="另外两个方法："><a href="#另外两个方法：" class="headerlink" title="另外两个方法："></a><a href="#%E5%8F%A6%E5%A4%96%E4%B8%A4%E4%B8%AA%E6%96%B9%E6%B3%95%EF%BC%9A" title="另外两个方法："></a>另外两个方法：</h2><ol><li>换其他的浏览器登录使用</li><li>把中文切换到英文！</li></ol><p>原文链接：<a href="https://anyubenyu.com/chatgpt-settle-send.html">一文教你如何解决ChatGPT消息发不出去，ChatGPT 点击无响应？ChatGPT无法使用？</a></p>]]></content>
    
    
    <categories>
      
      <category>ChatGPT</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Anthropic官网提供Claude3注册及使用教程(Claude开发者官网在哪里？)</title>
    <link href="/Anthropic-register-claude3.html"/>
    <url>/Anthropic-register-claude3.html</url>
    
    <content type="html"><![CDATA[<h2 id="Claude-3注册升级教程！解决如何注册升级Cluade3的问题以及预防封号"><a href="#Claude-3注册升级教程！解决如何注册升级Cluade3的问题以及预防封号" class="headerlink" title="Claude 3注册升级教程！解决如何注册升级Cluade3的问题以及预防封号"></a>Claude 3注册升级教程！解决如何注册升级Cluade3的问题以及预防封号</h2><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><a href="#%E5%89%8D%E8%A8%80" title="前言"></a><strong>前言</strong></h2><p>OpenAI的GPT-4曾被奉为不可战胜的巅峰，然而这个神话已经被打破了。</p><p><strong>最近发布的Claude 3</strong>新模型以惊人的表现，超越了GPT-4的性能，成为首个在全面性能评估中击败GPT-4的产品。这一成就标志着新一代LLM（大型语言模型）的崭露头角，为未来的人工智能技术设立了全新的标准。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403051944070.png" alt="img"></p><p>然而，我相信许多人在注册Claude 3时都遇到了一些困难。比如，可能会碰到手机验证码无法使用的问题，因为需要使用国外手机号码，而且官方支持的国家&#x2F;地区也只有150多个。<a href="https://www.anthropic.com/claude-ai-locations">Supported countries and regions: Claude.ai</a></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403092222915.webp" alt="img"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403092222952.webp" alt="img"></p><p>经过多次实验和两次账号封禁的经历，我终于找到了解决方法。在这个过程中，我发现了三个关键要素：</p><ul><li><strong>谷歌账号</strong></li><li><strong>验证手机号</strong></li><li><strong>网络</strong></li></ul><p><strong>这三者必须统一。</strong></p><p>如果你不符合上述条件，别担心！你可以通过该平台注册一个国外虚拟卡。</p><p><a href="https://bewildcard.com/i/GPT009">WildCard | 一分钟注册，轻松订阅海外软件服务</a></p><p><strong>其优势在于：如果在升级到GPT-4后遇到问题，充值后自动退款，而且可以提现。</strong></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403092222055.png" alt="img"></p><p><strong>另外，我建议使用Wildcard平台来升级您的GPT-4。但请注意，我不推荐使用拼车功能！</strong></p><p><strong>里面有免费的三次英国的手机号码：</strong></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403092222947.webp" alt="img"></p><p><strong>也提供你需要的网络以及邮箱账号等功能：</strong></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403092222962.webp" alt="img"></p><h2 id="一-哪些地区可以使用Claude？"><a href="#一-哪些地区可以使用Claude？" class="headerlink" title="一. 哪些地区可以使用Claude？"></a><a href="#%E4%B8%80-%E5%93%AA%E4%BA%9B%E5%9C%B0%E5%8C%BA%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8Claude%EF%BC%9F" title="一. 哪些地区可以使用Claude？"></a><strong>一. 哪些地区可以使用Claude？</strong></h2><p>Opus 和 Sonnet 目前已集成到 Anthropic 的 Claude.ai 和 Claude API 中，覆盖了 159 个国家&#x2F;地区。Haiku 将很快推出。此外，Sonnet 也可以通过亚马逊云科技的 Bedrock 服务以及谷歌云 Vertex AI Model Garden 的私人预览渠道获得，而 Opus 和 Haiku 也将在不久后登陆这两个平台。</p><h2 id="二、Claude3目前的优势和特点"><a href="#二、Claude3目前的优势和特点" class="headerlink" title="二、Claude3目前的优势和特点"></a><a href="#%E4%BA%8C%E3%80%81Claude3%E7%9B%AE%E5%89%8D%E7%9A%84%E4%BC%98%E5%8A%BF%E5%92%8C%E7%89%B9%E7%82%B9" title="二、Claude3目前的优势和特点"></a><strong>二、Claude3目前的优势和特点</strong></h2><ol><li><p>多样化模型选择：包括Claude 3 Haiku、Claude 3 Sonnet和Claude 3 Opus三款模型，针对不同的性能需求和成本效益，让您有更多选择。</p></li><li><p>行业领先性能：Opus模型在多个AI系统评估基准上超越同行，包括专家知识、专家推理和基础数学等领域，为您提供行业领先的性能。</p></li><li><p>增强的多语言能力：所有Claude 3模型在非英语语言（如西班牙语、日语和法语）的对话中表现出色，为全球用户提供更好的体验。</p></li><li><p>快速响应能力：Haiku模型处理信息密集型研究论文时速度极快，而Sonnet模型在大多数工作负载中的速度是前代模型的两倍，让您能更高效地完成任务。</p></li><li><p>强大的视觉处理能力：Claude 3模型能够处理各种视觉格式，包括照片、图表、图形和技术图示，使您能够更好地理解和处理视觉信息。</p></li><li><p>减少不必要的拒绝：新模型在理解上下文和处理提示词方面更加细致，减少了不必要的拒绝，提升了交互体验。</p></li><li><p>提高准确性：Opus模型在处理复杂、开放式问题时，正确答案的比例提高了两倍，错误答案减少，帮助您更精准地解决问题。</p></li><li><p>长上下文和近乎完美的回忆：Claude 3模型能够处理长达200K的上下文窗口，并且能够准确回忆大量数据中的信息，助您更深入地探索和理解内容。</p></li><li><p>负责任的设计：模型开发考虑了安全性和透明度，包括减少偏见、保护隐私和遵守负责任扩展政策，确保您的使用更加安全可靠。</p></li><li><p>易于使用：Claude 3模型更擅长遵循复杂指令，适应品牌声音和响应指南，以及生成结构化输出，让您能更轻松地实现自己的目标。</p></li><li><p>模型可用性：Opus和Sonnet模型现已通过API提供，Haiku模型即将推出。Sonnet模型支持claude.ai的免费体验，Opus模型为Claude Pro订阅者提供，让您更便捷地获取所需模型。</p></li><li><p>持续更新和功能增强：Anthropic计划在未来几个月内频繁更新Claude 3模型家族，并推出新功能，如工具使用、交互式编码和更高级的代理能力，为您提供更多可能性。</p></li><li><p>安全防护措施：随着AI能力的扩展，Anthropic致力于确保安全防护措施与性能提升同步，以引导AI发展朝着积极的社会结果，保障您的数据和隐私安全。</p></li></ol><h2 id="三、Claude3注册教程"><a href="#三、Claude3注册教程" class="headerlink" title="三、Claude3注册教程"></a><a href="#%E4%B8%89%E3%80%81Claude3%E6%B3%A8%E5%86%8C%E6%95%99%E7%A8%8B" title="三、Claude3注册教程"></a><strong>三、Claude3注册教程</strong></h2><h3 id="步骤1：获取Wildcard海外手机号"><a href="#步骤1：获取Wildcard海外手机号" class="headerlink" title="步骤1：获取Wildcard海外手机号"></a><a href="#%E6%AD%A5%E9%AA%A41%EF%BC%9A%E8%8E%B7%E5%8F%96Wildcard%E6%B5%B7%E5%A4%96%E6%89%8B%E6%9C%BA%E5%8F%B7" title="步骤1：获取Wildcard海外手机号"></a><strong>步骤1：获取Wildcard海外手机号</strong></h3><ol><li>点击注册教程链接访问：<a href="https://bewildcard.com/i/GPT009">wildcard使用教程？如何用wildcard订阅国外服务？</a></li><li>根据教程提示注册账户</li><li>进入网站，点击我的服务-&gt;下滑找到右下角海外手机号-&gt;点击使用-&gt;申请后就可以接码了（最下图是已经申请成功的界面）</li></ol><p><img src="https://pic2.zhimg.com/80/v2-1bf1ef2d9b99c561fcceb2a10a185815_720w.webp" alt="img"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403092222914.webp" alt="img"></p><ol><li>每个账号有三次免费申请的机会，而且网站说<strong>即使你用了虚拟手机号，可能会有失败的</strong>。不过你可以多试1～2次，我差不多是第2次才成功注册的。</li></ol><h3 id="步骤2：使用获取的手机号注册Claude3"><a href="#步骤2：使用获取的手机号注册Claude3" class="headerlink" title="步骤2：使用获取的手机号注册Claude3"></a><a href="#%E6%AD%A5%E9%AA%A42%EF%BC%9A%E4%BD%BF%E7%94%A8%E8%8E%B7%E5%8F%96%E7%9A%84%E6%89%8B%E6%9C%BA%E5%8F%B7%E6%B3%A8%E5%86%8CClaude3" title="步骤2：使用获取的手机号注册Claude3"></a><strong>步骤2：使用获取的手机号注册Claude3</strong></h3><ol><li>打开Claude3注册（<a href="https://www.anthropic.com/claude">Claude \ Anthropic</a>）页面，先填写邮箱等信息。</li></ol><p><img src="https://pic2.zhimg.com/80/v2-163c3cb06ef5149f6aa9b759f785b039_720w.webp" alt="img"></p><ol><li>然后填入你从Wildcard获得的海外手机号。</li><li>点击发送验证码。</li></ol><h3 id="步骤3：接收并输入验证码"><a href="#步骤3：接收并输入验证码" class="headerlink" title="步骤3：接收并输入验证码"></a><a href="#%E6%AD%A5%E9%AA%A43%EF%BC%9A%E6%8E%A5%E6%94%B6%E5%B9%B6%E8%BE%93%E5%85%A5%E9%AA%8C%E8%AF%81%E7%A0%81" title="步骤3：接收并输入验证码"></a><strong>步骤3：接收并输入验证码</strong></h3><ol><li>回到你的Wildcard的界面。</li><li>检查你的虚拟手机号收件箱，查看来自Claude3的验证码。</li><li>最后将验证码输入到Claude3的注册页面中，完成验证。</li></ol><p>Wildcard的平台地址：<a href="https://bewildcard.com/i/GPT009">https://bewildcard.com/i/GPT009</a> 。</p><p><strong>（PS：这个虚拟卡还可以升级订阅GPT-4～）</strong></p><p>原文链接：<a href="https://anyubenyu.com/Anthropic-register-claude3.html">Anthropic官网提供Claude3注册及使用教程(Claude开发者官网在哪里？)</a></p>]]></content>
    
    
    <categories>
      
      <category>Claude</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>如何解决Claude账号被封，及Claude3使用方法</title>
    <link href="/settle-claude3-banned.html"/>
    <url>/settle-claude3-banned.html</url>
    
    <content type="html"><![CDATA[<h1 id="Claude账户被封：常见问题和解决方案"><a href="#Claude账户被封：常见问题和解决方案" class="headerlink" title="Claude账户被封：常见问题和解决方案"></a>Claude账户被封：常见问题和解决方案</h1><p>在当今数字化时代，人工智能技术的不断发展已经改变了我们的生活方式和工作方式。最近Claude 3的出现，给我们带来了前所未有的智能和效率。然而，随着技术的进步，也伴随着一些挑战，比如Claude账号被封的问题。在本文中，我们将探讨为什么会出现这种情况以及如何解决和预防这一问题，帮助用户更好地利用人工智能技术。</p><p>关于Claude的注册可以参考这篇文章：<a href="https://anyubenyu.com/how-to-register-claude3.html">Claude注册教程</a></p><h2 id="为什么Claude账户会被封？"><a href="#为什么Claude账户会被封？" class="headerlink" title="为什么Claude账户会被封？"></a>为什么Claude账户会被封？</h2><p>Claude账户可能被封禁的主要原因有两种：</p><h3 id="工作区人数过多导致账户崩溃"><a href="#工作区人数过多导致账户崩溃" class="headerlink" title="工作区人数过多导致账户崩溃"></a>工作区人数过多导致账户崩溃</h3><ul><li>服务器负载过重可能导致账户崩溃。</li><li>解决方法包括卸载不必要的应用、清理缓存或申请增加服务器容量。</li></ul><h3 id="地区受限导致账户被停用"><a href="#地区受限导致账户被停用" class="headerlink" title="地区受限导致账户被停用"></a>地区受限导致账户被停用</h3><ul><li>某些地区限制可能导致账户被停用。</li><li>解决方法包括使用VPN切换地区或联系官方客服进行申诉。</li></ul><h2 id="如何解决Claude账户被封问题？"><a href="#如何解决Claude账户被封问题？" class="headerlink" title="如何解决Claude账户被封问题？"></a>如何解决Claude账户被封问题？</h2><p>解决Claude账户被封问题的方法主要包括以下两种：</p><h3 id="重新添加Claude应用"><a href="#重新添加Claude应用" class="headerlink" title="重新添加Claude应用"></a>重新添加Claude应用</h3><p>重新添加应用可能是解封常见方法之一，确保登录信息正确，以避免再次封禁。</p><h3 id="切换IP并通过邮箱登录"><a href="#切换IP并通过邮箱登录" class="headerlink" title="切换IP并通过邮箱登录"></a>切换IP并通过邮箱登录</h3><p>切换至支持的地区IP，并通过邮箱登录验证账户，有助于绕过地区限制解封。</p><h2 id="如何预防Claude账户被封？"><a href="#如何预防Claude账户被封？" class="headerlink" title="如何预防Claude账户被封？"></a>如何预防Claude账户被封？</h2><p>为了预防账户被封，用户可以采取以下预防措施：</p><h3 id="遵守使用规定和条款"><a href="#遵守使用规定和条款" class="headerlink" title="遵守使用规定和条款"></a>遵守使用规定和条款</h3><ul><li>严格遵守使用规定，避免违规行为。</li><li>定期了解使用条款的更新内容。</li></ul><h3 id="及时更新应用版本和系统信息"><a href="#及时更新应用版本和系统信息" class="headerlink" title="及时更新应用版本和系统信息"></a>及时更新应用版本和系统信息</h3><ul><li>保持Claude应用和系统更新，提升系统稳定性。</li><li>定期检查并下载最新版本的应用和系统。</li></ul><h2 id="常见问题解答"><a href="#常见问题解答" class="headerlink" title="常见问题解答"></a>常见问题解答</h2><h3 id="问题：Claude账户被封了怎么办？有什么解封方法？"><a href="#问题：Claude账户被封了怎么办？有什么解封方法？" class="headerlink" title="问题：Claude账户被封了怎么办？有什么解封方法？"></a>问题：Claude账户被封了怎么办？有什么解封方法？</h3><p><strong>解答：</strong> 当发现Claude账户被封时，可尝试以下解封方法：</p><ul><li>尝试重新添加Claude应用到工作区。</li><li>确认是否违反了使用规定或地区限制，需严格遵守平台规则。</li><li>若IP地址受限，尝试切换至美国或英国的IP，然后通过邮箱登录Claude解封。</li></ul><h3 id="问题：为何Claude账户会被封禁？有哪些常见原因？"><a href="#问题：为何Claude账户会被封禁？有哪些常见原因？" class="headerlink" title="问题：为何Claude账户会被封禁？有哪些常见原因？"></a>问题：为何Claude账户会被封禁？有哪些常见原因？</h3><p><strong>解答：</strong> 导致Claude账户被封禁的原因可能包括：</p><ul><li>违反应用规定或地区限制，务必遵守相关规则。</li><li>工作区人数过多导致崩溃，需合理控制工作区人数。</li><li>存在违规行为，如滥用应用功能等。</li></ul><h3 id="问题：如何解封Claude账户？有哪些有效的方法？"><a href="#问题：如何解封Claude账户？有哪些有效的方法？" class="headerlink" title="问题：如何解封Claude账户？有哪些有效的方法？"></a>问题：如何解封Claude账户？有哪些有效的方法？</h3><p><strong>解答：</strong> 若需要解封Claude账户，可尝试以下方法：</p><ul><li>申诉与联系开发团队，说明情况并请求解封服务。</li><li>更换IP地址并通过邮箱重新登录，可能有助于解封。</li><li>重新添加应用并详细说明遵守规定，争取解封。</li></ul><p><strong>（PS：这个虚拟卡还可以升级订阅GPT-4～）</strong></p><p>原文链接：<a href="https://anyubenyu.com/settle-claude3-banned.html">如何解决Claude账号被封，及Claude3使用方法</a></p>]]></content>
    
    
    <categories>
      
      <category>Claude</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【新手小白】Claude3注册教程，解决Claude手机号验证问题</title>
    <link href="/how-to-register-claude3.html"/>
    <url>/how-to-register-claude3.html</url>
    
    <content type="html"><![CDATA[<h2 id="【新手小白】Claude3注册教程，解决Claude手机号验证问题"><a href="#【新手小白】Claude3注册教程，解决Claude手机号验证问题" class="headerlink" title="【新手小白】Claude3注册教程，解决Claude手机号验证问题"></a>【新手小白】Claude3注册教程，解决Claude手机号验证问题</h2><p>Anthropic今日宣布推出其最新大型语言模型（LLM）系列——Claude 3，这一系列模型在各种认知任务上树立了新的性能标准。Claude 3系列包括三个子模型：Claude 3 Haiku、Claude 3 Sonnet和Claude 3 Opus，每个模型都提供了不同程度的智能、速度和成本选择，旨在满足广泛的人工智能应用需求。</p><p>在尝试注册Claude3时，许多用户报告遇到了一个常见的障碍——无法接收到手机验证码。这个问题尤其困扰那些没有海外手机号的用户。幸运的是，有一种解决方案可以帮助你顺利完成注册过程。本文将详细介绍如何利用Wildcard服务提供的海外手机号进行Claude3注册。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403061832417.png" alt="image-20240305134902463"></p><h2 id="1-哪些地区可以使用Claude？"><a href="#1-哪些地区可以使用Claude？" class="headerlink" title="1. 哪些地区可以使用Claude？"></a>1. 哪些地区可以使用Claude？</h2><p>Opus和Sonnet目前已集成到Anthropic的Claude.ai和Claude API中，覆盖了159个国家&#x2F;地区。Haiku即将推出，为用户带来更丰富的选择。此外，Sonnet还可以通过亚马逊云科技的Bedrock服务以及谷歌云Vertex AI Model Garden的私人预览渠道获取，而Opus和Haiku也将很快登陆这两个平台。随着这些模型的逐步推出和完善，用户将享受到更多优质的人工智能服务。</p><h2 id="2-什么是Wildcard？"><a href="#2-什么是Wildcard？" class="headerlink" title="2. 什么是Wildcard？"></a>2. 什么是Wildcard？</h2><p>Wildcard是一个专门为AIGC（例如chatgpt、midjourney、claude等）提供虚拟信用卡和手机号服务的平台，支持多个国家和地区的手机号。这些虚拟手机号可用于接收短信验证码，非常适合需要验证国外手机号以注册Claude的场合。如果您在寻找便捷的方式来完成注册流程，Wildcard绝对是您的最佳选择！</p><h2 id="3-注册Claude3教程"><a href="#3-注册Claude3教程" class="headerlink" title="3. 注册Claude3教程"></a>3. 注册Claude3教程</h2><h3 id="步骤1：获取Wildcard海外手机号"><a href="#步骤1：获取Wildcard海外手机号" class="headerlink" title="步骤1：获取Wildcard海外手机号"></a>步骤1：获取Wildcard海外手机号</h3><ol><li>访问<a href="https://bewildcard.com/i/GPT009">Wildcard官方网站</a>（从链接进入可以优惠两美元）。</li><li>根据网站指示注册账户。</li><li>进入网站，找到海外手机号菜单栏，点击“立即申请”。（下图是已经申请成功的界面）<img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403061832312.png" alt="image-20240305134221255"></li><li>每个账号有三次免费申请的机会，而且网站说即使你用了手机号，也可能会失败。我是到了第四次才成功注册的。</li></ol><h3 id="步骤2：使用获取的手机号注册Claude3"><a href="#步骤2：使用获取的手机号注册Claude3" class="headerlink" title="步骤2：使用获取的手机号注册Claude3"></a>步骤2：使用获取的手机号注册Claude3</h3><ol><li>打开Claude3注册页面，先填写邮箱等信息。</li><li>然后填入你从Wildcard获得的海外手机号。</li><li>点击发送验证码。</li></ol><h3 id="步骤3：接收并输入验证码"><a href="#步骤3：接收并输入验证码" class="headerlink" title="步骤3：接收并输入验证码"></a>步骤3：接收并输入验证码</h3><ol><li>返回到Wildcard的界面。</li><li>检查你的虚拟手机号收件箱，找到来自Claude3的短信验证码。</li><li>将验证码输入到Claude3的注册页面中，完成验证。</li></ol><h2 id="4-结论"><a href="#4-结论" class="headerlink" title="4. 结论"></a>4. 结论</h2><p>Claude 3 系列的推出，标志着 Anthropic 在大型语言模型领域取得的重大突破，其在智能水平、处理速度和多样化应用方面的表现，预示着人工智能技术的一个新的发展方向。随着 Claude 3 系列模型的进一步应用和优化，我们有理由相信，人工智能的未来将更加多元和智能。</p><p>使用Wildcard提供的海外手机号注册Claude3是解决无法发送手机验证码问题的有效方法。通过遵循上述步骤，你可以轻松完成Claude3的注册过程，享受其提供的服务。</p><p><strong>（PS：这个虚拟卡还可以升级订阅GPT-4～）</strong></p><p>原文链接：<a href="https://anyubenyu.com/how-to-register-claude3.html">【新手小白】Claude3注册教程，解决Claude手机号验证问题</a></p>]]></content>
    
    
    <categories>
      
      <category>Claude</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Claude3震撼发布！超越GPT4？附最新使用教程（新手小白）</title>
    <link href="/claude3-register-guide.html"/>
    <url>/claude3-register-guide.html</url>
    
    <content type="html"><![CDATA[<h1 id="Claude3深夜震撼发布！模型特点分析，附使用教程"><a href="#Claude3深夜震撼发布！模型特点分析，附使用教程" class="headerlink" title="Claude3深夜震撼发布！模型特点分析，附使用教程"></a>Claude3深夜震撼发布！模型特点分析，附使用教程</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>最新发布的Claude3引起了广泛关注，这次发布一举推出了三个不同类型的模型，分别是Claude 3 Haiku、Claude 3 Sonnet和Claude 3 Opus。每个模型都具有独特的特点和能力，满足了不同用户群体的需求。本文将深入分析这三个模型的特点，并提供详细的使用教程。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403051941975.png" alt="image-20240305194133842"></p><h2 id="模型特点分析"><a href="#模型特点分析" class="headerlink" title="模型特点分析"></a>模型特点分析</h2><h3 id="1-图像识别能力"><a href="#1-图像识别能力" class="headerlink" title="1. 图像识别能力"></a>1. 图像识别能力</h3><p>虽然以往的模型如GPT-4也具备图像识别的能力，但是Claude3在这方面表现突出。通过评测和官方演示视频可以发现，Claude3在图像识别方面表现优异，尤其擅长捕捉细节。特别是在“Science Diagrams”等方面，Claude3 Opus的表现甚至超越了GPT-4V。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403051942620.png" alt="image-20240305194201507"></p><p>在官方的示例中，Claude3甚至能够通过学习网络工具来理解并预测未来的GDP趋势，展现了其强大的图像识别能力。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403051942380.png" alt="image-20240305194247263"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403051943476.png" alt="image-20240305194332311"></p><h3 id="2-响应速度非常快"><a href="#2-响应速度非常快" class="headerlink" title="2. 响应速度非常快"></a>2. 响应速度非常快</h3><p>Claude3的响应速度也非常快，Haiku模型可以在三秒内读取一篇带有图片的arxiv论文（10k token）。相比之前的版本，Claude3的速度提升了两倍以上。</p><h3 id="3-超大上下文窗口"><a href="#3-超大上下文窗口" class="headerlink" title="3. 超大上下文窗口"></a>3. 超大上下文窗口</h3><p>Claude3提供了超过20万个上下文的窗口，三个模型都能够接受100万个输入。这为用户提供了更广泛的语境，使得模型更加全面理解用户输入。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403051943352.png" alt="image-20240305194354229"></p><h3 id="4-全面超越GPT-4的能力"><a href="#4-全面超越GPT-4的能力" class="headerlink" title="4. 全面超越GPT-4的能力"></a>4. 全面超越GPT-4的能力</h3><p>官方提供的评测数据显示，Claude3在编码、推理、数学、多语言和文本理解等方面全面超越了GPT-4。特别是在数学问题和推理能力方面表现突出。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403051944070.png" alt="image-20240305194417985"></p><h2 id="使用教程"><a href="#使用教程" class="headerlink" title="使用教程"></a>使用教程</h2><p>目前Opus和Sonnet模型已经在官网上线，用户可以前往Anthropic网站进行使用。然而，与GPT Plus类似，Opus模型需要付费，费用为20美元&#x2F;月。</p><p>由于Claude3的升级与OpenAI相似，暂时不支持国内用户使用信用卡支付。建议用户可以尝试使用国内的虚拟银行卡WildCard进行支付。<a href="https://bewildcard.com/i/GPT009">WildCard一键注册</a></p><p>特点：</p><ul><li>支付安全：支持支付宝和银联支付。</li><li>服务全面：支持onlyfans、chatgpt、midjourney等多种服务充值。</li><li>响应快速：右下角人工客服快速响应，客服回复及时。</li><li>网络优化：最近推出了专门用于访问OpenAI的浏览器。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Claude3的发布引起了广泛关注，其强大的图像识别能力、快速的响应速度和超大的上下文窗口使其在自然语言处理领域独具竞争优势。通过本文的分析和使用教程，希望读者能够更好地了解和使用Claude3模型，为其研究和应用带来更多可能性。</p><p><strong>（PS：这个虚拟卡还可以升级订阅GPT-4～）</strong></p><p>原文链接：<a href="https://anyubenyu.com/claude3-register-guide.html">Claude3震撼发布！超越GPT4？附最新使用教程（新手小白）</a></p>]]></content>
    
    
    <categories>
      
      <category>ChatGPT资讯</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Claude3正式发布！超越GPT4?</title>
    <link href="/claude3-sub.html"/>
    <url>/claude3-sub.html</url>
    
    <content type="html"><![CDATA[<h1 id="Claude3正式发布"><a href="#Claude3正式发布" class="headerlink" title="Claude3正式发布"></a>Claude3正式发布</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p><strong>OpenAI创始人奥特曼都还没来得及和马斯克掰扯完新仇旧恨，没关系，还有其他人会悄悄出手——</strong></p><p><strong>瞩目时刻：Anthropic悄然发布最新一代大模型Claude 3！</strong></p><p><strong>就在北京时间3月4日晚间，Anthropic以惊人的姿态，不打预防针，直接释放了备受期待的Claude 3，距离上一代的Claude 2发布仅仅相隔短短8个月！</strong></p><p><strong>Anthropic，OpenAI的劲敌，核心团队由OpenAI的创始人组成，于2021年分家创立。这股强大的竞争力在业内引起了巨大的轰动。</strong></p><p>PS:如需使用ChatGPT可以参考这篇文章：<a href="https://anyubenyu.com/chatgpt-update-guide.html">ChatGPT订阅、升级最新教程</a><br><strong>仅在2023年，Anthropic就获得了五轮融资，总额高达73亿美元！这不仅是资金的胜利，更是对其在大模型训练领域的无与伦比的认可。</strong></p><p><strong>本次发布的Claude 3，堪称业界标杆！直面OpenAI的GPT-4，不仅拥有多模态能力，更是以超过46页的技术报告华丽登场，自信地宣称：</strong></p><blockquote><p>全面超越GPT-4！</p></blockquote><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403051034092.jpeg"></p><p>△来源：Claude来源：</p><p>新一代的Claude 3分为三个版本，分别为Haiku、Sonnet、Opus三款模型。从模型尺寸来看，可以理解为模型的中杯、大杯、超大杯。</p><p>虽然Anthropic并没有给出模型的具体参数，不过给出了三款模型所适用的场景：</p><ul><li>Haiku：是相应速度最快的模型，也是成本最低的选项，在大多数纯文本任务上的表现仍然相当出色，也同时包含多模态能力（比如视觉）</li><li>Sonnet：适用于需要平衡性能和成本的场景，它在纯文本任务上的表现与后面的Opus相当，但在成本上更为经济，适合于那些需要性能稍微好点，但预算有限的企业和个人用户</li><li>Opus：具有强大的推理、数学和编码能力，接近人类的理解能力，适用于需要高度智能和复杂任务处理的场景，如企业自动化、复杂金融预测、研究和开发等。</li></ul><p>从本周开始，Claude会向159个国家开放。其中，Opus和Sonnet模型的API均已上线，开发者已经可以直接使用。经济性能兼顾的Sonnet，Opus则可供Claude Pro订阅者使用。</p><p>尽管OpenAI凭借Sora在文生视频领域打了一场漂亮的翻身仗，但视频赛道所在的发展阶段更早。如今的主战场仍在大语言模型（LLM）上，离产品化也更近。</p><p>圈内人也看热闹不嫌事大。近期不少报道显示，马斯克将OpenAI告上法庭，让OpenAI不得不内部推迟有关GPT-5的发布——GPT-5被认为能够实现AGI（通用人工智能）。著名AI圈网红、英伟达的首席AI科学家Jim Fan就表示：</p><blockquote><p>Claude 3刚刚发布了，坐等几个小时后OpenAI精心安排的GPT-5发布。</p></blockquote><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403051034128.jpeg"></p><p>△来源：Twitter（X）</p><p>2024年才刚刚过去两个月，我们就已经见证谷歌Gemini Pro、OpenAI的Sora，再到如今的Claude发布……巨头混战再度拉开序幕，大有愈演愈烈之势。</p><h2 id="一口气读15万单词，还能自己拆解复杂问题"><a href="#一口气读15万单词，还能自己拆解复杂问题" class="headerlink" title="一口气读15万单词，还能自己拆解复杂问题"></a>一口气读15万单词，还能自己拆解复杂问题</h2><p>如果是OpenAI是大模型领域的“六边形战士”，无论是模型视频、商业化综合水平一骑绝尘，那么Anthropic从风格上看更为低调，也更强调专才，但这次的能力提升确实巨大。</p><p>有看客甚至表示：</p><blockquote><p>Claude 3终结了GPT-4时代。</p></blockquote><p>这次Claude 3的两大更新亮点，一个是长文本，二是多模态能力。</p><p>长文本就是Anthropic的一个显著优势，体现为在读论文、小说等字数更多的文本时，Anthropic更擅长理解和回答用户的相关问题。</p><p>这次，Claude 3大大提升了上下文对话窗口，达到200k——可以理解为单次和模型对话能够输入的文本。</p><p>具体而言，Claude 3 200k的对话长度，相当于能够单次处理超过15万英文单词，而GPT-4 Turbo的上下文窗口为128k，大约是9.6万个英文单词。</p><p>并且，Claude 3也第一次允许图像和文档上传。和ChatGPT一样，Claude 3能够“认”出来图里的是什么东西，直接描述，回答用户的问题。</p><p>而更令人印象深刻的还是，Claude 3在分析一些复杂问题时，已经能够和人一样，先拆解问题，并且交由子模型来进行调度。</p><p>在Anthropic的演示视频里，就举了一个需要用python模拟经济形势走向的例子。当把“分析美国十年GDP未来趋势”的任务交给Claude 3之后，Claude就默默地做了这些事：</p><ul><li>先打开一个名为“webview”的工具，跳到这个问题相关的资料网址里</li><li>因为有多模态能力，所以能够把“看到”的信息，无论是文字还是图表，都扒拉下来，用来解决问题</li><li>然后自己写python程序、渲染趋势图，让人类看是否正确</li></ul><p>最有趣的就是，网页中如果看到一个数据图表，没有明确数据的，Claude 3甚至能通过识别图像，来估算每个阶段大概数据是多少，进行还原。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403051034114.jpeg"></p><p>△搜索引擎中的数据图表</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403051034201.jpeg"></p><p>△Claude 3还原的折线图，估算了每个时间节点的具体GDP</p><p>AI安全也是Anthropic区别于OpenAI的一点。在OpenAI和Anthropic团队分家的时候，其最重要分歧正是包含对AI安全的考虑，Anthropic希望建立一个“更可信”的模型，而OpenAI显然希望用商业化驱动模型更快地前进，路线上更为激进。</p><p>对此，Anthropic采取的措施包括但不限于：制定了一套框架，用于评估和减轻 AI 模型可能带来的潜在灾难性风险，比如继续拧自动化评估和红队测试，以确保AI不会发展出可能造成伤害的能力。</p><p>2023年4月，Anthropic甚至开源宪法人工智能（Constitutional AI）引起了圈内轰动，这是一个限制模型行为遵守特定宪法原则的AI。</p><p>以及2024年也是美国大选年， Anthropic 也在准备开发和执行关于在政治和选举背景下使用工具的政策，评估模型对选举错误信息、偏见和其他滥用的反应，确保用户能够在选定国家获得准确和最新的投票信息。</p><p>不过，Anthropic也因为太过重视AI安全，很多问题的评估上很谨慎，甚至直接不回答，惹来一片用户吐槽。这次，Anthropic表示，Claude 3在这个问题上大有改进。</p><p>比如，Claude 3的对无害信息的拒绝回复率，普遍来到了10%附近，比Claude2.1和2.0都有进步。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403051034166.jpeg"></p><p>△来源：Anthropic</p><p>据CNBC，Anthropic拒绝透露训练 Claude 3 到底花了多少时间和多少钱，但表示 Airtable 和 Asana 等知名SaaS公司有帮忙对模型进行了A&#x2F;B测试，让模型的可控性也有所改善。</p><h2 id="技术风暴后，商业舞台将如何演绎？Anthropic迎战商业挑战！"><a href="#技术风暴后，商业舞台将如何演绎？Anthropic迎战商业挑战！" class="headerlink" title="技术风暴后，商业舞台将如何演绎？Anthropic迎战商业挑战！"></a>技术风暴后，商业舞台将如何演绎？Anthropic迎战商业挑战！</h2><p>尽管Anthropic再次展示了其技术实力，但大模型领域已经经历了一年多的激烈竞争。如何将技术转化为实际产品，创造更大的商业价值，已成为所有公司共同面临的挑战。</p><p>如今，Anthropic背后得到了谷歌云和亚马逊的支持，形成了与OpenAI（背靠微软）鲜明的对比。然而，从商业化的角度来看，Anthropic目前仍远远落后于OpenAI，这意味着在2024年，Anthropic将面临更大的竞争压力。</p><p>与ChatGPT类似，Anthropic也在To B和To C市场上双管齐下。在企业端，Anthropic已经为Slack、Notion和Quora等用户提供了服务。</p><p>根据The Information在2023年12月的报道，Anthropic预计到2024年底将实现超过8.5亿美元的年收入。相比之下，同期OpenAI由于ChatGPT的强劲增长，年收入从10月中旬的13亿美元增至16亿美元。</p><p>展望未来，随着OpenAI商业化步伐的加快，这种差距可能会进一步拉大。The Information援引了一些OpenAI领导者的观点，他们预计到2024年底，OpenAI的年收入将达到50亿美元，而其他人则认为可能会更高。</p><p>技术上的军备竞赛尚未结束。截至2023年12月，Anthropic正在进行一轮高达7.5亿美元的融资，估值为184亿美元，较2023年初的41亿美元增长了4.5倍。</p><p><strong>（PS：这个虚拟卡还可以升级订阅GPT-4～）</strong></p><p>原文链接：<a href="https://anyubenyu.com/claude3-sub.html">Claude3正式发布！超越GPT4？</a></p>]]></content>
    
    
    <categories>
      
      <category>ChatGPT资讯</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>英伟达CEO黄仁勋预测：人工智能五年内将成为现实？可通过人类任何测试！</title>
    <link href="/huangrenxun-predict.html"/>
    <url>/huangrenxun-predict.html</url>
    
    <content type="html"><![CDATA[<h1 id="英伟达CEO黄仁勋预测通用人工智能五年内成为现实"><a href="#英伟达CEO黄仁勋预测通用人工智能五年内成为现实" class="headerlink" title="英伟达CEO黄仁勋预测通用人工智能五年内成为现实"></a>英伟达CEO黄仁勋预测通用人工智能五年内成为现实</h1><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h2><p>黄仁勋在2024年斯坦福经济政策研究所峰会上提出了通用人工智能（AGI）可能在未来五年内成为现实的预测。</p><h2 id="2-黄仁勋的观点"><a href="#2-黄仁勋的观点" class="headerlink" title="2. 黄仁勋的观点"></a>2. 黄仁勋的观点</h2><ul><li>AGI的实现取决于如何定义”通过人类测试”的标准。</li><li>随着时间推移，AI技术将逐渐通过越来越多的测试，最终达到通过”任何一项测试”的水平。</li></ul><h2 id="3-挑战与展望"><a href="#3-挑战与展望" class="headerlink" title="3. 挑战与展望"></a>3. 挑战与展望</h2><ul><li>科学界对人类思维工作方式的描述存在分歧，为AI设定清晰、一致的学习目标变得复杂。</li><li>让AI达到完全模拟人类工程师的复杂任务处理能力仍然是一个巨大挑战。</li></ul><h2 id="4-基础设施需求"><a href="#4-基础设施需求" class="headerlink" title="4. 基础设施需求"></a>4. 基础设施需求</h2><ul><li>支持AI产业扩张需要晶圆厂等基础设施建设。</li><li>随着对AI技术的需求增加，市场对芯片的需求也在增长，但随着技术改进，这种需求增长将会得到有效管理。</li></ul><h2 id="5-OpenAI回应马斯克起诉"><a href="#5-OpenAI回应马斯克起诉" class="headerlink" title="5. OpenAI回应马斯克起诉"></a>5. OpenAI回应马斯克起诉</h2><p>据报道，OpenAI 在发给公司员工的内部信中提到，公司”坚决不同意”马斯克提起的诉讼。OpenAI 首席战略官杰森·权认为，马斯克的做法“可能源于他后悔如今无法参与到 OpenAI 运营中来”。</p><p>日前，马斯克最近向旧金山高级法院提交了诉讼，他在起诉书中认为，OpenAI 与微软的合作已经损害了该公司最初对开源通用人工智能（AGI）的承诺。</p><p>如想使用ChatGPT可以参考这篇文章：<a href="https://anyubenyu.com/chatgpt-update-guide.html">ChatGPT订阅、升级指南</a></p><h2 id="6-结语"><a href="#6-结语" class="headerlink" title="6. 结语"></a>6. 结语</h2><p>黄仁勋的预测引发了科技界的广泛讨论，对AI技术的未来发展提出了挑战和展望。</p><p>原文链接：<a href="https://anyubenyu.com/huangrenxun-predict.html">英伟达CEO黄仁勋预测：人工智能五年内将成为现实？可通过人类任何测试！</a></p>]]></content>
    
    
    <categories>
      
      <category>ChatGPT资讯</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>起诉OpenAI，马斯克急了</title>
    <link href="/musk-sue-openai.html"/>
    <url>/musk-sue-openai.html</url>
    
    <content type="html"><![CDATA[<h1 id="马斯克起诉OpenAI要求其开源"><a href="#马斯克起诉OpenAI要求其开源" class="headerlink" title="马斯克起诉OpenAI要求其开源"></a>马斯克起诉OpenAI要求其开源</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>近日，马斯克将OpenAI及CEO山姆·奥特曼告上法庭，引发了科技圈的热议。这一纠纷将OpenAI的使命聚焦在了”非营利性”和”开源”两个关键词上。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403041203502.png" alt="image-20240304120232036"></p><h2 id="纠纷始末"><a href="#纠纷始末" class="headerlink" title="纠纷始末"></a>纠纷始末</h2><p>马斯克提出46页的诉讼文件，指控OpenAI违反了其初衷，背离了非营利性和公共开源人工通用智能(AGI)的使命。他声称OpenAI将GPT-4秘密化，与微软建立了独家合作关系，成为商业利益的帮凶。</p><p>如果想使用ChatGPT参考这篇文章：<a href="https://anyubenyu.com/chatgpt-update-guide.html">ChatGPT订阅、升级指南</a></p><h2 id="马斯克的指控和诉求"><a href="#马斯克的指控和诉求" class="headerlink" title="马斯克的指控和诉求"></a>马斯克的指控和诉求</h2><p>马斯克声称与奥特曼及布罗克曼共同创立OpenAI时，是出于对AI潜在风险的共同关注，承诺确保AI技术能够惠及全人类。但随着OpenAI在AI领域的领先地位日益巩固，公司方向发生了根本性转变，背离了非营利性质。</p><p>马斯克的诉讼要求法院强制OpenAI回归开源，并阻止公司及其创始人从中获利。</p><h2 id="分析与展望"><a href="#分析与展望" class="headerlink" title="分析与展望"></a>分析与展望</h2><p>此次纠纷将OpenAI的使命和道德准则置于舆论的风口浪尖。若马斯克胜诉，对OpenAI将带来严重打击，可能导致其无法在行业中持续发展。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>当前，马斯克、OpenAI及微软等尚未对此作出回应。然而，这起诉讼将深刻影响OpenAI未来的发展方向和行业地位。</p><p>原文链接：<a href="https://anyubenyu.com/musk-sue-openai.html">起诉OpenAI，马斯克急了</a></p>]]></content>
    
    
    <categories>
      
      <category>ChatGPT资讯</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>ChatGPT打不开？一文搞定(最新)</title>
    <link href="/chatgpt-open-failure.html"/>
    <url>/chatgpt-open-failure.html</url>
    
    <content type="html"><![CDATA[<h1 id="ChatGPT网络问题解决方案指南"><a href="#ChatGPT网络问题解决方案指南" class="headerlink" title="ChatGPT网络问题解决方案指南"></a>ChatGPT网络问题解决方案指南</h1><h2 id="一-前言"><a href="#一-前言" class="headerlink" title="一.前言"></a>一.前言</h2><p>要使用ChatGPT，首先需要登录官方网站或官方应用程序。官方网址为 <a href="https://chat.openai.com/">https://chat.openai.com</a>。网络节点选择方面，推荐使用美国、加拿大、欧洲地区，而不推荐使用香港、澳门、俄罗斯的节点。</p><h2 id="二-关于梯子"><a href="#二-关于梯子" class="headerlink" title="二.关于梯子"></a>二.关于梯子</h2><h3 id="2-1-常见问题及解决方法："><a href="#2-1-常见问题及解决方法：" class="headerlink" title="2.1 常见问题及解决方法："></a>2.1 常见问题及解决方法：</h3><ol><li><p><strong>地区选择问题：</strong> 加速器所选地区不正确，建议选择美国、加拿大、欧洲地区的节点。</p></li><li><p><strong>加速器不支持问题：</strong> 部分加速器可能不支持ChatGPT的线路，需确保所选加速器支持。</p></li><li><p><strong>手机使用建议：</strong> 在手机上使用时，应选择全局模式，且可以使用浏览器访问官网或者通过官方APP登录。</p></li></ol><h3 id="2-2-常见网络问题包括："><a href="#2-2-常见网络问题包括：" class="headerlink" title="2.2 常见网络问题包括："></a>2.2 常见网络问题包括：</h3><ul><li>网页加载异常</li><li>登录问题</li><li>对话过程中出现错误</li></ul><h2 id="三-问题目录"><a href="#三-问题目录" class="headerlink" title="三.问题目录"></a>三.问题目录</h2><h3 id="3-1-打开ChatGPT提示-“Unable-to-load-site”"><a href="#3-1-打开ChatGPT提示-“Unable-to-load-site”" class="headerlink" title="3.1 打开ChatGPT提示 “Unable to load site”"></a>3.1 打开ChatGPT提示 “Unable to load site”</h3><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403011453699.png" alt="image-20240301145332536"></p><p>原因是：当前用的科学上网的节点不行。换到其他地区的节点（上面已经说过）</p><h3 id="3-2-网页提示-“Oops！We-ran-into-an-issue-while-authenticating-you-”"><a href="#3-2-网页提示-“Oops！We-ran-into-an-issue-while-authenticating-you-”" class="headerlink" title="3.2 网页提示 “Oops！We ran into an issue while authenticating you.”"></a>3.2 网页提示 “Oops！We ran into an issue while authenticating you.”</h3><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403011454487.png" alt="image-20240301145409421"></p><p>也是网络节点问题。 请继续更换其他节点。直到正常！！</p><h3 id="3-3-使用提示-“Something-went-wrong”"><a href="#3-3-使用提示-“Something-went-wrong”" class="headerlink" title="3.3 使用提示 “Something went wrong”"></a>3.3 使用提示 “Something went wrong”</h3><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403011455306.png" alt="image-20240301145543242"></p><p>同样是梯子问题。</p><h3 id="3-4-打开ChatGPT-APP提示-“ChatGPT-is-not-available-in-your-region-”"><a href="#3-4-打开ChatGPT-APP提示-“ChatGPT-is-not-available-in-your-region-”" class="headerlink" title="3.4 打开ChatGPT APP提示 “ChatGPT is not available in your region.”"></a>3.4 打开ChatGPT APP提示 “ChatGPT is not available in your region.”</h3><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403011457497.png" alt="image-20240301145719449"></p><p>如图所示，ChatGPT is not available in your region. 即 <strong>ChatGPT 不支持你所在的国家</strong>。</p><h2 id="四-加速器服务商指南"><a href="#四-加速器服务商指南" class="headerlink" title="四.加速器服务商指南"></a>四.加速器服务商指南</h2><p>如果仍然无法解决问题，可以尝试以下加速器产品：</p><ol><li><strong>「Wildcard」</strong><ul><li>官网注册：<a href="https://bewildcard.com/i/GPT009">WildCard | 一分钟开卡，轻松订阅海外软件服务</a></li><li>这是一个虚拟卡平台，不光可以提供加速服务，同时可以进行各种境外支付，包括ChatGPT-PLUS，Midjourney，Onlyfans等等</li></ul></li></ol><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403011501052.png" alt="image-20240301150138998"></p><p>原文链接：<a href="https://anyubenyu.com/chatgpt-open-failure.html">ChatGPT打不开？一文搞定(最新)</a></p>]]></content>
    
    
    <categories>
      
      <category>ChatGPT</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>ChatGPT Plus有询问次数限制吗？如何无限使用</title>
    <link href="/chatgpt-limit.html"/>
    <url>/chatgpt-limit.html</url>
    
    <content type="html"><![CDATA[<h1 id="ChatGPT-Plus订阅用户对GPT-4使用次数限制的失望"><a href="#ChatGPT-Plus订阅用户对GPT-4使用次数限制的失望" class="headerlink" title="ChatGPT Plus订阅用户对GPT-4使用次数限制的失望"></a>ChatGPT Plus订阅用户对GPT-4使用次数限制的失望</h1><p>ChatGPT Plus订阅用户对GPT-4的使用次数限制引起了广泛关注和讨论。用户反映他们无法充分利用GPT-4来完成工作，特别是那些重度使用和依赖该服务的用户。在此限制下，每3小时只能使用40次，这对于一些用户来说是不够的。</p><h2 id="限制次数的调整历程"><a href="#限制次数的调整历程" class="headerlink" title="限制次数的调整历程"></a>限制次数的调整历程</h2><p>在2023年6月，GPT-4首次推出时，用户在网页版使用该模型时每3小时仅能提问25次。然而，该限制被广大用户认为不足以满足他们的需求。随后，OpenAI在7月份开始放宽限制，将使用次数提高到每3小时50次。然而，这种限制只持续了数月，到11月时OpenAI再次调整，将使用次数降为每3小时40次。这使得用户在进行持续工作或研究时需要更加合理地安排他们的使用次数。</p><h2 id="限制带来的影响"><a href="#限制带来的影响" class="headerlink" title="限制带来的影响"></a>限制带来的影响</h2><p>ChatGPT Plus订阅用户面临着使用次数的限制，这对于那些频繁使用GPT-4模型的用户来说是个挑战。特别是对于那些依靠该模型进行持续工作或研究的用户来说，每3小时40次的限制无法满足他们高效率的需求。用户反馈称，他们无法完成足够多的任务，这让他们感到沮丧和失望。</p><h2 id="用户期望的解决方案"><a href="#用户期望的解决方案" class="headerlink" title="用户期望的解决方案"></a>用户期望的解决方案</h2><p>对于ChatGPT Plus订阅用户来说，他们希望OpenAI能够进一步放宽限制或提供更多的选择。一种可能的解决方案是将每3小时的使用次数增加到一个更高的数字，或者提供其他付费选项，让用户可以根据自己的需求进行定制。</p><h1 id="限制对工作需求的影响"><a href="#限制对工作需求的影响" class="headerlink" title="限制对工作需求的影响"></a>限制对工作需求的影响</h1><p>ChatGPT Plus会员订阅用户发现，每3小时仅限40次使用次数的限制使他们无法充分利用GPT-4来回答问题、进行对话等。这限制了他们在工作中使用GPT Plus的效率。此外，这个限制还对工作时效性产生了不利影响。在处理紧急工作时，用户可能会遇到时间不足的困扰，无法及时完成任务。</p><h1 id="GPT-4使用次数的变化"><a href="#GPT-4使用次数的变化" class="headerlink" title="GPT-4使用次数的变化"></a>GPT-4使用次数的变化</h1><p>从2023年3月16日起，OpenAI发布了GPT-4给PLUS会员体验，虽然有使用限制，但这个限制是动态变化的。然而，随着时间的推移，GPT-4的使用次数限制发生了多次变化。</p><h2 id="初始设定"><a href="#初始设定" class="headerlink" title="初始设定"></a>初始设定</h2><p>最初，订阅会员每4小时可以提问100次。然而，不久后，这一限制被缩减为每4小时50次。</p><h2 id="现行限制"><a href="#现行限制" class="headerlink" title="现行限制"></a>现行限制</h2><p>目前，订阅用户在3小时内仅能提问25次，这对于希望更频繁地使用GPT-4的用户来说是一个不利因素。然而，在2023年7月27日，OpenAI放宽了ChatGPT Plus对GPT-4模型的使用限制，将每3小时的使用量增加到了50次。</p><p>2024年1月20日的报道显示，ChatGPT Plus订阅用户每3小时只能使用40次。而目前网页版每3小时最多只能提问25次。这一变化引起了广泛的关注和讨论，因为这意味着ChatGPT Plus用户需要更加精明地利用他们的会话次数。</p><h1 id="用户反应与疑问"><a href="#用户反应与疑问" class="headerlink" title="用户反应与疑问"></a>用户反应与疑问</h1><p>用户对ChatGPT Plus的使用次数限制更新引起了广泛关注。他们注意到使用上限从每3小时50次降低到了40次，这让他们开始质疑ChatGPT Plus的价值和订阅优势。</p><h2 id="用户的不满与疑问："><a href="#用户的不满与疑问：" class="headerlink" title="用户的不满与疑问："></a>用户的不满与疑问：</h2><ul><li>一些用户认为40次的使用上限不足以完成他们的工作，因此无法充分利用ChatGPT Plus。</li><li>他们开始怀疑订阅ChatGPT Plus是否还有价值，因为使用次数限制被降低了。</li><li>用户希望得到更多的解释和理由，以理解为什么会有使用次数的限制以及为什么要降低使用上限。</li></ul><h1 id="GPT-4-3小时40次的常见问答Q-A"><a href="#GPT-4-3小时40次的常见问答Q-A" class="headerlink" title="GPT-4 3小时40次的常见问答Q&amp;A"></a>GPT-4 3小时40次的常见问答Q&amp;A</h1><h2 id="问题1：GPT-4和ChatGPT-Plus之间有什么区别？"><a href="#问题1：GPT-4和ChatGPT-Plus之间有什么区别？" class="headerlink" title="问题1：GPT-4和ChatGPT Plus之间有什么区别？"></a>问题1：GPT-4和ChatGPT Plus之间有什么区别？</h2><p>答案：GPT-4是OpenAI开发的下一代语言模型，而ChatGPT Plus是一个基于GPT-4模型的付费订阅服务。他们之间的区别如下：</p><ul><li>GPT-4是模型本身，它是一个强大的通用语言模型，能够生成人类类似的文本。</li><li>ChatGPT Plus是一种订阅服务，用户可以通过付费获得更多的对话次数和更高质量的文本生成。</li><li>ChatGPT Plus的使用次数限制为每3小时40次，这意味着用户可以在每3小时内与模型进行40次对话。</li><li>GPT-4和ChatGPT Plus的表现可能存在差异，因为ChatGPT Plus针对会员用户进行了优化和训练，以提供更好的体验。</li></ul><h2 id="问题2：GPT"><a href="#问题2：GPT" class="headerlink" title="问题2：GPT"></a>问题2：GPT</h2><p>-4每3小时25次回答指的是什么？</p><p>答案：GPT-4每3小时25次回答是指在ChatGPT Plus的订阅中，用户每3小时只能与GPT-4模型进行25次对话的限制。</p><p>这意味着用户在每3小时内最多可以问25个问题，而一旦达到这个限制，用户在剩余的时间内将无法与模型进行对话。</p><p>这个限制是为了平衡系统的资源和用户体验。尽管用户可能觉得每3小时25次是不够的，但OpenAI根据资源和性能限制做出了这样的决定。</p><h2 id="问题3：如何突破GPT-4每3小时25次回答的限制？"><a href="#问题3：如何突破GPT-4每3小时25次回答的限制？" class="headerlink" title="问题3：如何突破GPT-4每3小时25次回答的限制？"></a>问题3：如何突破GPT-4每3小时25次回答的限制？</h2><p>答案：目前，突破GPT-4每3小时25次回答限制的方法有以下几种：</p><ul><li>升级到ChatGPT Plus 4.0版本：付费订阅ChatGPT Plus的最新版本可以突破限制，提供更多的对话次数和更好的体验。</li><li>在移动版或iOS版使用GPT-4：据报道，移动版或iOS版的ChatGPT Plus没有限制每3小时25次回答的限制，可以无限制地与GPT-4进行对话。</li></ul><p>通过以上方法，用户可以在使用ChatGPT Plus服务时突破每3小时25次回答限制，获得更多的灵活性和更高效的对话体验。</p><h2 id="问题4：如何免费使用GPT-4？"><a href="#问题4：如何免费使用GPT-4？" class="headerlink" title="问题4：如何免费使用GPT-4？"></a>问题4：如何免费使用GPT-4？</h2><p>答案：以下是免费使用GPT-4的几种方法：</p><ul><li>免费版的Forefront：Forefront提供了每3小时5次的免费GPT-4对话，用户可以全天24小时使用总共40次免费的GPT-4。</li><li>试用Free ChatGPT KEY：一些网站可能提供免费的ChatGPT KEY试用，用户可以通过申请获得一定时间的免费GPT-4对话服务。</li></ul><p>通过以上方法，用户可以以免费的方式体验和使用GPT-4模型，来满足一定的对话需求。</p><p>如果想拥有一个ChatGPT-PLUS长久使用4.0参考这篇文章：<a href="https://anyubenyu.com/chatgpt-update-guide.html">ChatGPT订阅、注册、升级新手小白最新教程</a></p><p>原文链接：<a href="https://anyubenyu.com/chatgpt-limit.html"> ChatGPT Plus有询问次数限制吗？如何无限使用</a></p>]]></content>
    
    
    <categories>
      
      <category>ChatGPT</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Onlyfans年龄认证怎么办？附最新订阅教程（新手小白）</title>
    <link href="/onlyfans-age-ver.html"/>
    <url>/onlyfans-age-ver.html</url>
    
    <content type="html"><![CDATA[<h2 id="Onlyfans年龄认证怎么办？"><a href="#Onlyfans年龄认证怎么办？" class="headerlink" title="## Onlyfans年龄认证怎么办？"></a>## Onlyfans年龄认证怎么办？</h2><h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a><strong>1. 概述</strong></h2><ul><li><strong>OnlyFans简介</strong>：OnlyFans，自2016年起，作为一种内容订阅服务平台，让内容创作者能通过用户订阅的方式获得收入。这个平台在多个领域如音乐、健身、摄影及成人内容等都十分受欢迎。</li></ul><p>本指南旨在解释如何在OnlyFans平台上完成年龄验证，这是一个用户面临的常见问题。</p><h2 id="2-年龄验证的必要性"><a href="#2-年龄验证的必要性" class="headerlink" title="2. 年龄验证的必要性"></a><strong>2. 年龄验证的必要性</strong></h2><p>OnlyFans实行年龄验证主要是为了符合法律规定，防止未成年人接触不适宜的内容。由于平台内容多样，法定年龄的用户才被允许访问，以确保遵守网络内容和未成年人保护的相关法律。年龄验证是OnlyFans保护未成年人的措施之一，同时也体现了该平台对用户自由与社会责任的平衡。</p><h2 id="3-OnlyFans的年龄验证机制"><a href="#3-OnlyFans的年龄验证机制" class="headerlink" title="3. OnlyFans的年龄验证机制"></a><strong>3. OnlyFans的年龄验证机制</strong></h2><p>OnlyFans在用户注册时仅要求提供邮箱，而未直接询问年龄。用户在设置中也无法直接设定年龄。因此，OnlyFans依赖第三方服务来完成年龄验证。</p><h2 id="4-通过年龄验证的方法"><a href="#4-通过年龄验证的方法" class="headerlink" title="4. 通过年龄验证的方法"></a><strong>4. 通过年龄验证的方法</strong></h2><p>以下是一些通过OnlyFans年龄验证的常用方法：</p><ul><li><p><strong>4.1 使用虚拟Visa卡注册</strong></p><p> 由于信用卡信息可用于年龄验证，因此更换信用卡信息也是一种方式。推荐使用<a href="https://bewildcard.com/i/GPT007">wildcard</a>，通过该链接注册可享受开卡优惠。</p><p> 详细操作请参考：<a href="https://anyubenyu.com/onlyfans-sub.html">Onlyfans 注册以及充值、虚拟信用卡订阅教程</a></p></li><li><p><strong>4.2 调整邮箱中的生日信息</strong></p><p> 修改邮箱账户中的生日信息，确保显示为成年人的出生日期。例如，下图是Google邮箱的设置界面，其他邮箱的操作也类似。</p><p> <img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402242236036.png" alt="邮箱设置示例"></p></li><li><p><strong>4.3 切换IP地址</strong></p><p> 有用户发现，切换IP地址有时也能帮助通过年龄验证，尽管其具体原理尚不明确。</p></li></ul><h2 id="5-结论"><a href="#5-结论" class="headerlink" title="5. 结论"></a><strong>5. 结论</strong></h2><p>总的来说，通过OnlyFans的年龄验证可以通过以下几种方法：使用虚拟信用卡注册、调整邮箱中的生日信息，以及在需要时切换IP地址。这些方法可以帮助用户有效地满足OnlyFans的年龄验证要求。</p><p>完成年龄验证后，用户便可以开始享受订阅服务。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402242236058.png" alt="订阅示意图"></p><p>原文链接：<a href="https://anyubenyu.com/onlyfans-age-ver.html">Onlyfans年龄认证指南</a></p><hr>]]></content>
    
    
    <categories>
      
      <category>Onlyfans</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【新手小白】Sora如何申请？Sora使用教程（最新）</title>
    <link href="/only-way-to-use-sora.html"/>
    <url>/only-way-to-use-sora.html</url>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li><a href="#1-%E8%99%9A%E5%81%87%E7%9A%84sora%E4%BD%BF%E7%94%A8%E6%B8%A0%E9%81%93">1. 虚假的Sora使用渠道</a></li><li><a href="#2-%E7%9C%9F%E5%AE%9E%E7%9A%84sora%E4%BD%BF%E7%94%A8%E6%B8%A0%E9%81%93">2. 真实的Sora使用渠道</a></li><li><a href="#4-openai-red-teaming-network%E7%9A%84%E7%9B%AE%E7%9A%84%E6%98%AF%E4%BB%80%E4%B9%88">4. OpenAI Red Teaming Network的目的是什么</a></li><li><a href="#5-%E5%A6%82%E4%BD%95%E5%8A%A0%E5%85%A5openai-red-teaming-network">5. 如何加入OpenAI Red Teaming Network</a></li><li><a href="#6-openai-red-teaming-network%E7%94%B3%E8%AF%B7%E9%9A%BE%E5%BA%A6">6. OpenAI Red Teaming Network申请难度</a></li><li><a href="#7-%E6%80%BB%E7%BB%93">7. 总结</a></li></ul><p>近日，OpenAI发布的Sora模型引发了广泛关注，成为行业内外热议的焦点。这一模型不仅在专业领域引起了极大兴趣，还激发了普通群众对于人工通用智能（AGI）的热情。</p><p>随着Sora模型的爆红，越来越多的人开始关注一个问题：我们何时能开始使用Sora？</p><p>在OpenAI的官方论坛上，关于这个问题的讨论异常激烈。有关如何使用Sora的话题阅读量已接近70,000，显示出人们对此充满期待。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402212023864.png" alt="image-20240221202304796"></p><p>实际上，针对大家关心的这个问题，OpenAI已经给出了官方回应：目前<strong>普通公众</strong>还无法使用Sora。这里特别指出的是“普通公众”，那么，是否存在通过官方渠道使用Sora的途径呢？</p><p>答案出乎意料——确实存在这样的机会！</p><p>今天，我要向大家揭秘的就是这一机会——那就是OpenAI的“Red Teaming Network”！</p><h2 id="1-虚假的Sora使用渠道"><a href="#1-虚假的Sora使用渠道" class="headerlink" title="1. 虚假的Sora使用渠道"></a>1. 虚假的Sora使用渠道</h2><p>在深入探讨OpenAI的“Red Teaming Network”之前，我觉得有必要先向大家普及一下关于Sora的一些不实使用渠道。</p><p>由于Sora模型的高人气，不少人试图利用这一热点进行牟利，因此希望大家保持警惕，避免上当受骗。</p><p>大家都知道，中美两国在AI领域各自拥有领军企业和人物，分别是美国的Sam Altman和中国的李一舟。最近，关于这两位人物的梗图在网络上大受欢迎。图中左侧为OpenAI的CEO Sam Altman，而右侧则是在社交媒体上拥有超百万粉丝、销售AI课程的清华大学博士李一舟。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402212023750.png" alt="image-20240221202323573"></p><p>这位自称是清华博士的网络红人李一舟，最近推出了一款售价199元的AI课程，在抖音上成功吸引了超过百万粉丝。他不仅在这里推广，还在朋友圈广告宣传，打出了一个诱人的优惠：原价999元的AI课程，现价只需199元。</p><p>根据飞瓜数据的统计，李一舟推出的AI课程《每个人的人工智能课》在一年内售出大约25万套，总销售额达到了约5000万元。</p><p>因此，我想提醒大家，在面对这类课程时要保持警惕，聪明地保护自己的钱包，不要轻易受到诱惑哦~</p><h2 id="2-真实的Sora使用渠道"><a href="#2-真实的Sora使用渠道" class="headerlink" title="2. 真实的Sora使用渠道"></a>2. 真实的Sora使用渠道</h2><p>在谈论了那些虚假的Sora使用渠道之后，现在让我们转向真实且可靠的使用方法，也就是本文的焦点：OpenAI Red Teaming Network。</p><p>根据OpenAI官方网站的信息，尽管目前Sora尚未对普通公众开放，但实际上有两种途径可以接触到Sora：</p><ol><li>OpenAI Red Teaming Network成员</li><li>视觉艺术家、设计师和电影制作者</li></ol><p>下图是OpenAI官网的截图，信息来源保真</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402212023099.png" alt="image-20240221202343031"></p><p>关于后者，由于其条件相对不明确，OpenAI并未提供一个具体的官方申请途径。然而，对于Red Teaming Network这一选项，OpenAI确实提供了一个官方的申请渠道。</p><p>因此，我们今天的重点将集中在这第一种方式——Red Teaming Network上。</p><h2 id="3-什么是OpenAI-Red-Teaming-Network"><a href="#3-什么是OpenAI-Red-Teaming-Network" class="headerlink" title="3. 什么是OpenAI Red Teaming Network"></a>3. 什么是OpenAI Red Teaming Network</h2><p>OpenAI Red Teaming Network，简而言之，是OpenAI发起的一个特别项目，它邀请各领域的专家参与其中。项目的核心是进行“红队测试”，这是一种通过模拟攻击者角色来发现<strong>潜在安全漏洞</strong>的方法，旨在<strong>评估并提升</strong>OpenAI的AI模型的安全性和可靠性。</p><p>这个网络不只是关注一次性的安全评估，它更是致力于构建一个持续性的、动态变化的安全评价体系。通过不断的挑战和测试，这个网络确保AI技术能在安全和可靠性方面持续进步。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402212023234.png" alt="image-20240221202359185"></p><h2 id="4-OpenAI-Red-Teaming-Network的目的是什么"><a href="#4-OpenAI-Red-Teaming-Network的目的是什么" class="headerlink" title="4. OpenAI Red Teaming Network的目的是什么"></a>4. OpenAI Red Teaming Network的目的是什么</h2><p>在人工智能迅速发展的今天，安全性与可靠性已成为每位AI实践者和研究者心中的关键议题。</p><p>正是出于这个原因，OpenAI Red Teaming Network应运而生，其核心目标是：汇聚全球顶尖智慧，共同应对AI领域的潜在风险。</p><p>OpenAI特别强调多样性和全球视角，在这个网络中，他们欢迎来自世界各地、拥有各种背景和专业知识的专家参与。</p><p>这个网络的参与者不局限于AI领域的专家。<strong>任何能够提供独特见解和评估的人</strong>都有机会加入。</p><p>不论是计算机科学、心理学、法律还是哲学领域，只要你对提升AI安全性充满热情，就可能成为这个网络的一员。</p><h2 id="5-如何加入OpenAI-Red-Teaming-Network"><a href="#5-如何加入OpenAI-Red-Teaming-Network" class="headerlink" title="5. 如何加入OpenAI Red Teaming Network"></a>5. 如何加入OpenAI Red Teaming Network</h2><p>根据OpenAI官方网站的最新消息，目前想要加入这个网络，你只需填写一个表格，就有机会成为其一员，并且有机会体验到OpenAI最新推出的，甚至是尚未公开发布的模型。</p><p>表格链接在这里：<a href="https://openai.com/form/red-teaming-network">https://openai.com/form/red-teaming-network</a></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402212024396.png" alt="image-20240221202448348"></p><h2 id="6-OpenAI-Red-Teaming-Network申请难度"><a href="#6-OpenAI-Red-Teaming-Network申请难度" class="headerlink" title="6. OpenAI Red Teaming Network申请难度"></a>6. OpenAI Red Teaming Network申请难度</h2><p>综合来看，加入这个项目的难度显然不小，毕竟涉及到商业机密，且能够接触到最新、未发布的模型。然而，一旦你的申请成功，你将获得其他人所无法享受的特权。</p><p>从申请表格的内容来看，OpenAI在申请过程中主要关注以下几个方面的申请人素质：</p><ul><li>申请人的最高学历及其专业领域</li></ul><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402212025355.png" alt="image-20240221202506302"></p><p>申请人对于Red Teaming的个人解读和看法</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402212025592.png" alt="image-20240221202529544"></p><p>此前对于OpenAI推出的模型以及相关AI技术的熟练程度</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402212025864.png" alt="image-20240221202548818"></p><h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7. 总结"></a>7. 总结</h2><p>总体而言，目前仅有两种途径可以使用官方版的Sora：一是加入Red Teaming Network，二是作为知名的艺术界从业者。<strong>除此之外的所有说法，都不过是虚假诱导。</strong></p><p>如果你恰好是一位AI行业的从业者，对AI安全领域有所研究，并且希望能提前体验OpenAI的最新模型，不妨尝试申请Red Teaming Network。也许，你就是下一个成功的案例呢~</p><p>参考文章：<a href="https://anyubenyu.com/only-way-to-use-sora.html">【新手小白】Sora如何申请？Sora使用教程（最新）</a></p>]]></content>
    
    
    <categories>
      
      <category>Sora</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【最新】Sora到底是什么？Sora详解：一文带你熟悉Sora</title>
    <link href="/sora-wiki.html"/>
    <url>/sora-wiki.html</url>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li><a href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5">基本概念</a><ul><li><a href="#%E4%BB%80%E4%B9%88%E6%98%AFsora">什么是Sora</a></li><li><a href="#sora%E5%BC%95%E5%8F%91%E5%85%A8%E7%90%83%E7%9A%84%E5%85%B3%E6%B3%A8">Sora引发全球的关注</a></li><li><a href="#gpt%E5%95%86%E5%BA%97%E4%B8%AD%E6%9C%89sora-gpt%E5%90%97">GPT商店中有Sora GPT吗？</a></li><li><a href="#sora%E7%9A%84%E8%83%BD%E5%8A%9B">Sora的能力</a></li><li><a href="#openai%E7%9A%84sora%E6%9C%89%E6%9B%BF%E4%BB%A3%E5%93%81%E5%90%97">OpenAI的Sora有替代品吗？</a></li><li><a href="#sora%E6%9C%89%E5%A4%9A%E5%8E%89%E5%AE%B3">Sora有多厉害？</a></li><li><a href="#%E6%88%91%E5%8F%AF%E4%BB%A5%E5%9C%A8chatgpt%E4%B8%8A%E4%BD%BF%E7%94%A8sora-ai%E5%90%97">我可以在ChatGPT上使用Sora AI吗？</a></li><li><a href="#sora%E7%9A%84%E5%BD%93%E5%89%8D%E9%99%90%E5%88%B6">Sora的当前限制</a></li><li><a href="#sora%E5%AF%B9%E6%9C%AA%E6%9D%A5%E5%BD%B1%E5%93%8D%E5%87%A0%E4%BD%95%E5%93%AA%E4%BA%9B%E4%BA%BA%E4%BC%9A%E5%9B%A0%E6%AD%A4%E5%A4%B1%E4%B8%9A">Sora对未来影响几何？哪些人会因此失业</a></li></ul></li><li><a href="#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8sora">如何使用Sora</a><ul><li><a href="#sora%E6%98%AF%E5%90%A6%E5%90%91%E5%85%AC%E4%BC%97%E5%BC%80%E6%94%BE%E6%98%AF%E5%90%A6%E5%85%8D%E8%B4%B9">Sora是否向公众开放，是否免费？</a></li><li><a href="#%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96sora%E7%9A%84%E8%AE%BF%E9%97%AE%E6%9D%83%E9%99%90%E5%B9%B6%E4%BD%BF%E7%94%A8sora">如何获取Sora的访问权限并使用Sora？</a></li></ul></li><li><a href="#sora%E7%9A%84%E5%AE%89%E5%85%A8%E6%80%A7">Sora的安全性</a><ul><li><a href="#sora%E6%98%AF%E5%90%A6%E5%AE%89%E5%85%A8">Sora是否安全？</a></li><li><a href="#sora%E7%9A%84%E5%86%85%E5%AE%B9%E9%99%90%E5%88%B6">Sora的内容限制</a></li><li><a href="#%E5%AE%89%E5%85%A8%E6%8E%AA%E6%96%BD">安全措施</a></li></ul></li><li><a href="#sora-api%E7%9B%B8%E5%85%B3">Sora API相关</a><ul><li><a href="#openai-sora-api">OpenAI Sora API</a></li><li><a href="#sora%E5%AE%9A%E4%BB%B7%E5%8F%8Asora-api%E7%9A%84%E5%AE%9A%E4%BB%B7">Sora定价及Sora API的定价</a></li></ul></li><li><a href="#sora%E5%92%8C%E5%85%B6%E4%BB%96%E5%B7%A5%E5%85%B7%E7%9A%84%E6%AF%94%E8%BE%83">Sora和其他工具的比较</a><ul><li><a href="#sora-vs-diffusion">Sora VS Diffusion</a></li><li><a href="#sora-vs-midjourney">Sora VS Midjourney</a></li><li><a href="#sora-vs-dalle-3">Sora VS DALL·E 3</a></li><li><a href="#sora-vs-pika-runway-stable-video-diffusion">Sora VS Pika, Runway, Stable Video Diffusion</a></li><li><a href="#%E4%B8%8D%E5%90%8C%E7%82%B9">不同点</a></li></ul></li><li><a href="#sora%E6%8A%80%E6%9C%AF%E7%9B%B8%E5%85%B3">Sora技术相关</a><ul><li><a href="#sora%E6%9C%80%E5%A4%A7%E7%9A%84%E6%8A%80%E6%9C%AF%E7%AA%81%E7%A0%B4%E6%98%AF%E4%BB%80%E4%B9%88">Sora最大的技术突破是什么？</a></li><li><a href="#sora%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0">Sora原理概述</a></li></ul></li><li><a href="#sora%E6%9C%AA%E6%9D%A5%E5%8F%91%E5%B1%95">Sora未来发展</a><ul><li><a href="#%E6%9C%AA%E6%9D%A5%E8%AE%A1%E5%88%92">未来计划</a></li></ul></li></ul><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>自2015年成立以来，OpenAI已经成为人工智能研究与推广的领军机构。这家机构在深度学习、自然语言处理等多个前沿领域不断取得重大突破，引领着行业的发展潮流。</p><p>特别是通过其GPT-4等先进模型的开发，OpenAI不仅巩固了自己在人工智能技术创新与应用开发方面的领导地位，更展现了其对AI技术安全和伦理发展的深切承诺。OpenAI致力于利用这些突破性技术造福全人类，为构建一个更智能、更安全的未来而努力。</p><p>（PS：如果你需要开通ChatGPT-4.0的话，请查看：<a href="https://anyubenyu.com/chatgpt-update-guide.html">ChatGPT订阅、升级教程</a>）</p><p>2024年2月18日，OpenAI发布了其最新成就——Sora，这是一个革命性的、先进的视频生成大型模型。Sora的问世不仅代表着OpenAI在视频生成技术领域的巨大飞跃，更标志着该领域新纪元的开启。</p><p>Sora的发布凸显了OpenAI在多个关键方面的卓越成就：视频内容的生成质量、清晰的分辨率以及对文本语义的精准还原能力。这一重大进展不仅展示了OpenAI在技术创新上的领先地位，更预示着人工智能技术在视频内容创造和编辑方面的未来潜力。</p><h3 id="什么是Sora"><a href="#什么是Sora" class="headerlink" title="什么是Sora"></a>什么是Sora</h3><p>在2024年2月18日凌晨，OpenAI引领技术风潮，推出了其最新的大型视频生成模型，命名为“Sora”。这一发布在人工智能界引起了广泛关注，展现了OpenAI在视频生成技术方面的前沿地位。</p><p>从OpenAI官网上展示的Sora生成的视频效果来看，该模型在多个关键领域表现卓越。它不仅在视频质量、分辨率和文本语义还原方面达到了令人惊叹的水平，还在视频动作的一致性、可控性、细节表现和色彩呈现等方面表现出色。</p><p>Sora独特之处在于其能够生成长达一分钟的高质量视频。这些视频不仅精准地展现了场景中的光影关系和物体间的物理遮挡与碰撞，而且镜头效果流畅、变化多端。这一创新超越了当前市场上的主流产品，如Gen-2、SVD-XT和Pika，表明Sora的问世是该领域的一次重大突破，犹如一张制胜的王牌。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402210052925.png" alt="image-20240221005218795"></p><h3 id="Sora引发全球的关注"><a href="#Sora引发全球的关注" class="headerlink" title="Sora引发全球的关注"></a>Sora引发全球的关注</h3><p>Sora的惊艳亮相迅速在全球范围内引起了热烈反响，网络上涌现了一片对人工智能快速发展的惊叹之声，众多知名人士和大V也纷纷发表了自己的看法。</p><p><strong>360公司创始人周鸿祎</strong>对Sora给出了极为积极的评价。他认为，Sora的出现标志着通用人工智能（AGI）实现的时间窗口可能从原本预计的10年大幅缩减至仅一两年内。周鸿祎强调，科技竞争的关键在于集聚优秀人才和深厚的技术积累。他提到：“很多人都在说Sora在效果上远超Pika和Runway，这一点并不令人意外。与那些创业团队相比，像OpenAI这样掌握核心技术的公司无疑具有强大的实力。有观点认为，拥有了AI之后，创业公司只需成为个体经营者，但今天的情况再次证明这种想法是非常荒谬的。”</p><p>周鸿祎还指出，尽管从表面上看国内的大模型发展水平似乎已接近GPT-3.5，但实际上与GPT-4.0相比仍有大约一年半的差距。他认为OpenAI手中可能还握有更多“秘密武器”，不论是GPT-5，还是其他自我学习和自动生成内容的机器学习技术。“奥特曼（OpenAI CEO）是个营销高手，懂得如何掌控节奏。他们并未展示手中所有的牌。这样看来，中国与美国在AI领域的差距可能还在进一步扩大。”</p><p>Sora发布数小时后，埃隆·马斯克在社交媒体上回复了“gg humans”（Good Games的缩写，常用于表示“打得好，我认输”）。随后，马斯克还表示，在未来几年中，借助AI增强的人类将创造出史上最杰出的作品。</p><h3 id="GPT商店中有Sora-GPT吗？"><a href="#GPT商店中有Sora-GPT吗？" class="headerlink" title="GPT商店中有Sora GPT吗？"></a>GPT商店中有Sora GPT吗？</h3><p>目前没有任何GPT可以使用Sora AI。有些可能使用“Sora”这个关键词来吸引注意，但实际上是不可用的。</p><h3 id="Sora的能力"><a href="#Sora的能力" class="headerlink" title="Sora的能力"></a>Sora的能力</h3><p>只需在输入框中键入单词、短语或句子，Sora便能根据这些信息巧妙地创造出丰富的场景。目前，Sora拥有以下引人注目的能力：</p><ul><li>能够构建含有多个角色和精细动作的复杂场景。</li><li>能够根据用户的指示，精确且详尽地重现主题和背景设定。</li><li>能够理解并展现在所生成场景中的元素及其物理属性。</li></ul><p>OpenAI指出，Sora具备生成涵盖数个角色、特定类型动作、以及细致入微的主题和背景的复杂场景的能力。这个模型“不仅能够准确理解用户的指示，还能洞察这些元素在物理世界中的实际存在方式”。</p><h3 id="OpenAI的Sora有替代品吗？"><a href="#OpenAI的Sora有替代品吗？" class="headerlink" title="OpenAI的Sora有替代品吗？"></a>OpenAI的Sora有替代品吗？</h3><p>目前没有。它在视频质量方面超越了其他产品，如Runway、Pika、Stable video。</p><h3 id="Sora有多厉害？"><a href="#Sora有多厉害？" class="headerlink" title="Sora有多厉害？"></a>Sora有多厉害？</h3><p>依据OpenAI在Twitter上发布的初步展示视频，以及创作者们在各大社交媒体平台上的积极反馈，Sora展现了其根据用户提示精确制作视频的卓越能力。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402210052421.png" alt="image-20240221005248276"></p><p>然而，OpenAI同时也坦诚地指出，目前的Sora模型仍有待完善之处。具体而言，“在准确模拟复杂场景的物理特性方面，Sora可能遇到一些挑战，同时它也可能对某些特定的因果关系实例理解不足。”</p><h3 id="我可以在ChatGPT上使用Sora-AI吗？"><a href="#我可以在ChatGPT上使用Sora-AI吗？" class="headerlink" title="我可以在ChatGPT上使用Sora AI吗？"></a>我可以在ChatGPT上使用Sora AI吗？</h3><p>目前，Sora尚未集成到ChatGPT系统或其他OpenAI产品中。这主要是因为其访问权限目前仅限于特定的测试团体，所以还未与公众广泛使用的工具如ChatGPT进行融合。</p><h3 id="Sora的当前限制"><a href="#Sora的当前限制" class="headerlink" title="Sora的当前限制"></a>Sora的当前限制</h3><ul><li>在精确模拟复杂物理过程的能力上遇到一定难题。</li><li>有时对空间细节和特定事件的顺序产生误解。</li><li>在构建逼真的运动和正确模拟对象与角色之间互动时面临挑战。</li></ul><h3 id="Sora对未来影响几何？哪些人会因此失业"><a href="#Sora对未来影响几何？哪些人会因此失业" class="headerlink" title="Sora对未来影响几何？哪些人会因此失业"></a>Sora对未来影响几何？哪些人会因此失业</h3><p>毫无疑问，技术革新如双刃剑，一方面开拓了激动人心的应用前景，另一方面也引发了对于人工智能可能夺走工作机会的担忧。</p><p>尤其是在影视产业，如视频剪辑师和后期制作人员这些角色可能最先感受到冲击。随着像Sora这样的视频模型能够自动或半自动生成视频内容，传统的视频制作和编辑岗位可能会见证需求的减少。后期制作环节，包括剪辑、特效、音效等，同样能够通过AI技术实现自动化或半自动化。</p><p>然而，Sora的出现也向世界展示了人工智能的无限潜力。2024年这一坚实的里程碑落成，给人类带来的是更多的希望而非绝望。因此，它并不一定导致广泛的失业潮。相反，Sora可能会推动视频行业向着更高端、更创新的方向发展。</p><h2 id="如何使用Sora"><a href="#如何使用Sora" class="headerlink" title="如何使用Sora"></a>如何使用Sora</h2><h3 id="Sora是否向公众开放，是否免费？"><a href="#Sora是否向公众开放，是否免费？" class="headerlink" title="Sora是否向公众开放，是否免费？"></a>Sora是否向公众开放，是否免费？</h3><p>OpenAI目前已经向一组精选的“红队成员”开放了Sora，这些成员是专门评估风险和识别潜在问题的专家，他们的任务是从各个角度“对抗性”地测试这个模型，以识别错误信息、偏见和仇恨内容等问题。</p><p>除此之外，Sora还向一部分视觉艺术家、设计师和电影制作人开放。正如OpenAI首席执行官Sam Altman所言，这是一批“数量有限的创作者”，目的是从他们那里收集反馈，进一步完善平台，使其对创意专业人士更加实用。</p><p>对于这些早期用户而言，Sora目前是免费提供的，他们将享有模型的早期访问权限。</p><p>然而，关于Sora未来向公众开放时是否会收费，目前尚无明确信息。值得注意的是，OpenAI已经为其其他产品，如ChatGPT和图像创作工具Dall-E推出了付费版本。</p><h3 id="如何获取Sora的访问权限并使用Sora？"><a href="#如何获取Sora的访问权限并使用Sora？" class="headerlink" title="如何获取Sora的访问权限并使用Sora？"></a>如何获取Sora的访问权限并使用Sora？</h3><p>目前，Sora AI尚未对公众开放，因此您暂时无法登录使用。目前还没有设定一个公开的访问申请流程。</p><p>Sora的使用权限目前仅限于一小群被精选的测试者。OpenAI已经向红队研究员、视觉艺术家、设计师和电影制作人等专业人士授予权限，他们的主要任务是评估Sora可能带来的潜在危害、提供创意方面的反馈，并助力推动Sora模型的进一步发展。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402210053477.png" alt="image-20240221005305401"></p><p>截至目前，Sora并未提供公共API或更广泛的使用权限。</p><p>尽管OpenAI官网上的演示展示了这款文本到视频生成模型的巨大潜力，但实际的使用权限目前依然局限于内部测试和特定的外部试点组。</p><p>OpenAI表示，在未来考虑将Sora纳入商业产品时，可能会扩大其访问权限。然而，关于向公众开放的时间表，目前还未有明确的规划。</p><p>现阶段，这一创新的Sora模型只对OpenAI以外的一小批测试用户开放。其向更广泛公众的开放可能将依据OpenAI自身的使用政策和对风险的评估，随着这项技术的不断成熟而逐步实现。</p><h2 id="Sora的安全性"><a href="#Sora的安全性" class="headerlink" title="Sora的安全性"></a>Sora的安全性</h2><h3 id="Sora是否安全？"><a href="#Sora是否安全？" class="headerlink" title="Sora是否安全？"></a>Sora是否安全？</h3><p>像其他人工智能平台一样，Sora所能生成的内容也引起了人们的担忧。为此，OpenAI正积极寻求解决方案。</p><p>除了与“红队”成员合作外，OpenAI还在开发工具，以辅助检测误导性内容。这包括一种能识别视频是否由Sora生成的“检测分类器”。</p><p>OpenAI的文本分类器旨在“审查并拒绝违反使用政策的文本输入提示”。举例来说，当用户提出与极端暴力、色情内容、仇恨图像、名人肖像或侵犯他人知识产权相关的请求时，系统将予以拒绝。</p><p>此外，OpenAI还计划与全球范围内的政策制定者、教育工作者和艺术家合作，以“深入了解他们的担忧，并探索这项新技术的积极应用场景”。通过这些举措，OpenAI致力于在创新与责任之间找到平衡点，确保Sora的发展既安全又有益。</p><h3 id="Sora的内容限制"><a href="#Sora的内容限制" class="headerlink" title="Sora的内容限制"></a>Sora的内容限制</h3><p>Sora严格遵守伦理准则和安全规程，以限制传播暴力内容、侵犯版权或其他被认为有害的信息。该模型致力于促进一个安全而尊重的环境，鼓励人们在这样的框架内发挥创造力。通过这种方式，Sora不仅是技术进步的象征，同时也是对负责任创新的坚定承诺。</p><h3 id="安全措施"><a href="#安全措施" class="headerlink" title="安全措施"></a>安全措施</h3><ul><li>携手红队共同评估和识别任何潜在的风险或危害。</li><li>创新开发工具专门用于识别和筛查误导性内容。</li><li>采用源自DALL·E 3的成熟安全措施，包括先进的文本和图像分类系统，确保严格遵循使用政策指南。</li></ul><h2 id="Sora-API相关"><a href="#Sora-API相关" class="headerlink" title="Sora API相关"></a>Sora API相关</h2><h3 id="OpenAI-Sora-API"><a href="#OpenAI-Sora-API" class="headerlink" title="OpenAI Sora API"></a>OpenAI Sora API</h3><p>根据OpenAI发布的有关Sora的博客文章，目前Sora模型尚未提供公共API接口。</p><p>这表明，现阶段Sora的使用权仅限于特定的测试用户群体，尚未面向大众开放。这一决策主要是基于对潜在风险的考虑。</p><p>文章还提到，未来可能会将Sora集成到OpenAI的现有产品线中。这意味着从长期视角看，OpenAI可能会通过其商业产品向用户开放Sora的访问权限。然而，目前尚无公开API或其他形式的访问方式。</p><p>综上所述，Sora模型当前仅在内部测试和有限的用户群中启用，没有提供公开的API接口。OpenAI是否会推出公开API接口，可能取决于他们未来的商业战略布局。如需对此内容进行进一步的阐释，请随时告知！</p><h3 id="Sora定价及Sora-API的定价"><a href="#Sora定价及Sora-API的定价" class="headerlink" title="Sora定价及Sora API的定价"></a>Sora定价及Sora API的定价</h3><p>关于Sora AI是否会免费，我持有谨慎的观点，尤其是考虑到视频生成所需的GPU资源。</p><p>围绕OpenAI对于即将公开发布的Sora模型的收费策略，公众的好奇心日益增长。在详细回顾了OpenAI发布的关于Sora能力的研究后，我预测他们可能会实施基于视频输出质量如分辨率等因素的层级定价制度。对于那些需要较多计算资源的高清视频输出，价格可能从每分钟10美元起跳，更高的收费也在情理之中。我认为，最初的需求可能主要来自电影、流媒体节目和游戏开发等娱乐行业，这些领域有能力充分利用视频AI技术的优势。但是，成本因素将是决定Sora能在多大程度上被娱乐行业之外的专业创作者所利用的关键。</p><p>我们期待OpenAI正式公布其定价策略，同时，人们对这一创新但可能成本高昂的模型将如何影响各个领域进行了广泛的猜测和讨论。</p><h2 id="Sora和其他工具的比较"><a href="#Sora和其他工具的比较" class="headerlink" title="Sora和其他工具的比较"></a>Sora和其他工具的比较</h2><h3 id="Sora-VS-Diffusion"><a href="#Sora-VS-Diffusion" class="headerlink" title="Sora VS Diffusion"></a>Sora VS Diffusion</h3><p>Sora模型在长达一分钟的视频制作中展现出了引人注目的连贯性，这相较于以往的扩散模型来说是一大进步。与专注于单幅图像创作的DALL-E不同，Sora展现了其将书面提示转化为不仅是独立的场景，还包括平滑过渡和多视角视频序列的能力。</p><p>这一进展标志着从静态图像扩散技术向视频扩散技术的重大飞跃。Sora通过在连续帧之间保持时间上的连贯性，成功克服了其他视频生成方法所面临的一大核心挑战：在动态环境中维持一致的身份和物理真实性。</p><p>研究团队将这一成就归功于变压器架构的应用，它在空间和时间上的更佳整合，以及创新的基于补丁的训练方法，为解锁Sora在视频生成能力上的潜力铺平了道路。</p><p>尽管图像质量和保真度正在持续迅速进步，但Sora在连贯和连续生成视频方面的进展，为其他扩散模型所未曾触及。它在动态建模和物理现实感方面的表现，为长视频内容的应用开辟了新的可能性。</p><p>未来，Sora似乎已经为扩散方法在模拟我们周围可见世界的核心原则方面的进一步探索设定了新的标准。</p><h3 id="Sora-VS-Midjourney"><a href="#Sora-VS-Midjourney" class="headerlink" title="Sora VS Midjourney"></a>Sora VS Midjourney</h3><p>尽管Sora和Midjourney均展示了他们在文本到图像&#x2F;视频生成领域的显著能力，但目前还不宜将两者直接对比。</p><p>Midjourney的焦点在于为广大用户群提供图像扩散模型的访问，这一过程中它成功构建了一个活跃的艺术社区。通过这种方式，Midjourney不仅提供了技术，还促进了创意交流和灵感的碰撞。</p><p>另一方面，Sora的使用受到更为严格的限制，目前仅限于内部测试。这种独家访问策略限制了外界对其方法论及其强弱点的认识。与此同时，我们还未能充分体验到Midjourney在用户提示和风格选择方面提供的细致控制和个性化定制。</p><p>此外，视频内容的复杂性远超单一图像，这意味着Sora在处理连贯的长视频、平滑转换和视角变化方面所展现的专业水准，与Midjourney的核心优势呈现不同的技术面向。</p><p>因此，由于目前无法公开访问Sora，与Midjourney等现有创意平台进行全面的基准测试还不太现实。</p><p>在评估Sora的技术如何增强、扩展或可能替代像Midjourney这样的解决方案时，我们可能需要等待OpenAI开放更多的访问权限或提供更多透明度。</p><p>总的来说，尽管两者都代表了AI创造力的未来方向，但要进行深入的比较和评估，需要Sora首先在公众面前展示更多的可用性。</p><h3 id="Sora-VS-DALL·E-3"><a href="#Sora-VS-DALL·E-3" class="headerlink" title="Sora VS DALL·E 3"></a>Sora VS DALL·E 3</h3><p>Sora代表了OpenAI在视频生成领域的一项巨大突破，能够生成长达一分钟的高保真视频。作为一个先进的生成模型，Sora通过训练能够处理各种持续时间、分辨率和宽高比的视频和图像数据。它采用基于变换器的架构，有效操作视频和图像的时空潜在代码，是在视频生成模型规模扩大努力中的关键一步。Sora的开发被看作是构建物理世界通用模拟器这一宏伟目标上的一个有希望的里程碑。</p><p>Sora与DALL-E 3的联系在于它们对生成建模的共享方法，以及在模拟物理世界方面的应用。</p><p>DALL-E 3因能根据文本描述生成图像而备受瞩目，采用了与Sora相似的方法来运用大规模生成模型。</p><p>Sora则将这种能力扩展到视频领域，允许用户创造动态的视觉内容。这两个模型都展现了利用生成模型来创造多样化和复杂媒体内容的巨大潜力，为AI驱动的内容创作领域做出了显著贡献。</p><h3 id="Sora-VS-Pika-Runway-Stable-Video-Diffusion"><a href="#Sora-VS-Pika-Runway-Stable-Video-Diffusion" class="headerlink" title="Sora VS Pika, Runway, Stable Video Diffusion"></a>Sora VS Pika, Runway, Stable Video Diffusion</h3><table><thead><tr><th>模型</th><th>发布日期</th><th>使用便捷性</th><th>特点</th><th>价格</th></tr></thead><tbody><tr><td>OpenAI Sora</td><td>2024年2月</td><td>未知</td><td>强大、功能更健全</td><td>尚未开放</td></tr><tr><td>Pika</td><td>2023年1月</td><td>简单</td><td>用户友好，多种风格和效果</td><td>订阅制</td></tr><tr><td>Runway</td><td>2023年</td><td>困难</td><td>强大、功能更健全</td><td>订阅制</td></tr><tr><td>Stable Video Diffusion</td><td>2023年</td><td>困难</td><td>视频稳定和增强</td><td>自托管&#x2F;订阅制</td></tr></tbody></table><h3 id="不同点"><a href="#不同点" class="headerlink" title="不同点"></a>不同点</h3><ul><li>OpenAI的Sora模型，作为<strong>业界领先</strong>的文本到视频生成模型，虽然功能强大，但目前仍处于开发阶段，因此实际应用可能存在一定难度。</li><li>作为Sora的一个更加用户友好的选择，Pika提供了一种简便的方式来生成具有丰富风格和效果的视频，适合那些寻求更易操作选项的用户。</li><li>Runway和Stable Video Diffusion是两个视频编辑平台，它们提供了一系列创建和编辑视频的工具，包括将文本转换为视频的功能，满足各种创意需求。</li></ul><h2 id="Sora技术相关"><a href="#Sora技术相关" class="headerlink" title="Sora技术相关"></a>Sora技术相关</h2><h3 id="Sora最大的技术突破是什么？"><a href="#Sora最大的技术突破是什么？" class="headerlink" title="Sora最大的技术突破是什么？"></a>Sora最大的技术突破是什么？</h3><p>当前，文本到视频领域面临着众多挑战，如处理帧间依赖性、训练数据的广度和深度、计算资源的需求以及过拟合问题，这些因素共同阻碍了高质量长视频的生成。</p><p>OpenAI的Sora模型在这方面实现了显著的技术突破。它能在不牺牲质量的情况下生成长达一分钟的视频，这在行业中是极其罕见的成就。这一进步不仅展现了Sora的先进性，更是再次证明了OpenAI在大型模型领域的卓越研发实力和领先地位。</p><h3 id="Sora原理概述"><a href="#Sora原理概述" class="headerlink" title="Sora原理概述"></a>Sora原理概述</h3><p>此前，openai发布了Sora技术报告，这里有一份技术报告的思维导图分析。需要的话请查看：<a href="https://anyubenyu.com/sora-technical-report-mindmap/">探秘Sora原理，图解Sora(思维导图)</a></p><p>Sora采用的扩散模型技术启动于一个充满静态噪声的视频状态，然后通过一系列精细的步骤逐渐消除这些噪声，从而将视频转化为清晰的视觉内容。这一过程模仿了从混沌到有序的自然过渡，使得Sora能够以高度精确的方式呈现用户的文本提示。</p><p>与ChatGPT类似，Sora同样基于Transformer架构，这一架构在处理大规模数据和捕捉复杂模式方面表现卓越。此外，Sora还借鉴了DALL-E 3的重述技术，这项技术能够为视觉训练数据生成精确、描述性强的字幕。因此，Sora在视频生成过程中能够精准地反映并还原用户文本提示的语义内容，展现出卓越的理解和转换能力。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402210053326.png" alt="image-20240221005326217"></p><h2 id="Sora未来发展"><a href="#Sora未来发展" class="headerlink" title="Sora未来发展"></a>Sora未来发展</h2><h3 id="未来计划"><a href="#未来计划" class="headerlink" title="未来计划"></a>未来计划</h3><ul><li>邀请红队专家、视觉艺术家、设计师和电影制作人体验Sora，并提供宝贵反馈，以便进一步完善和发展这一技术。</li><li>计划在Sora未来的迭代中整合C2PA元数据标准，增强内容的透明度和可信度。</li><li>与全球范围内的政策制定者、教育专家和艺术家展开合作，共同探索Sora在不同领域中的潜在正面应用，并对可能的担忧进行深入讨论和理解。</li></ul><p>参考文章：<a href="https://anyubenyu.com/sora-wiki.html">【最新】Sora到底是什么？Sora详解：一文带你熟悉Sora</a></p>]]></content>
    
    
    <categories>
      
      <category>Sora</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Sora新突破！AI生成电影迈向新阶段，配音版Sora登场！将如何改变影视行业？</title>
    <link href="/sora-with-elevenlabs-audio.html"/>
    <url>/sora-with-elevenlabs-audio.html</url>
    
    <content type="html"><![CDATA[<h2 id="Sora之后迎来新突破！-配音版Sora来袭，AI生成电影又更近一步！"><a href="#Sora之后迎来新突破！-配音版Sora来袭，AI生成电影又更近一步！" class="headerlink" title="Sora之后迎来新突破！ 配音版Sora来袭，AI生成电影又更近一步！"></a>Sora之后迎来新突破！ 配音版Sora来袭，AI生成电影又更近一步！</h2><p>在2024年伊始，人工智能界迎来了一次创新性的突破，由AI语音技术的先锋公司ElevenLabs带头实现。他们最近的成就体现在为OpenAI的Sora视频模型提供了令人动容的AI配音。这一进步不仅为长久以来的“无声电影”时代画上了圆满的句号，而且有潜力彻底革新整个价值高达万亿美元的影视制作行业。</p><p>视频链接：<a href="https://www.bilibili.com/video/BV1Uu4m1A7t9/?vd_source=2c472247eb6758ec360912435e346ecf">配音版Sora - 哔哩哔哩</a></p><h2 id="Sora模型：AI视频生成的里程碑"><a href="#Sora模型：AI视频生成的里程碑" class="headerlink" title="Sora模型：AI视频生成的里程碑"></a>Sora模型：AI视频生成的里程碑</h2><p>自从OpenAI推出Sora模型以来，它凭借高品质和逼真的视频生成能力，令公众深感震撼。Sora能够基于简单的文本提示，创造出令人难以置信的视频内容，涵盖了从壮丽的自然风光到繁复的城市街景等各种场景。然而，尽管其视频效果极为令人印象深刻，但一直以来缺少配音的部分仍是一个小小的遗憾。</p><h2 id="ElevenLabs：AI配音的革命"><a href="#ElevenLabs：AI配音的革命" class="headerlink" title="ElevenLabs：AI配音的革命"></a>ElevenLabs：AI配音的革命</h2><p>正在众人对Sora视频无声状态的惋惜之际，ElevenLabs的技术飞跃给这些视频注入了新的生命。借助其先进的AI语音合成技术，ElevenLabs不仅为Sora视频赋予了声音，而且还实现了与视频中动态和情境的精准匹配。无论是动物的叫声、城市的喧嚣，还是大自然的宁静，每一个声音都显得逼真而细腻，仿佛将观众带入了一个身临其境的体验。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402240952241.png" alt="image-20240224095239073"></p><h2 id="技术分析：AI配音如何实现？"><a href="#技术分析：AI配音如何实现？" class="headerlink" title="技术分析：AI配音如何实现？"></a>技术分析：AI配音如何实现？</h2><p>ElevenLabs的AI配音技术远非简单的视频配音工作，它涉及对视频内容的深入分析，精准识别出视频中的关键元素和场景。接着，结合其庞大的声音数据库，通过复杂的算法运算，精心挑选出最适合的声音配音方案。这个过程不仅对模型的图像识别能力提出了高标准，还要求对各种声音的类型、特点以及它们与特定场景的匹配度有着深入而细致的理解。</p><h2 id="影响及展望：AI配音将如何改变影视行业？"><a href="#影响及展望：AI配音将如何改变影视行业？" class="headerlink" title="影响及展望：AI配音将如何改变影视行业？"></a>影响及展望：AI配音将如何改变影视行业？</h2><p>ElevenLabs的这项创新毫无疑问地为影视制作行业开辟了新的可能性。首先，它大幅度降低了制作高质量配音内容的成本和难度，使得即便是规模较小的制作团队也能制作出具有卓越配音效果的作品。其次，AI配音技术所具备的灵活性和多样性，极大地拓展了创作的想象空间。展望未来，我们可能会见证更多语言、更丰富风格的配音作品的诞生，一个多姿多彩的声音世界将逐渐成为现实。</p><p>网友们对此感到震撼，纷纷赞叹：“这简直是向完全由AI生成的电影迈进了一大步！”</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402240952821.png" alt="image-20240224095213773"></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>ElevenLabs与OpenAI的Sora模型联手，这场梦幻般的合作不仅彰显了AI技术在视频和音频领域的巨大潜力，而且预示着未来影视制作的多样性和创新性。随着技术的持续进步，AI配音技术有望在游戏、广告、教育等众多行业中扮演关键角色，从而全新定义我们对声音的认知和应用。在这个AI技术不断演进的时代，影视制作的未来显得无比广阔和充满可能性。</p><p>想用Sora的可以参考这篇文章：<a href="https://anyubenyu.com/use-sora-guide.html">【保姆级】OpenAI Sora：最新文生视频教程,Sora怎么用（新手小白）</a></p><p>原文链接：<a href="https://anyubenyu.com/sora-with-elevenlabs-audio.html">Sora新突破！AI生成电影迈向新阶段，配音版Sora登场！将如何改变影视行业？</a></p>]]></content>
    
    
    <categories>
      
      <category>Sora</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【保姆级】OpenAI Sora：最新文生视频教程,Sora怎么用（新手小白）</title>
    <link href="/use-sora-guide.html"/>
    <url>/use-sora-guide.html</url>
    
    <content type="html"><![CDATA[<h2 id="1-Sora-是什么？"><a href="#1-Sora-是什么？" class="headerlink" title="1. Sora 是什么？"></a>1. Sora 是什么？</h2><p>2024年2月16日，OpenAI 在其官网上面正式宣布推出文本生成视频的大模型 Sora:</p><p><a href="https://openai.com/sora">https://openai.com/sora</a></p><p><strong>（PS：目前，OpenAI 尚未公开开放 Sora 的灰度测试。然而，借鉴之前 DALL·E 图像模型的案例，我们可以预见首先会向 ChatGPT Plus 的付费用户提供这一服务。对于有意体验此服务的用户，如果您尚未注册或希望了解如何升级至 GPT Plus，可以参考下面的教程: <a href="https://anyubenyu.com/chatgpt-update-guide.html">升级 ChatGPT Plus 的教程</a> ，一分钟完成升级</strong></p><p>Sora拥有将简短文本描述转化为高达60秒的高质量视频的强大功能，从而将视频创作过程提升至前所未有的简易性和高效率。这一技术为视频创作领域带来了革命性的变革，极大地简化了制作流程。</p><p>本文将为您提供关于如何使用Sora的最新详细教程。</p><h2 id="2-Sora-视频案例"><a href="#2-Sora-视频案例" class="headerlink" title="2. Sora 视频案例"></a>2. Sora 视频案例</h2><p>Sora的应用领域十分广泛，它能够覆盖从教育教学、产品演示到内容营销等多个方面，为这些领域提供了实现高质量视频内容创作的强大工具。通过Sora，各类用户能够更加便捷地创造出既专业又引人入胜的视频内容。</p><p>下面是 OpenAI 官方发布的应用案例：</p><blockquote><p>1.Prompt: A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse. She wears sunglasses and red lipstick. She walks confidently and casually. The street is damp and reflective, creating a mirror effect of the colorful lights. Many pedestrians walk about.  </p></blockquote><p>翻译：一位时尚的女性走在东京街头，周围是温暖闪亮的霓虹灯和活力四射的城市标识。她穿着一件黑色皮夹克，一条长长的红色连衣裙，搭配黑色靴子，并背着一个黑色手提包。她戴着墨镜，涂着红色口红。她步履自信，悠然自得地走着。街道潮湿而反光，呈现出丰富多彩的灯光的镜面效果。许多行人在街上走动。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402181854616.jpeg"></p><p>openai sora文生视频案例</p><blockquote><p>2.Prompt: Several giant wooly mammoths approach treading through a snowy meadow, their long wooly fur lightly blows in the wind as they walk, snow covered trees and dramatic snow capped mountains in the distance, mid afternoon light with wispy clouds and a sun high in the distance creates a warm glow, the low camera view is stunning capturing the large furry mammal with beautiful photography, depth of field.  </p></blockquote><p>翻译：几只巨大的长毛猛犸象踏过一片雪白的草地，它们长长的毛发在微风中轻轻飘动着，远处覆盖着雪的树木和雄伟的雪山，午后的光线下有些薄云，太阳高悬在远方，营造出温暖的光芒。低角度的摄影视角令人惊叹，捕捉到了这些大型毛茸茸的哺乳动物，画面景深感强烈。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402181854749.jpeg"></p><p>openai sora文生视频案例</p><blockquote><p>3.Prompt: Historical footage of California during the gold rush.  </p></blockquote><p>翻译：加利福尼亚淘金热时期的历史影像。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402181854555.jpeg"></p><p>openai sora文生视频案例</p><blockquote><p>4.Prompt: A close up view of a glass sphere that has a zen garden within it. There is a small dwarf in the sphere who is raking the zen garden and creating patterns in the sand.  </p></blockquote><p>翻译：放大观看一个玻璃球，里面有一个禅宗花园。球内有一个小矮人，他正在用耙子整理禅宗花园，并在沙地上创造出图案。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402181854605.jpeg"></p><p>openai sora文生视频案例</p><blockquote><p>5.Prompt: A cartoon kangaroo disco dances.  </p></blockquote><p>翻译：一只卡通袋鼠在迪斯科舞厅跳舞。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402181854586.jpeg"></p><p>openai sora文生视频案例</p><blockquote><p>6.Prompt: The camera follows behind a white vintage SUV with a black roof rack as it speeds up a steep dirt road surrounded by pine trees on a steep mountain slope, dust kicks up from it’s tires, the sunlight shines on the SUV as it speeds along the dirt road, casting a warm glow over the scene. The dirt road curves gently into the distance, with no other cars or vehicles in sight. The trees on either side of the road are redwoods, with patches of greenery scattered throughout. The car is seen from the rear following the curve with ease, making it seem as if it is on a rugged drive through the rugged terrain. The dirt road itself is surrounded by steep hills and mountains, with a clear blue sky above with wispy clouds.  </p></blockquote><p>翻译：摄像机跟随一辆白色老式SUV，顶部有黑色行李架，它加速通过一条陡峭的土路，周围是松树，地势陡峭，车轮卷起了尘土，阳光照射在SUV上，它沿着土路飞驰，给场景增添了温暖的光芒。土路在远处轻轻弯曲，看不到其他车辆。路边的树是红杉，绿色的植物点缀其中。汽车从后方的镜头中轻松地跟随着曲线，使其看起来好像在崎岖的地形中轻松驾驶。土路周围是陡峭的山丘和山脉，天空晴朗，偶有薄云飘过。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402181854622.jpeg"></p><p>openai sora文生视频案例</p><blockquote><p>7.Prompt: Reflections in the window of a train traveling through the Tokyo suburbs.</p><p>翻译：一辆列车穿越东京郊区时，窗户上的倒影。</p></blockquote><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402181854244.jpeg"></p><p>openai sora文生视频案例</p><p>8.Prompt: Tour of an art gallery with many beautiful works of art in different styles. 翻译：参观一个艺术画廊，展示了许多不同风格的精美艺术品。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402181854319.jpeg"></p><blockquote><p>9.Prompt: A grandmother with neatly combed grey hair stands behind a colorful birthday cake with numerous candles at a wood dining room table, expression is one of pure joy and happiness, with a happy glow in her eye. She leans forward and blows out the candles with a gentle puff, the cake has pink frosting and sprinkles and the candles cease to flicker, the grandmother wears a light blue blouse adorned with floral patterns, several happy friends and family sitting at the table can be seen celebrating, out of focus. The scene is beautifully captured, cinematic, showing a 3&#x2F;4 view of the grandmother and the dining room. Warm color tones and soft lighting enhance the mood.  </p></blockquote><p>翻译：一位头发整齐梳理的祖母站在木制餐桌后面，桌上摆放着一个五彩缤纷的生日蛋糕，上面点着许多蜡烛，她的表情洋溢着纯粹的喜悦和幸福，眼中闪烁着快乐的光芒。她向前倾身，轻轻吹灭了蜡烛，蛋糕上涂着粉红色的糖霜和彩色糖粒，蜡烛的火焰也熄灭了，祖母穿着一件淡蓝色的上衣，上面点缀着花卉图案，可以看到几位快乐的朋友和家人坐在餐桌旁庆祝，但是他们处于焦点之外。这个场景被美丽地拍摄下来，有电影般的感觉，展示了祖母和餐厅的三分之四视角。温暖的色调和柔和的光线增强了氛围。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402181854293.jpeg"></p><p>openai sora文生视频案例</p><blockquote><p>10.Prompt: A Chinese Lunar New Year celebration video with Chinese Dragon.  </p></blockquote><p>翻译：一个有中国龙的中国农历新年庆祝视频。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402181854274.jpeg"></p><p>openai sora文生视频案例</p><h2 id="3-Sora-怎么使用"><a href="#3-Sora-怎么使用" class="headerlink" title="3. Sora 怎么使用"></a>3. Sora 怎么使用</h2><p><strong>（PS：目前，OpenAI 尚未公开开放 Sora 的灰度测试。然而，借鉴之前 DALL·E 图像模型的案例，我们可以预见首先会向 ChatGPT Plus 的付费用户提供这一服务。对于有意体验此服务的用户，如果您尚未注册或希望了解如何升级至 GPT Plus，可以参考下面的教程: <a href="https://anyubenyu.com/chatgpt-update-guide.html">升级 ChatGPT Plus 的教程</a> ，一分钟完成升级</strong></p><h3 id="3-1-使用Sora前的准备工作"><a href="#3-1-使用Sora前的准备工作" class="headerlink" title="3.1 使用Sora前的准备工作"></a>3.1 使用Sora前的准备工作</h3><p>在开始之前，请确保您已经注册了OpenAI账户，并且已经获得了访问Sora的权限。同时，请准备好您希望转换成视频的文本描述，并记住，这些描述越详细越好。这将有助于Sora更准确地理解并实现您的视频创作愿景。</p><h3 id="3-2-Sora使用步骤一：文本描述"><a href="#3-2-Sora使用步骤一：文本描述" class="headerlink" title="3.2 Sora使用步骤一：文本描述"></a>3.2 Sora使用步骤一：文本描述</h3><p>首先，登录您的OpenAI账户，并导航至Sora的使用界面。在这里，您会找到一个专门的区域用于输入文本描述。您的输入可以是一个故事的概要、具体的场景描述，或者详细的动作指令。确保您的描述尽可能清晰和具体，这将帮助Sora更精确地捕捉并实现您的创意。</p><h3 id="3-3-Sora使用步骤二：生成视频"><a href="#3-3-Sora使用步骤二：生成视频" class="headerlink" title="3.3 Sora使用步骤二：生成视频"></a>3.3 Sora使用步骤二：生成视频</h3><p>在完成文本描述和调整好所有自定义设置之后，点击“生成视频”按钮来启动过程。此时，Sora将开始处理您的请求，这个过程可能需要几分钟的时间。一旦完成，您就可以观看并预览Sora为您创造的视频了。这一步骤将是您创意实现的关键时刻，让您的想象力转化为生动的视觉表现。</p><p><strong>需要注意的是，截止2024年2月18日，OpenAI只向部分专业用户开放了Sora的访问权限。普通用户只能观看其发布的演示视频。</strong></p><h2 id="4-Sora-常见问题"><a href="#4-Sora-常见问题" class="headerlink" title="4. Sora 常见问题"></a>4. Sora 常见问题</h2><p>OpenAI的Sora代表着视频创作新纪元的到来，它让从业内专业人士到业余爱好者都能够轻松地制作出高品质的视频内容。虽然目前还存在一些限制，但随着技术的不断发展和完善，我们有理由相信这些挑战将会逐步被克服。现在就尝试使用Sora，开启您充满创造力的AI视频制作旅程吧！</p><h2 id="5-Sora技术原理"><a href="#5-Sora技术原理" class="headerlink" title="5. Sora技术原理"></a>5. Sora技术原理</h2><p>OpenAI推出了一项划时代的技术成果——Sora，这是一个能够基于文本生成视频的先进AI模型。仅凭简洁的文本描述，Sora便能创造出高达1分钟的流畅视频。但您可能好奇，Sora是如何实现这一技术壮举的呢？接下来，让我们深入探索并揭秘Sora背后的技术原理。也可以看这张思维导图：<a href="https://anyubenyu.com/sora-technical-report-mindmap/">Sora原理，图解Sora</a></p><h3 id="基于Transformer架构"><a href="#基于Transformer架构" class="headerlink" title="基于Transformer架构"></a>基于Transformer架构</h3><p>Sora模型在其核心构造上与GPT模型颇为相似，均是基于先进的Transformer架构，从而赋予了Sora卓越的扩展能力。Transformer架构采用的是一种革命性的自注意力机制的神经网络，它能够高效地处理输入文本中各个位置的信息。这种机制使得模型能夾捉到更广泛的全局上下文信息，极大地增强了对文本的理解深度。正是得益于这样的架构，Sora在将文本转化为视频的过程中，能够更加精准地把握并表现出文本中的细节和含义。</p><h3 id="扩散模型和训练稳定性"><a href="#扩散模型和训练稳定性" class="headerlink" title="扩散模型和训练稳定性"></a>扩散模型和训练稳定性</h3><p>Sora模型引入了创新的扩散模型方法，这与传统的生成对抗网络（GAN）模型相比，展现出了更加卓越的生成多样性和训练稳定性。扩散模型的核心在于逐步消除噪声的过程，以此逐渐构建和完善视频内容。这种方法不仅有效提升了生成视频的质量，而且还确保了视频场景的真实感和细节丰富度。通过采用这种先进的扩散模型，Sora能够创造出更加逼真、细腻的视频环境，为用户带来更为生动和丰富的视觉体验。</p><h3 id="生成视频的数据处理和压缩"><a href="#生成视频的数据处理和压缩" class="headerlink" title="生成视频的数据处理和压缩"></a>生成视频的数据处理和压缩</h3><p>为了应对生成视频时涉及的大量数据处理需求，Sora模型巧妙地采用了高效的数据处理和压缩技术。通过对视频数据进行精细的处理和智能压缩，Sora不仅能够显著减少对存储空间的需求，同时也确保了视频质量的保持。这意味着在优化存储效率的同时，Sora依然能够提供清晰、高质量的视频输出，从而在保障视频质量的前提下实现了数据处理的高效率。</p><h3 id="视频质量和逼真度"><a href="#视频质量和逼真度" class="headerlink" title="视频质量和逼真度"></a>视频质量和逼真度</h3><p>Sora模型在生成视频的过程中，注重保持视频质量和逼真度。通过采用Transformer架构和扩散模型的方法，Sora能够生成更加连贯、且具有很高逼真度的视频场景。这使得Sora在应用领域具有广泛的潜力，比如可以用于影视制作、游戏开发等方面。</p><p>参考链接：<a href="https://www.openai.com/research/sora/">https://www.openai.com/research/sora/</a></p><h2 id="6-openai-sora如何使用的常见问答Q-A"><a href="#6-openai-sora如何使用的常见问答Q-A" class="headerlink" title="6. openai sora如何使用的常见问答Q&amp;A"></a>6. openai sora如何使用的常见问答Q&amp;A</h2><h3 id="Sora是什么？"><a href="#Sora是什么？" class="headerlink" title="Sora是什么？"></a>Sora是什么？</h3><ul><li><strong>定义：</strong> Sora是OpenAI开发的一个先进的AI视频生成模型。</li><li><strong>功能：</strong> 它能够根据用户提供的文字描述生成长达60秒的高质量视频。</li><li><strong>特点：</strong> 视频特色包括复杂场景、生动的角色表情和多样的镜头运动。</li></ul><h3 id="如何使用Sora？"><a href="#如何使用Sora？" class="headerlink" title="如何使用Sora？"></a>如何使用Sora？</h3><ul><li><strong>步骤一：</strong> 登录您的OpenAI账户并定位到Sora的操作界面。</li><li><strong>步骤二：</strong> 在提供的文本框内输入文本描述，例如故事概述、场景描述或具体动作指令。</li><li><strong>步骤三：</strong> 点击生成按钮，Sora将根据您提供的文本来制作视频。</li></ul><h3 id="Sora的优点是什么？"><a href="#Sora的优点是什么？" class="headerlink" title="Sora的优点是什么？"></a>Sora的优点是什么？</h3><ul><li><strong>扩展性：</strong> Sora基于Transformer架构设计，适用于多种场景。</li><li><strong>高清晰度：</strong> 能生成高清质量视频，展现复杂场景的光影效果和物理互动。</li><li><strong>场景丰富：</strong> 能够创造包含多个角色、多种动作类型的视频，并与主题和背景紧密相连。</li></ul><h3 id="Sora的训练原理是什么？"><a href="#Sora的训练原理是什么？" class="headerlink" title="Sora的训练原理是什么？"></a>Sora的训练原理是什么？</h3><ul><li><strong>训练阶段一：</strong> 使用标注模型为训练集视频生成详尽的描述。</li><li><strong>指导生成：</strong> 这些描述帮助Sora更准确地进行视频生成。</li><li><strong>技术应用：</strong> 使用稳定扩散技术将静态噪声转化为连贯的图像序列。</li><li><strong>扩散模型：</strong> Sora通过初步的扩散模型确定视频长度，随后逐步去除噪声以完成视频制作。</li></ul><p>原文链接：<a href="https://anyubenyu.com/use-sora-guide.html">【保姆级】OpenAI Sora：最新文生视频教程,Sora怎么用（新手小白）</a></p>]]></content>
    
    
    <categories>
      
      <category>ChatGPT</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【新手小白教程】如何订阅Patreon？patreon支付、充值教程（2024最新）</title>
    <link href="/sub-patreon-guide.html"/>
    <url>/sub-patreon-guide.html</url>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li><a href="#1-%E5%BC%95%E8%A8%80">1. 引言</a></li><li><a href="#2-%E6%B3%A8%E5%86%8Cpatreon%E8%B4%A6%E6%88%B7">2. 注册Patreon账户</a></li><li><a href="#3-%E6%B5%8F%E8%A7%88patreon%E5%86%85%E5%AE%B9">3. 浏览Patreon内容</a></li><li><a href="#4-%E9%80%89%E6%8B%A9%E8%AE%A2%E9%98%85%E6%97%B6%E9%95%BF">4. 选择订阅时长</a></li><li><a href="#5-%E5%BC%80%E9%80%9A%E8%99%9A%E6%8B%9F%E5%8D%A1">5. 开通虚拟卡</a><ul><li><a href="#51-%E4%BB%80%E4%B9%88%E6%98%AF%E8%99%9A%E6%8B%9F%E4%BF%A1%E7%94%A8%E5%8D%A1">5.1. 什么是虚拟信用卡</a></li><li><a href="#52-%E5%A6%82%E4%BD%95%E5%BC%80%E9%80%9A%E8%99%9A%E6%8B%9F%E5%8D%A1">5.2. 如何开通虚拟卡</a></li></ul></li><li><a href="#6-%E4%BD%BF%E7%94%A8%E8%99%9A%E6%8B%9F%E5%8D%A1%E8%AE%A2%E9%98%85">6. 使用虚拟卡订阅</a></li><li><a href="#7-%E6%80%BB%E7%BB%93">7. 总结</a></li></ul><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h2><ul><li><p><strong>什么是Patreon</strong>：<br>Patreon是一个颇具创新性的在线平台，它为内容创造者提供了一种独特的机会，使他们能够通过订阅服务模式直接从粉丝那里获取资金支持或接收打赏。<br>该平台迎合了广泛的创作者类型，涵盖了艺术家、音乐家、作家、视频制作人等多种身份。<br>在Patreon上，这些创作者能定期发布他们的独家内容。与此同时，粉丝可以选择付费订阅来获取这些独特内容，或选择免费订阅以支持他们喜欢的创作者。</p></li><li><p><strong>目的</strong>：本教程的宗旨在于向您提供一份全面的指南，旨在指导您如何在Patreon平台上进行订阅和支付操作。我们将提供详尽的步骤和有用的提示，确保您能够轻松、顺畅地完成整个订阅和支付流程。</p></li></ul><h2 id="2-注册Patreon账户"><a href="#2-注册Patreon账户" class="headerlink" title="2. 注册Patreon账户"></a>2. 注册Patreon账户</h2><ul><li><strong>步骤一</strong>：访问<a href="https://www.patreon.com/">Patreon</a>官网。</li><li><strong>步骤二</strong>：创建账户，填写必要的个人信息。</li><li><strong>步骤三</strong>：有概率需要邮箱验证及账户激活。</li></ul><h2 id="3-浏览Patreon内容"><a href="#3-浏览Patreon内容" class="headerlink" title="3. 浏览Patreon内容"></a>3. 浏览Patreon内容</h2><ul><li>在Patreon上面找到你想要订阅的内容，然后进入支付界面</li></ul><h2 id="4-选择订阅时长"><a href="#4-选择订阅时长" class="headerlink" title="4. 选择订阅时长"></a>4. 选择订阅时长</h2><ul><li><p>选择需要的订阅时长，点击进入支付界面</p><p><img src="https://s2.loli.net/2024/02/18/fZobuvBjTUcCzHA.png" alt="image.png"></p><p>选择完订阅时长后，需要你填写信用卡信息， 接下来我们看如何开通虚拟信用卡。</p><p><img src="https://s2.loli.net/2024/02/18/MEy8FhRsuH9OTzv.png" alt="image.png"></p></li></ul><h2 id="5-开通虚拟卡"><a href="#5-开通虚拟卡" class="headerlink" title="5. 开通虚拟卡"></a>5. 开通虚拟卡</h2><h3 id="5-1-什么是虚拟信用卡"><a href="#5-1-什么是虚拟信用卡" class="headerlink" title="5.1. 什么是虚拟信用卡"></a>5.1. 什么是虚拟信用卡</h3><p>简单的说来，就是如果你需要订阅国外的服务（如chatgpt、midjourney、onlyfans、pateron等等）的话，就必须要有国外的信用卡。但是国内不是没有办法开通国外信用卡吗，所以就需要使用虚拟信用卡，然后用这张虚拟卡去订阅服务。</p><p>这里我比较推荐虚拟卡平台WildCard。相比其他平台，这个平台操作十分简单，用户交互性很简单，全程无脑式操作就行。</p><h3 id="5-2-如何开通虚拟卡"><a href="#5-2-如何开通虚拟卡" class="headerlink" title="5.2. 如何开通虚拟卡"></a>5.2. 如何开通虚拟卡</h3><p>开通步骤如下：</p><p>首先点击链接进入 <a href="https://bewildcard.com/i/GPT009">WildCard 一分钟开卡，轻松订阅海外软件服务</a></p><p>进入网站首页，填写相关信息开卡，中途需要用到支付宝认证，但是只需要扫码即可，不需要上传身份证或者人脸识别。</p><p><img src="https://s2.loli.net/2024/01/25/9zqkCjSZUV3Ex62.png" alt="image.png"></p><p>支付宝认证完之后，选择卡片开通的时长（根据个人需要选择，个人推荐两年的，比较划算，每天不到两毛钱）。</p><p><img src="https://s2.loli.net/2024/01/25/swk3aUTVeQmG2S7.png" alt="image.png"></p><p>支付之后需要几分钟的时间等待开通成功。开通成功之后就可以拿到一张虚拟卡。</p><p>然后在<strong>Patreon</strong>的链接里面，把下面卡片的信息复制粘贴进去就行了。</p><p><img src="https://s2.loli.net/2024/02/01/9GQRHiwsmBJlUhA.jpg" alt="image.png"></p><h2 id="6-使用虚拟卡订阅"><a href="#6-使用虚拟卡订阅" class="headerlink" title="6. 使用虚拟卡订阅"></a>6. 使用虚拟卡订阅</h2><p>接下来详细看如何用购买的虚拟卡订阅<strong>Patreon</strong>。</p><p>回到<strong>Patreon</strong>，在点击订阅时长之后，提示填写信用卡信息</p><p><img src="https://s2.loli.net/2024/02/18/MEy8FhRsuH9OTzv.png" alt="image.png"></p><p>上面需要的每一项信息，都可以直接在虚拟卡网页上看到，直接像下面这样复制过去即可：</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402181659171.png" alt="img"></p><h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7. 总结"></a>7. 总结</h2><ul><li>总费用：wildcard开卡费9.99美元 + Patreon订阅费用</li><li>订阅开通成功之后就可以畅快欣赏Patreon上面的精彩内容啦</li></ul><p>参考文章：<a href="https://anyubenyu.com/sub-patreon-guide.html">【保姆级教程】如何订阅patreon？patreon订阅需要银行卡？patreon虚拟信用卡购买支付教程</a></p>]]></content>
    
    
    <categories>
      
      <category>Patreon</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【新手小白】如何订阅Youtube Premium？Youtube Premium购买教程（2024最新）</title>
    <link href="/sub-youtube-guide.html"/>
    <url>/sub-youtube-guide.html</url>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li><a href="#youtube-premium-%E8%AE%A2%E9%98%85%E6%8C%87%E5%8D%97">YouTube Premium 订阅指南</a><ul><li><a href="#1-%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C">1. 准备工作</a></li><li><a href="#2-%E8%99%9A%E6%8B%9F%E4%BF%A1%E7%94%A8%E5%8D%A1%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B">2. 虚拟信用卡使用教程</a><ul><li><a href="#21-%E8%99%9A%E6%8B%9F%E4%BF%A1%E7%94%A8%E5%8D%A1%E6%98%AF%E4%BB%80%E4%B9%88%E4%B8%9C%E8%A5%BF"><strong>2.1 虚拟信用卡是什么东西</strong></a></li><li><a href="#22-%E5%BC%80%E9%80%9A%E8%99%9A%E6%8B%9F%E5%8D%A1"><strong>2.2 开通虚拟卡</strong></a></li></ul></li><li><a href="#3-youtube-premium%E4%B8%AA%E4%BA%BA%E4%BC%9A%E5%91%98%E8%AE%A2%E9%98%85">3. YouTube Premium个人会员订阅</a></li><li><a href="#4-youtube-premium%E5%AE%B6%E5%BA%AD%E4%BC%9A%E5%91%98%E8%AE%A2%E9%98%85">4. YouTube Premium家庭会员订阅</a></li><li><a href="#5-%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9">5. 注意事项</a></li><li><a href="#6-%E7%BB%93%E8%AF%AD">6. 结语</a></li></ul></li></ul><h2 id="YouTube-Premium-订阅指南"><a href="#YouTube-Premium-订阅指南" class="headerlink" title="YouTube Premium 订阅指南"></a>YouTube Premium 订阅指南</h2><p>YouTube Premium（原名YouTube Red）向用户提供了一系列尊享服务，包括<strong>无广告观看体验、离线下载功能、后台播放支持以及独家原创内容</strong>等。</p><p>此外，用户还可以享受YouTube Music的无广告服务。鉴于不同国家&#x2F;地区的YouTube Premium订阅价格可能存在差异，许多用户选择通过订阅其他国家&#x2F;地区的服务来节省费用。本指南将详细说明如何使用虚拟信用卡，轻松订阅YouTube Premium的个人或家庭会员计划。</p><h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h2><ul><li><strong>获取虚拟信用卡</strong>：您需要一张虚拟信用卡用于订阅。请确保虚拟信用卡有足够的余额，以避免产生拒付记录。</li><li><strong>VPN服务</strong>：为了订阅其他国家&#x2F;地区的YouTube Premium，您需要使用VPN服务更改您的IP地址至目标国家。本教程以菲律宾为例，因为其订阅价格相对较低。</li></ul><h2 id="2-虚拟信用卡使用教程"><a href="#2-虚拟信用卡使用教程" class="headerlink" title="2. 虚拟信用卡使用教程"></a>2. 虚拟信用卡使用教程</h2><h3 id="2-1-虚拟信用卡是什么东西"><a href="#2-1-虚拟信用卡是什么东西" class="headerlink" title="2.1 虚拟信用卡是什么东西"></a><strong>2.1 虚拟信用卡是什么东西</strong></h3><p>虚拟信用卡是一种数字化的信用卡形式，它为用户提供了一次性或可多次使用的卡号，专为<strong>在线交易设计</strong>，从而免去了使用实体信用卡的必要。</p><p>这种卡拥有与实体信用卡相同的属性，如卡号、CVV安全码、注册地址等，几乎涵盖了实体卡的所有功能。</p><p>通常由信用卡发行机构或数字支付服务提供的虚拟信用卡，其主要目的是增加一层额外的安全保护。通过设置使用限制，如交易次数、交易额度和有效期等，虚拟信用卡能有效减少欺诈风险，同时保护用户的真实账户信息免遭泄露。</p><h3 id="2-2-开通虚拟卡"><a href="#2-2-开通虚拟卡" class="headerlink" title="2.2 开通虚拟卡"></a><strong>2.2 开通虚拟卡</strong></h3><p>首先进入官方网站 <a href="https://bewildcard.com/i/GPT009">WildCard 一分钟开卡，轻松订阅海外软件服务</a></p><p>进入网站首页之后，点击立即体验</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402181646556.png" alt="image.png"></p><p>然后点击“立即开卡”</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402181646541.png" alt="image.png"></p><p>然后输入你的手机号码接收验证码（使用邀请码GPT009可以在开卡时优惠2美元）</p><p>然后填写你的个人信息</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402181646378.png" alt="image.png"></p><p>点击下一步，进行支付宝扫码认证（不需要人脸或身份证）</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402181646383.png" alt="image.png"></p><p>在支付宝扫码验证之后，选择开通的时长（根据个人情况选择，我推荐两年的，性价比更高）。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402181646372.png" alt="image.png"></p><p>支付之后需要几分钟的时间等待开通成功。</p><p>然后在youtube绑定信用卡的链接里面，把卡片的信息复制粘贴进去就行了。</p><h2 id="3-YouTube-Premium个人会员订阅"><a href="#3-YouTube-Premium个人会员订阅" class="headerlink" title="3. YouTube Premium个人会员订阅"></a>3. YouTube Premium个人会员订阅</h2><ol><li><strong>更改IP地址</strong>：使用VPN服务更改您的IP地址至菲律宾。</li><li><strong>访问YouTube Premium订阅页面</strong>：打开YouTube并登录您的账户，然后访问YouTube Premium的订阅页面。</li><li><strong>选择订阅方案</strong>：页面上会显示个人会员订阅选项，通常包括一个免费试用期。</li><li><strong>选择支付方式</strong>：您可以选择信用卡、借记卡或PayPal等支付方式。输入您的虚拟信用卡信息。</li><li><strong>确认订阅</strong>：根据页面指示完成订阅过程。您可能需要支付小额验证费用，该费用会在验证后返还。</li></ol><h2 id="4-YouTube-Premium家庭会员订阅"><a href="#4-YouTube-Premium家庭会员订阅" class="headerlink" title="4. YouTube Premium家庭会员订阅"></a>4. YouTube Premium家庭会员订阅</h2><ol><li><strong>锁定国家区域</strong>：在Google Play书店购买免费电子书，以锁定您的账户至特定国家&#x2F;地区。这一步骤确保您可以订阅家庭会员。</li><li><strong>更改IP地址</strong>：使用VPN服务更改您的IP地址至菲律宾。</li><li><strong>访问YouTube Premium订阅页面</strong>：打开YouTube并登录您的账户，然后访问YouTube Premium的订阅页面，选择家庭计划。</li><li><strong>添加支付信息</strong>：选择支付方式并输入虚拟信用卡信息。</li><li><strong>邀请家庭成员</strong>：订阅成功后，您可以邀请最多5位家庭成员加入，享受与个人会员相同的权益。</li></ol><h2 id="5-注意事项"><a href="#5-注意事项" class="headerlink" title="5. 注意事项"></a>5. 注意事项</h2><ul><li><strong>取消订阅</strong>：如果您不打算继续订阅，建议在试用期结束前取消订阅，以避免费用的自动续订。</li><li><strong>虚拟信用卡安全</strong>：请确保使用可靠的虚拟信用卡服务，避免安全风险。</li><li><strong>VPN使用</strong>：选择稳定的VPN服务，确保订阅过程中IP地址稳定。</li></ul><h2 id="6-结语"><a href="#6-结语" class="headerlink" title="6. 结语"></a>6. 结语</h2><p>按照上述指引操作，您将能以更加优惠的价格全面体验YouTube Premium所提供的服务。您还可以考虑邀请家人或朋友加入家庭计划，这样不仅可以共享服务，还能进一步分摊费用，使每位成员的成本更低。别忘了定期检查并管理您的订阅，确保您能够持续享受到无广告、高品质的视频观看体验。</p><p>参考文章：<a href="https://anyubenyu.com/sub-youtube-guide.html">【新手小白】如何订阅Youtube Premium？Youtube Premium购买教程（2024最新）</a></p>]]></content>
    
    
    <categories>
      
      <category>Youtube</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>探秘Sora原理，图解Sora(思维导图)</title>
    <link href="/sora-technical-report-mindmap/"/>
    <url>/sora-technical-report-mindmap/</url>
    
    <content type="html"><![CDATA[<h2 id="Sora原理？Sora技术报告解读（思维导图版）"><a href="#Sora原理？Sora技术报告解读（思维导图版）" class="headerlink" title="Sora原理？Sora技术报告解读（思维导图版）"></a>Sora原理？Sora技术报告解读（思维导图版）</h2><p>这份思维导图是将Sora技术报告进行了整理和总结，并以思维导图的方式呈现了出来。</p><p>使大家能够更清晰、明了的读懂sora技术报告。</p><p>sora技术报告链接：<a href="https://openai.com/research/video-generation-models-as-world-simulators">https://openai.com/research/video-generation-models-as-world-simulators</a></p><p>思维导图以图片的格式给出，<strong>图片较大，加载需要一定时间，请耐心等待</strong></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402181623656.png" alt="img"></p><p>参考文章：<a href="https://anyubenyu.com/sora-technical-report-mindmap/">Sora原理？Sora技术报告解读（思维导图版）</a></p><p>文章链接: <a href="https://anyubenyu.com/sora-technical-report-mindmap/">https://anyubenyu.com/sora-technical-report-mindmap/</a></p>]]></content>
    
    
    <categories>
      
      <category>Sora</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【亲测】解决ChatGPT邮箱注册失败，提示The email you provided is not supported，解决&#39;不支持所提供邮箱&#39;</title>
    <link href="/chatgpt-register-failure.html"/>
    <url>/chatgpt-register-failure.html</url>
    
    <content type="html"><![CDATA[<h1 id="ChatGPT注册、邮箱问题"><a href="#ChatGPT注册、邮箱问题" class="headerlink" title="ChatGPT注册、邮箱问题"></a>ChatGPT注册、邮箱问题</h1><h2 id="1-亲测-解决ChatGPT邮箱注册失败，提示”The-email-you-provided-is-not-supported”"><a href="#1-亲测-解决ChatGPT邮箱注册失败，提示”The-email-you-provided-is-not-supported”" class="headerlink" title="1. [亲测] 解决ChatGPT邮箱注册失败，提示”The email you provided is not supported”"></a>1. [亲测] 解决ChatGPT邮箱注册失败，提示”The email you provided is not supported”</h2><p>随着OpenAI推出的ChatGPT服务因其出色的对话能力而迅速受到全球用户的青睐，人工智能技术的进步显著。</p><p>不过，一些用户在注册ChatGPT时遇到了问题，尤其是当他们尝试使用特定的邮箱服务商注册时，系统会显示一条信息：“The email you provided is not supported”，表明所用的电子邮箱不受支持。</p><p>这个问题主要是由于OpenAI为了防止服务被滥用，采取了一系列风险控制措施所导致的。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402261746696.png" alt="image-20240226174624587"></p><h2 id="2-为什么会有这样的限制？"><a href="#2-为什么会有这样的限制？" class="headerlink" title="2. 为什么会有这样的限制？"></a>2. 为什么会有这样的限制？</h2><p>OpenAI公司采取了一系列限制措施，旨在多方面确保其服务的安全性、合规性，并维护高质量的用户体验。这些措施包括遵循全球各地的法律规定，以及考虑到ChatGPT服务并未在全球所有地区提供。</p><p>为了控制服务访问和质量，OpenAI实施了包括IP地理位置检测、手机号码验证以及对电子邮箱服务商的筛选在内的限制。</p><p>这意味着在一些尚未正式开放服务的地区，如中国大陆，使用某些特定的邮箱服务（如QQ邮箱、火狐邮箱、微软邮箱、谷歌邮箱、教育邮箱）或以”cn”结尾的邮箱注册时，用户可能会面临不支持的提示。这些限制措施是OpenAI为保障服务稳定性和遵守地区法规而必要的调整。</p><h2 id="3-如何解决邮箱注册问题？"><a href="#3-如何解决邮箱注册问题？" class="headerlink" title="3. 如何解决邮箱注册问题？"></a>3. 如何解决邮箱注册问题？</h2><p>尽管遇到了注册障碍，但还是有方法可以解决这一问题，以下是一些亲测有效的解决方案：</p><ol><li>使用其他邮箱</li><li>更换IP环境</li><li>使用一键注册账号服务</li></ol><p>前两种方法都需要手动进行注册，过程略显繁琐。因此，如果你希望更方便快捷的话，可以看看<strong>一键注册服务</strong>。</p><h3 id="3-1-使用其他邮箱"><a href="#3-1-使用其他邮箱" class="headerlink" title="3.1 使用其他邮箱"></a>3.1 使用其他邮箱</h3><p>由于OpenAI实施了一系列限制政策，多数流行的邮箱服务现<strong>已无法用于注册</strong>，包括QQ邮箱、163邮箱，以及所有以.cn或.edu结尾的邮箱地址。</p><p>使用这些邮箱尝试注册时，基本上都会收到错误提示：“Oops! The email you provided is not supported”。</p><p>所以，最好选择一些国际知名的邮箱服务商，如Gmail（对于能够正常访问的用户）、Outlook、Yahoo等，这些服务商的邮箱普遍被ChatGPT支持。</p><p>这里，提供了一些能注册OpenAI账号的邮箱：</p><ol><li>outlook（对国内提供服务，有概率不成功）</li><li>hotmail（对国内提供服务，有概率不成功）</li><li>live.cn（对国内提供服务，有概率不成功）</li><li>gmail（<strong>最推荐</strong>的邮箱，但注册相对繁琐）</li><li>proton.me（比较小众，之前可以用，最近有同学反映会注册失败）</li><li>Yiles Mail（比较小众，目前可用，不做长期保证）</li></ol><p>总的讲来，最好是使用gmail进行注册。其他邮箱如Yiles Mail有概率会失败</p><h3 id="3-2-更换IP环境"><a href="#3-2-更换IP环境" class="headerlink" title="3.2 更换IP环境"></a>3.2 更换IP环境</h3><p>除了邮箱服务商的限制之外，”The email you provided is not supported”的提示也可能是IP地址的问题。</p><p>如果某一IP地址因为<strong>过度使用或滥用</strong>而被标记，那么即便使用被广泛接受的Gmail邮箱进行ChatGPT注册，用户同样可能面临这一报错信息。</p><p>比如你可能使用了某些比较劣质的梯子，很多人共用同一个IP地址，那么OpenAI就会限制这个IP地址的注册。</p><p>所以，不仅要使用支持注册GPT的邮箱，还要使用良好的IP环境。</p><p>这里，为大家提供了三种解决方案：</p><ol><li>使用更优质的梯子</li><li>使用专用的openai远程环境</li><li>使用一键注册账号服务，详见：<a href="https://anyubenyu.com/chatgpt-update-guide.html">ChatGPT注册太繁琐？教你一键注册官方GPT账号</a></li></ol><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402261746148.png" alt="image-20240226174651079"></p><h3 id="3-3-使用一键注册账号服务"><a href="#3-3-使用一键注册账号服务" class="headerlink" title="3.3 使用一键注册账号服务"></a>3.3 使用一键注册账号服务</h3><p>Wildcard的一键注册服务为用户提供了一个便捷的途径，通过它可以轻松完成对OpenAI账户的注册，尤其是对于那些希望避免复杂注册流程或无法直接访问OpenAI服务的用户。</p><p>这项服务利用Wildcard提供的虚拟信用卡功能，允许用户不仅能够一键注册ChatGPT账号，还能轻松管理与订阅其他国外服务。</p><p>具体流程请查看，这里不再赘述：<a href="https://anyubenyu.com/chatgpt-update-guide.html">ChatGPT注册太繁琐？教你一键注册官方GPT账号</a></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402261747841.png" alt="image-20240226174708797"></p><h2 id="4-结语"><a href="#4-结语" class="headerlink" title="4. 结语"></a>4. 结语</h2><p>面对“所提供的电子邮件不受支持”的提示可能会让人感到不便，但幸运的是，绝大多数用户都能找到合适的解决方案以顺畅注册ChatGPT。</p><p>首先，确保你选用的邮箱服务商处于OpenAI的支持列表之内，其中推荐使用Gmail，因为它普遍被接受。</p><p>其次，IP地址也是注册过程中需考虑的关键因素。尝试使用VPN或更改IP地址可能有助于解决区域限制的问题。</p><p>如果你尝试了上述所有方法仍旧遇到障碍，考虑使用一键注册服务，这是一个便捷的选择，能让你迅速完成ChatGPT账户的设置。这种方法可以作为最后的手段，帮助你轻松跨过注册过程中可能遇到的任何技术障碍。</p>]]></content>
    
    
    <categories>
      
      <category>ChatGPT</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【保姆级】什么是ChatGPT Team?一键升级官方ChatGPT Team教程（最新）</title>
    <link href="/chatgpt-team-guide.html"/>
    <url>/chatgpt-team-guide.html</url>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li><a href="#1-chatgpt-team%E4%BB%8B%E7%BB%8D"><strong>1. ChatGPT Team介绍</strong></a></li><li><a href="#2-chatgpt-team%E7%9A%84%E4%BC%98%E5%8A%BF"><strong>2. ChatGPT Team的优势</strong></a></li><li><a href="#3-chatgpt-team%E4%BB%B7%E6%A0%BC"><strong>3. ChatGPT Team价格</strong></a></li><li><a href="#4-%E5%A6%82%E4%BD%95%E5%BC%80%E9%80%9Achatgpt-team"><strong>4. 如何开通ChatGPT Team</strong></a><ul><li><a href="#41-%E4%B8%80%E9%94%AE%E5%8D%87%E7%BA%A7chatgpt-team%E6%95%99%E5%AD%A6"><strong>4.1 一键升级ChatGPT Team教学</strong></a></li><li><a href="#42-%E6%89%8B%E5%8A%A8%E5%BC%80%E9%80%9Achatgpt-team%E6%95%99%E5%AD%A6"><strong>4.2 手动开通ChatGPT Team教学</strong></a></li></ul></li><li><a href="#5-%E6%80%BB%E7%BB%93">5. <strong>总结</strong></a></li><li><a href="#6-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98"><strong>6. 常见问题</strong></a></li></ul><h2 id="1-ChatGPT-Team介绍"><a href="#1-ChatGPT-Team介绍" class="headerlink" title="1. ChatGPT Team介绍"></a><strong>1. ChatGPT Team介绍</strong></h2><p><strong>ChatGPT团队版</strong>是由OpenAI在2023年下半年特别推出的<strong>会员服务计划</strong>，专为满足企业和团队用户对专业和高级服务需求而设计。</p><p>相较于ChatGPT Plus，团队版提供了<strong>更为丰富的功能和服务</strong>。这包括对ChatGPT4、DALL·E等尖端模型的访问权限，扩展的上下文窗口，增加的对话次数上限，以及对用户数据的额外隐私保护——确保产生的数据不会用于进一步的GPT模型训练。这些特性共同构成了团队版的核心优势，旨在为团队用户提供一个更加安全、高效和定制化的使用体验。</p><p><img src="https://s2.loli.net/2024/02/13/RFbnjK3voegXwlY.png" alt="image.png"></p><p>这一计划特别适合需要<strong>高频使用ChatGPT</strong>服务且对数据隐私有较高要求的企业用户。</p><p>今天我就来教大家如何开通ChatGPT Team，分别是<strong>一键升级方式</strong>和<strong>手动开通方式</strong>。</p><p>如需使用ChatGPT4.0可以参考另一篇文章<a href="https://anyubenyu.com/chatgpt-update-guide.html">ChatGPT注册、订阅、升级教程</a></p><h2 id="2-ChatGPT-Team的优势"><a href="#2-ChatGPT-Team的优势" class="headerlink" title="2. ChatGPT Team的优势"></a><strong>2. ChatGPT Team的优势</strong></h2><p>下面是ChatGPT Team的优势和特点：</p><p>以下是ChatGPT团队版的优势和特色：</p><ul><li><strong>高级模型访问权限</strong>：包括GPT-4，搭配32K的扩展上下文窗口，提供比Plus版本更深入的内容理解和交互能力。</li><li><strong>丰富的功能</strong>：用户可以享受GPT-4、DALL·E 3、高级数据分析和联网等高级功能。</li><li><strong>增加的对话次数</strong>：与Plus会员每三小时40次的对话限制相比，团队版用户每三小时可享有100次对话。</li><li><strong>数据隐私保障</strong>：商业数据和用户对话不会被用于训练GPT模型，确保信息安全。</li><li><strong>专属工作空间</strong>：提供安全的团队工作空间，支持在此环境中创建和分享自定义GPT模型，不涉及数据训练用途。</li><li><strong>团队管理工具</strong>：配备管理员控制台，便于工作空间和团队管理。</li><li><strong>早期访问新功能</strong>：享受新功能和改进的早期访问权限，保持技术先进性。</li></ul><p>这些特点共同构成了ChatGPT团队版的核心竞争力，旨在为企业和团队用户提供一个更加专业、安全和高效的服务平台。</p><h2 id="3-ChatGPT-Team价格"><a href="#3-ChatGPT-Team价格" class="headerlink" title="3. ChatGPT Team价格"></a><strong>3. ChatGPT Team价格</strong></h2><p>当前，ChatGPT团队版的订阅价格设定为每月25美元，仅略高于ChatGPT Plus版本的20美元月费。</p><p>然而，要想锁定这一优惠价格，用户必须一次性前付全年的订阅费用。若用户选择按月支付，费用则会增加至每月30美元。</p><p>此外，创建ChatGPT团队账户时，必须至少包括两名成员。这样的设置旨在鼓励团队合作，同时确保服务能够满足多用户环境的需求。</p><p><img src="https://s2.loli.net/2024/02/13/AK4zpblGUxmWhH7.png" alt="image.png"></p><h2 id="4-如何开通ChatGPT-Team"><a href="#4-如何开通ChatGPT-Team" class="headerlink" title="4. 如何开通ChatGPT Team"></a><strong>4. 如何开通ChatGPT Team</strong></h2><p><strong>工具准备：</strong>一台电脑、科学上网工具、ChatGPT账号</p><p>如果你没有ChatGPT账号，请点击：<a href="https://anyubenyu.com/chatgpt-update-guide.html">ChatGPT注册太繁琐？教你一键注册官方GPT账号！</a></p><h3 id="4-1-一键升级ChatGPT-Team教学"><a href="#4-1-一键升级ChatGPT-Team教学" class="headerlink" title="4.1 一键升级ChatGPT Team教学"></a><strong>4.1 一键升级ChatGPT Team教学</strong></h3><p>首先进入<a href="https://bewildcard.com/i/GPT009">wildcard</a>首页，进去开通一张虚拟信用卡，开通需要支付11.9美元（从链接进入可以优惠两美元，即9.9美元，并且是<strong>一次性付费</strong>，之后不需要再付费）</p><p>开通后，点击”我的服务“进入主界面</p><p><img src="https://s2.loli.net/2024/02/13/Wg6jK3CY5yvTSub.png" alt="image.png"></p><p>再点击进入一键升级ChatGPT Team</p><p><img src="https://s2.loli.net/2024/02/13/VqbKcwZ9dWAHmBr.png" alt="image.png"></p><p>然后订阅类型选择team</p><p><img src="https://s2.loli.net/2024/02/13/t8aobuUZmIXk5T6.png" alt="image.png"></p><p>接着按照图中步骤（这里的步骤<strong>跟本文4.2节里的前半部分相同</strong>，也可以参考4.2节）进入ChatGPT官网，选择你需要的订阅方式、team人数、team名称设置好之后，点击下一步</p><p><img src="https://s2.loli.net/2024/02/13/x6J19mFIrASlqXp.png" alt="image.png"></p><p>最后将支付链接拷贝到输入框，点击确定支付并升级，就可以升级到GPT Team啦！</p><p><img src="https://s2.loli.net/2024/02/13/C3JtPSZ6sTzFdfg.png" alt="image.png"></p><p><img src="https://s2.loli.net/2024/02/13/pziyRrHfhNZ5taQ.png" alt="image.png"></p><h3 id="4-2-手动开通ChatGPT-Team教学"><a href="#4-2-手动开通ChatGPT-Team教学" class="headerlink" title="4.2 手动开通ChatGPT Team教学"></a><strong>4.2 手动开通ChatGPT Team教学</strong></h3><p>首先进入网站首页，首先点击自己的头像，然后再弹出菜单中选择My plan</p><p><img src="https://s2.loli.net/2024/02/13/m65j4FueSgI2BHv.png" alt="image.png"></p><p>然后点击Add Team wokrspace，进入升级界面</p><p><img src="https://s2.loli.net/2024/02/13/o2x549pKgZibjyN.png" alt="image.png"></p><p>接下来会要求你创建workspace，先输入你团队的名字，注意，这里的名字在后续可以随时更改的</p><p><img src="https://s2.loli.net/2024/02/13/jZJARC1yTL9MdGl.png" alt="image.png"></p><p>设置好名字后，点击Select billing options，即选择订阅计划</p><p>这里有两种订阅计划，年付和月付，年付的话是25刀每月，月付的话是30刀每月。根据个人需要选择即可。</p><p>此外，还可以选择team里面的人数，最低是2人</p><p><img src="https://s2.loli.net/2024/02/13/ecRt71xmFdOBUgV.png" alt="image.png"></p><p>然后点击continue to billing，进入支付，在这里输入你的信用卡信息，然后点击确认支付即可</p><p>如果你<strong>没有国外信用卡</strong>或者有虚拟信用卡但是<strong>订阅失败</strong>，可以参考使用4.1节的<strong>一键升级ChatGPT Team教程</strong></p><p><img src="https://s2.loli.net/2024/02/13/K4qOjJmcEiwHbT9.png" alt="image.png"></p><h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. <strong>总结</strong></h2><p><strong>工具网站（从链接进入有14块钱优惠）</strong>： <a href="https://bewildcard.com/i/GPT009">WildCard 一分钟开卡，轻松订阅海外软件服务</a></p><p><strong>总费用：</strong></p><ul><li>开卡费用9.99$（一整年的费用，平均下来每天不到两毛钱）</li><li>GPT Team订阅的费用（25$）</li><li>总共34.99$，折合<strong>人民币约245元</strong>（参考汇率7）</li></ul><p>参考文章：<a href="https://anyubenyu.com/chatgpt-team-guide.html">【保姆级】什么是ChatGPT-Team-一键升级官方ChatGPT-Team教程（最新）</a></p><h2 id="6-常见问题"><a href="#6-常见问题" class="headerlink" title="6. 常见问题"></a><strong>6. 常见问题</strong></h2><hr><h3 id="关于ChatGPT团队版"><a href="#关于ChatGPT团队版" class="headerlink" title="关于ChatGPT团队版"></a><strong>关于ChatGPT团队版</strong></h3><p><strong>什么是ChatGPT团队版？</strong><br>ChatGPT团队版是OpenAI专为企业和团队用户设计的高级会员服务，提供包括GPT-4在内的高级模型访问权限，增加的上下文窗口和对话次数，同时重视用户数据的隐私保护。</p><p><strong>ChatGPT团队版的主要优势有哪些？</strong><br>该服务的优点主要包括：高级模型访问（如GPT-4和DALL·E 3）、扩大的32K上下文窗口、每三小时最多100次的对话次数、用户数据隐私保护、专用工作空间及团队管理工具的提供，以及早期访问新功能的机会。</p><p><strong>ChatGPT团队版的定价是怎样的？</strong><br>订阅ChatGPT团队版需每月支付25美元（按年支付）或每月30美元（按月支付）。团队账户初始成员数至少为两人。</p><p><strong>如何开通ChatGPT团队版？</strong><br>用户可通过一键升级（使用Wildcard虚拟信用卡支付11.9美元开通费）或访问官网手动开通（选择订阅计划、设置团队、选择成员数量并完成支付）两种方式开通服务。</p><p><strong>如果没有国外信用卡，我该如何订阅？</strong><br>可以通过使用Wildcard等服务所提供的虚拟信用卡来支付订阅费，便于国际用户轻松开通服务。</p><p><strong>在开通过程中需要注意什么？</strong><br>确保网络连接稳定是关键。若采用一键升级方式，务必通过官方或可信赖的渠道获取虚拟信用卡服务，以避免安全风险。</p><hr>]]></content>
    
    
    <categories>
      
      <category>ChatGPT</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>OpenAI 发布全新文本生成视频模型 Sora，功能有多强大？将带来哪些影响？</title>
    <link href="/chatgpt-sora.html"/>
    <url>/chatgpt-sora.html</url>
    
    <content type="html"><![CDATA[<p>卷疯了卷疯了，短短十几小时内，OpenAI和谷歌接连发布核弹级成果。</p><p>国内还没睡的人们，经历了过山车般的疯狂一晚。</p><p>就在刚刚，OpenAI突然发布首款文生视频模型——Sora。简单来说就是，AI视频要变天了！</p><p>它不仅能够根据文字指令创造出既逼真又充满想象力的场景，而且生成长达1分钟的超长视频，还是一镜到底那种。</p><p>Runway Gen 2、Pika等AI视频工具，都还在突破几秒内的连贯性，而OpenAI，已经达到了史诗级的纪录。</p><p>60秒的一镜到底，视频中的女主角、背景人物，都达到了惊人的一致性，各种镜头随意切换，人物都是保持了神一般的稳定性。</p><blockquote><p>Prompt: A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse. She wears sunglasses and red lipstick. She walks confidently and casually. The street is damp and reflective, creating a mirror effect of the colorful lights. Many pedestrians walk about.</p></blockquote><p>OpenAI究竟是怎么做到的？根据官网介绍，「通过一次性为模型提供多帧的预测，我们解决了一个具有挑战性的问题。」</p><p>显然，这个王炸级技术有着革命般的意义，连Sam Altman都沉迷到不能自拔！</p><p>他不仅疯狂发推安利，而且还亲自下场为网友生成视频：你们随意来prompt，我一一输出。想注册ChatGPT的参考这篇文章：<a href="https://anyubenyu.com/chatgpt-update-guide.html">ChatGPT 注册、订阅、升级教程</a></p><p><img src="https://picx.zhimg.com/v2-c203835052e132385dc8e1e620eedb7b_r.jpg?source=1def8aca"></p><blockquote><p>一位戴着尖顶帽，身披绣有白色星星的蓝色长袍的巫师正在施法，他的一只手射出闪电，另一只手中拿着一本旧书。</p></blockquote><p><img src="https://pic1.zhimg.com/v2-ff34818c19791f6dcfee9789f22fd70e_r.jpg?source=1def8aca"></p><blockquote><p>在一间拥有电影级灯光设置的充满托斯卡纳乡村风情的厨房里，一位擅长利用社交媒体的奶奶，正在教你制作美味的自制诺奇面。</p></blockquote><p><img src="https://pic1.zhimg.com/v2-80b337439a231ead387da03775f516a3_r.jpg?source=1def8aca"></p><blockquote><p>我们将带你进行一次未来城市的街头巡览，在这里，高科技与自然和谐共处，展现出一种独特的赛博朋克风格。<br>这座城市洁净无瑕，到处可见的是先进的未来式有轨电车、绚丽的喷泉、巨型的全息投影以及四处巡逻的机器人。<br>想象一下，一个来自未来的人类导游正带领一群好奇的外星访客，向他们展示人类极致创造力的结晶——这座无与伦比、充满魅力的未来城市。</p></blockquote><p>多项技术破纪录</p><p>借助于对语言的深刻理解，Sora能够准确地理解用户指令中所表达的需求，把握这些元素在现实世界中的表现形式。</p><p>也因此，Sora创造出的角色，能够表达丰富的情感！</p><p>它所制作出的复杂场景，不仅可以包括多个角色，还有特定的动作类型，以及对对象和背景的精确细节描绘。</p><p>看，下图中人物的瞳孔、睫毛、皮肤纹理，都逼真到看不出一丝破绽，完全没有AI味儿。</p><p>从此，视频和现实究竟还有什么差别？！</p><p><img src="https://picx.zhimg.com/v2-145a2b1d151343c35292f190e49d0ba7_r.jpg?source=1def8aca"></p><blockquote><p>Prompt: Extreme close up of a 24 year old woman’s eye blinking, standing in Marrakech during magic hour, cinematic film shot in 70mm, depth of field, vivid colors, cinematic</p></blockquote><p>此外，Sora还能在同一视频中设计出多个镜头，同时保持角色和视觉风格的一致性。</p><p>要知道，以前的AI视频，都单镜头生成的。</p><p>而这次OpenAI能在多角度的镜头切换中，就能实现对象的一致性，这不得不说是个奇迹！</p><p>这种级别的多镜头一致性，是Gen 2和Pika都完全无法企及的……</p><p><img src="https://picx.zhimg.com/v2-5278291982aed5a49e9fbb546fbac091_r.jpg?source=1def8aca"></p><blockquote><p>Prompt: A movie trailer featuring the adventures of the 30 year old space man wearing a red wool knitted motorcycle helmet, blue sky, salt desert, cinematic style, shot on 35mm film, vivid colors.</p></blockquote><p>举个例子：「雪后的东京熙熙攘攘。镜头穿过繁忙的街道，跟随着几位享受着美丽雪景和在附近摊位购物的人们。美丽的樱花瓣伴随着雪花在风中飘舞。」</p><p>Sora根据这个提示所呈现的，便是东京在冬日里梦幻的一幕。</p><p>无人机的镜头跟随一对悠闲散步的情侣穿梭在街道上，左侧是车辆在河岸路上行驶的声音，右侧是顾客在一排小店之间穿梭的景象。</p><p><img src="https://pic1.zhimg.com/v2-2a7ed279e8fa1bad1f3824c051b2ea6d_r.jpg?source=1def8aca"></p><blockquote><p>Prompt: Beautiful, snowy Tokyo city is bustling. The camera moves through the bustling city street, following several people enjoying the beautiful snowy weather and shopping at nearby stalls. Gorgeous sakura petals are flying through the wind along with snowflakes.</p></blockquote><p>可以说，Sora的效果已经领先到了恐怖的级别，完全跳出了用冷兵器短兵相接的时代，其他AI视频被彻底干趴。</p><h3 id="世界模型成真了？？"><a href="#世界模型成真了？？" class="headerlink" title="世界模型成真了？？"></a><strong>世界模型成真了？？</strong></h3><p>最最最可怕的一点来了，Sora身上，竟已经有了世界模型的雏形？</p><p>通过观察大量数据，它竟然学会了许多关于世界的物理规律。</p><p>下面这个片段太令人印象深刻了：prompt中描绘了「一个短毛绒怪物跪在一支红蜡烛旁的动画场景」，同时描述了怪物的动作和视频的氛围。</p><p>随后，Sora就创造了一个类似皮克斯作品的生物，它似乎融合了Furby、Gremlin和《怪兽公司》中Sully的DNA。</p><p>让人震惊的是，Sora对于毛发纹理物理特性的理解，准确得令人惊掉下巴！</p><p>想当初，在《怪兽公司》上映时，皮克斯为了创造出怪物在移动时超级复杂的毛发纹理，可是费了好大一番功夫，技术团队直接连肝几个月。</p><p>而这一点，Sora轻而易举地就实现了，而且从没有人教过它！</p><p>「它学会了关于 3D 几何形状和一致性的知识，」项目的研究科学家Tim Brooks表示。</p><p>「这并非我们预先设定的——它完全是通过观察大量数据自然而然地学会的。」</p><p><img src="https://picx.zhimg.com/v2-cfa7b215e1a679394108dda517064df1_r.jpg?source=1def8aca"></p><blockquote><p>Prompt: Animated scene features a close-up of a short fluffy monster kneeling beside a melting red candle. The art style is 3D and realistic, with a focus on lighting and texture. The mood of the painting is one of wonder and curiosity, as the monster gazes at the flame with wide eyes and open mouth. Its pose and expression convey a sense of innocence and playfulness, as if it is exploring the world around it for the first time. The use of warm colors and dramatic lighting further enhances the cozy atmosphere of the image.</p></blockquote><p>得益于DALL·E 3所使用的扩散模型，以及GPT-4的Transformer引擎，Sora不仅能够生成满足特定要求的视频，而且能够展示出对电影拍摄语法的自发理解。</p><p>这种能力体现在它对讲故事的独特才能上。</p><p>例如，在一个以「色彩缤纷的鱼类和海洋生物充斥的，由纸艺精心构建的珊瑚礁世界」为主题的视频中，项目研究员Bill Peebles指出，Sora通过其摄影角度和拍摄时机，成功地推进了故事的发展。</p><p>「视频中实际上发生了多次镜头转换——这些镜头并非后期拼接而成，而是模型一气呵成地生成的，」他解释道。「我们并没有特别指令它这么做，它却能自动完成。」</p><p><img src="https://pic1.zhimg.com/v2-47a04c9e3c7dda9a7c65ca33813729d8_r.jpg?source=1def8aca"></p><blockquote><p>Prompt: A gorgeously rendered papercraft world of a coral reef, rife with colorful fish and sea creatures.</p></blockquote><p>不过，当前的模型并不完美。它在模拟复杂场景的物理效果上可能会遇到难题，有时也难以准确理解特定情境下的因果关系。比如，某人吃掉饼干的一部分后，饼干可能看起来仍然完整无损。</p><p><img src="https://picx.zhimg.com/v2-846900de76e6c771b91b361a5b355c45_r.jpg?source=1def8aca"></p><p><img src="https://pic1.zhimg.com/v2-7b47839b8cf92029b48983d2373ae18f_r.jpg?source=1def8aca"></p><p>此外，模型在处理空间细节，如区分左右时可能会出错，也可能在描述随时间变化的事件，如特定的摄影机动作轨迹时，表现不够精确。</p><p><img src="https://picx.zhimg.com/v2-3d3ec12aa158731ea9673e96764fee99_r.jpg?source=1def8aca"></p><p><img src="https://picx.zhimg.com/v2-05b8ff557102f90d70205223aa77adf8_r.jpg?source=1def8aca"></p><p>好在，它还并不完美。</p><p>否则，虚拟和现实的界限，还能区分得清吗？</p><p><img src="https://pica.zhimg.com/v2-d1732749cf3a73fa371bcb57173e0b22_r.jpg?source=1def8aca"></p><p>这不是现实？</p><p>但是无可否认的是，可怕的事实已经就在面前：一个已经能够理解和模拟现实世界的模型，也就意味着AGI已经不远了。</p><h2 id="「唯一真正的视频生成工作」"><a href="#「唯一真正的视频生成工作」" class="headerlink" title="「唯一真正的视频生成工作」"></a><strong>「唯一真正的视频生成工作」</strong></h2><p>业内大佬张启煊评价道，「Sora是我目前看到唯一跳脱出空镜头生成、真正的视频生成工作。」</p><p>在他看来，目前看来Sora跟Pika、Runway是有代差的，视频生成领域终于被OpenAI支配。或许某天3D视频领域，有朝一日也能体会到这种恐惧。</p><p>网友们都被震惊到失语：「下一个十年会是疯狂的十年。」</p><p><img src="https://picx.zhimg.com/50/v2-27448805d469a76e075e2aba2a6981e1_720w.jpg?source=1def8aca"></p><p>「都结束了，我的饭碗要丢了。」</p><p><img src="https://picx.zhimg.com/50/v2-c002779c7e9d87d2f241a88791ec93af_720w.jpg?source=1def8aca"></p><p>「整个素材行业都会随着这篇成果的发布而消亡……」</p><p><img src="https://picx.zhimg.com/50/v2-3509c7381a5a99a48ecb5e406257a7da_720w.jpg?source=1def8aca"></p><p>OpenAI就是没法停下干死初创公司的脚步，是吗？</p><p><img src="https://picx.zhimg.com/50/v2-539c83b3cb0535ae4903dc15fd122620_720w.jpg?source=1def8aca"></p><p>「好莱坞即将发生核爆」。</p><p><img src="https://picx.zhimg.com/50/v2-8a39f6120545ad637fe07d074f7d7ccc_720w.jpg?source=1def8aca"></p><p>AI电影制作人和他们目前的项目。</p><p><img src="https://picx.zhimg.com/v2-e58015cd764cfe2730533fb10e482cca_r.jpg?source=1def8aca"></p><p>技术介绍</p><p>Sora是一种扩散模型，它能够通过从一开始看似静态噪声的视频出发，经过多步骤的噪声去除过程，逐渐生成视频。</p><p>Sora不仅能够一次性生成完整的视频，还能延长已生成的视频。</p><p>通过让模型能够预见多帧内容，团队成功克服了确保视频中的主体即便暂时消失也能保持一致性的难题。</p><p>与GPT模型类似，Sora采用了Transformer架构，从而实现了卓越的性能扩展。</p><p>OpenAI把视频和图像分解为较小的数据单元——「patches」，每个「patches」相当于GPT中的一个「token」。</p><p>这种统一的数据表示方法能够在更广泛的视觉数据上训练扩散Transformer，覆盖了不同的持续时间、分辨率和纵横比。</p><p>Sora基于DALL·E和GPT模型的研究成果，采用了DALL·E 3的重标注技术，通过为视觉训练数据生成详细描述的标题，使模型更加准确地遵循用户的文本指令生成视频。</p><p>除了能根据文本指令生成视频外，这款模型还能将现有的静态图像转化成视频，精确细致地赋予图像中内容以生动的动画。模型还能扩展现有视频或补全缺失的帧。</p><p>Sora为理解和模拟现实世界的模型奠定了基础，对此OpenAI认为这是实现通用人工智能（AGI）的重要步骤。</p><p>作品欣赏</p><p>一列火车穿越东京郊区时，窗户上反射出的迷人景象。</p><p><img src="https://pic1.zhimg.com/v2-ae7a2948b578963cbc0e296add092cb9_r.jpg?source=1def8aca"></p><blockquote><p>Prompt: Reflections in the window of a train traveling through the Tokyo suburbs.</p></blockquote><p>在雪地草原上，几只巨大的羊毛猛犸象缓缓前行，它们长长的毛皮在微风中轻轻飘扬。远处是雪覆盖的树木和雄伟的雪山，午后的阳光穿透薄云，给这个场景增添了一抹温暖的光彩。低角度的拍摄令这些庞大的毛茸茸动物显得尤为壮观，景深效果引人入胜。</p><p><img src="https://pica.zhimg.com/v2-5d7005e3da8fb3e76652326b50f97e15_r.jpg?source=1def8aca"></p><blockquote><p>Prompt: Several giant wooly mammoths approach treading through a snowy meadow, their long wooly fur lightly blows in the wind as they walk, snow covered trees and dramatic snow capped mountains in the distance, mid afternoon light with wispy clouds and a sun high in the distance creates a warm glow, the low camera view is stunning capturing the large furry mammal with beautiful photography, depth of field.</p></blockquote><p>无人机从空中俯瞰大苏尔加雷角海滩附近的崎岖悬崖，海浪冲击着岩石，形成白色的浪尖，落日的金色光辉照亮了岩石海岸。远处有一个小岛上立着灯塔，悬崖边缘覆盖着绿色植被。从道路到海滩的陡峭下降和悬崖边缘凸出的景象，展现了海岸的原始美丽和太平洋海岸公路的崎岖风景。</p><p><img src="https://pic1.zhimg.com/v2-e3cb585cac6daf57fe2cf2d25533e40f_r.jpg?source=1def8aca"></p><blockquote><p>Prompt: Drone view of waves crashing against the rugged cliffs along Big Sur’s garay point beach. The crashing blue waters create white-tipped waves, while the golden light of the setting sun illuminates the rocky shore. A small island with a lighthouse sits in the distance, and green shrubbery covers the cliff’s edge. The steep drop from the road down to the beach is a dramatic feat, with the cliff’s edges jutting out over the sea. This is a view that captures the raw beauty of the coast and the rugged landscape of the Pacific Coast Highway.</p></blockquote><p>蓝色时刻下的圣托里尼岛航拍视图，展现了白色基克拉迪建筑和蓝色圆顶的绝美建筑。火山口的景色令人叹为观止，灯光营造出一种美丽而宁静的氛围。</p><p><img src="https://picx.zhimg.com/v2-7dfb12d2ab478f8f9d4e87a9a6e1bf60_r.jpg?source=1def8aca"></p><blockquote><p>Prompt: Aerial view of Santorini during the blue hour, showcasing the stunning architecture of white Cycladic buildings with blue domes. The caldera views are breathtaking, and the lighting creates a beautiful, serene atmosphere.</p></blockquote><p>一位20多岁的年轻人坐在天空中的一朵云上，沉浸在书本中。</p><p><img src="https://pic1.zhimg.com/v2-5fae17c2afa824fb16e3e8abfec3c9e9_r.jpg?source=1def8aca"></p><blockquote><p>Prompt: A young man at his 20s is sitting on a piece of cloud in the sky, reading a book.</p></blockquote><p>一群活泼的金毛寻回犬小狗在银白色的雪地上嬉戏，它们好奇的小脑袋时而从雪地中探出，被雪花点缀，萌态十足。</p><p><img src="https://picx.zhimg.com/v2-debcdcde80e32f34e037c1680a339a21_r.jpg?source=1def8aca"></p><blockquote><p>Prompt: A litter of golden retriever puppies playing in the snow. Their heads pop out of the snow, covered in.</p></blockquote><p>在意大利布拉诺一排排鲜艳的彩色建筑中，一只可爱的斑点狗正通过窗户好奇地望向外面。与此同时，街道上人来人往，有的步行，有的骑行。</p><p><img src="https://pic1.zhimg.com/v2-5c2236c9c55802bdc94195a40ddf77b2_r.jpg?source=1def8aca"></p><blockquote><p>Prompt: The camera directly faces colorful buildings in burano italy. An adorable dalmation looks through a window on a building on the ground floor. Many people are walking and cycling along the canal streets in front of the buildings.</p></blockquote><p>一幅充满工人、设备和重型机械的建筑工地的移轴摄影。</p><p><img src="https://picx.zhimg.com/v2-24e4cfd32e81df23154b0f3a2fb28a21_r.jpg?source=1def8aca"></p><blockquote><p>Prompt: Tiltshift of a construction site filled with workers, equipment, and heavy machinery.</p></blockquote><p>在一个培养皿中，生长着一片竹林，其中小熊猫们在欢快地奔跑。</p><p><img src="https://pic1.zhimg.com/v2-1c8d44f3883bd68fad8d49e68334be29_r.jpg?source=1def8aca"></p><blockquote><p>Prompt: A petri dish with a bamboo forest growing within it that has tiny red pandas running around.</p></blockquote><p>一只卡通袋鼠正在迪斯科舞池中跳舞。</p><p><img src="https://pic1.zhimg.com/v2-bf2eb14d7f5011f3133563a0a63c1e87_r.jpg?source=1def8aca"></p><blockquote><p>Prompt: A cartoon kangaroo disco dances.</p></blockquote><p>在一杯咖啡中，两艘海盗船展开了激烈的战斗，超写实的近景视频。</p><p><img src="https://pic1.zhimg.com/v2-ac33aeaa0398a40cfcb033cc04379160_r.jpg?source=1def8aca"></p><blockquote><p>Prompt: Photorealistic closeup video of two pirate ships battling each other as they sail inside a cup of coffee.</p></blockquote><p>大佬猜测：游戏引擎加持？</p><p>Pytorch联合创始人Soumith Chintala猜测道，「根据Sam Altman发布的所有用户请求视频，Sora似乎是由游戏引擎提供支持，并为游戏引擎生成作品和参数」。</p><p><img src="https://picx.zhimg.com/50/v2-10813da7aae81cdee325a40698a98739_720w.jpg?source=1def8aca"></p><p>英伟达高级科学家Jim Fan对全新Sora模型，发表了一些自己的观点：</p><p>Sora是一个数据驱动的物理引擎。它是对许多世界的模拟，无论是真实的，还是虚构的。该模拟器通过去噪和梯度学习方式，学习了复杂的渲染、「直观的」物理、长期推理和语义理解。</p><p>如果Sora使用虚幻引擎5接受过大量合成数据的训练，我不会感到惊讶的。必须如此！</p><p><img src="https://pica.zhimg.com/50/v2-2b743b9a992a14e529ac0c36b42981a8_720w.jpg?source=1def8aca"></p><p>同样，爱丁堡大学的博士生Yao Fu表示，「生成式模型学习生成数据的算法，而不是记住数据本身。就像语言模型编码生成语言的算法（在你的大脑中）一样，视频模型编码生成视频流的物理引擎。语言模型可以视为近似人脑，而视频模型近似物理世界」。</p><p><img src="https://pica.zhimg.com/50/v2-4d177a26bf0776a883de6a587f63c1ff_720w.jpg?source=1def8aca"></p><p>重塑视频行业</p><p>虽然，文本转视频技术要威胁到传统电影制作，可能还需要很长时间——</p><p>你无法通过简单地将120个Sora生成的一分钟视频拼接起来制作出连贯的电影，因为这些模型无法确保内容的连续性。</p><p><img src="https://picx.zhimg.com/50/v2-eff8facfbdfecf98ec5a626c4fb8a207_720w.jpg?source=1def8aca"></p><p>但是，这并不妨碍Sora和类似的程序彻底改变TikTok等社交平台。</p><p>「制作一部专业电影需要大量的昂贵设备。」Peebles 说，「这个模型将让普通人在社交媒体上制作出高质量的视频内容成为可能。」</p><p>如果想注册ChatGPT使用，可以参考以下链接：</p><p><a href="https://anyubenyu.com/chatgpt-update-guide.html">ChatGPT注册、升级教程</a></p><p>参考引用：<a href="https://www.zhihu.com/question/644478200">https://www.zhihu.com/question/644478200</a></p>]]></content>
    
    
    <categories>
      
      <category>ChatGPT</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【必看】Onlyfans如何使用搜索功能？Onlyfans如何搜索博主？如何在OnlyFans搜索HongkongDoll</title>
    <link href="/onlyfans-how-search.html"/>
    <url>/onlyfans-how-search.html</url>
    
    <content type="html"><![CDATA[<h2 id="0-目录"><a href="#0-目录" class="headerlink" title="0. 目录"></a><strong>0. 目录</strong></h2><ul><li><a href="#1-%E4%BB%80%E4%B9%88%E6%98%AFonlyfans"><strong>1. 什么是Onlyfans</strong></a></li><li><a href="#2-onlyfans%E6%90%9C%E7%B4%A2%E5%8A%9F%E8%83%BD%E6%A6%82%E8%A7%88"><strong>2. OnlyFans搜索功能概览</strong></a></li><li><a href="#3-%E5%A6%82%E4%BD%95%E5%9C%A8onlyfans%E4%B8%8A%E9%9D%A2%E6%90%9C%E7%B4%A2"><strong>3. 如何在Onlyfans上面搜索</strong></a><ul><li><a href="#31-%E4%BD%BF%E7%94%A8onlyfans%E5%AE%98%E6%96%B9%E6%90%9C%E7%B4%A2%E6%9C%8D%E5%8A%A1"><strong>3.1 使用Onlyfans官方搜索服务</strong></a></li><li><a href="#32-%E9%80%9A%E8%BF%87%E7%A4%BE%E4%BA%A4%E5%AA%92%E4%BD%93%E8%B7%B3%E8%BD%AC%E7%9A%84%E6%96%B9%E5%BC%8F"><strong>3.2 通过社交媒体跳转的方式</strong></a></li><li><a href="#33-%E4%BD%BF%E7%94%A8%E7%AC%AC%E4%B8%89%E6%96%B9%E6%90%9C%E7%B4%A2%E5%B7%A5%E5%85%B7"><strong>3.3 使用第三方搜索工具</strong></a></li></ul></li><li><a href="#4-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98"><strong>4. 常见问题</strong></a></li></ul><h2 id="1-什么是Onlyfans"><a href="#1-什么是Onlyfans" class="headerlink" title="1. 什么是Onlyfans"></a><strong>1. 什么是Onlyfans</strong></h2><p>OnlyFans是一种革命性的内容订阅服务平台，自2016年成立以来，它为内容创作者提供了一个独特的舞台，让他们能够在这个平台上分享自己的作品，包括图片、视频等。想要查看这些独家内容的用户，需要支付一定的订阅费。此外，OnlyFans还提供了一种个性化的互动方式，即用户可以通过打赏创作者，从而获得为自己量身定制的作品。</p><p>得益于其创新的付费模式，OnlyFans吸引了众多创作者在此平台发布他们的作品，使其在多个领域获得了广泛的欢迎，如音乐、健身、摄影等。然而，平台的<strong>独特设计</strong>也带来了一定的挑战，许多用户发现自己难以在OnlyFans上寻找到<strong>自己喜爱的博主</strong>，这成为了一个普遍存在的问题。</p><p>今天就来向大家介绍三种在Onlyfans搜索的方式，分别是<strong>官方搜索</strong>、<strong>社交媒体跳转</strong>和<strong>第三方搜索引擎</strong>的方式，希望能帮助到大家~</p><p>如果你想要在OnlyFans订阅博主的话，可以看这篇文章：<a href="https://anyubenyu.com/use_onlyfans.html">【保姆级教程】如何注册Onlyfans？Onlyfans虚拟卡订阅教程</a></p><h2 id="2-OnlyFans搜索功能概览"><a href="#2-OnlyFans搜索功能概览" class="headerlink" title="2. OnlyFans搜索功能概览"></a><strong>2. OnlyFans搜索功能概览</strong></h2><p>在OnlyFans上搜索特定博主不像在其他社交媒体平台上那样直观，主要是因为OnlyFans的搜索功能相对有限，并且平台在设计上更注重隐私和独家内容。</p><p>比如，我们现在想在onlyfans上面看hongkongdoll的视频，如果直接在搜索栏进行搜索，结果如下：</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402240950398.png" alt="image-20240224095046311"></p><p>发现什么内容都没有，是关键词的问题吗？换成hongkong试试呢</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402240950903.png" alt="image-20240224093708117"></p><p>依然还是找不到任何内容。</p><p>这到底是为什么呢</p><p>其实，并不是我们的关键词错了，而是onlyfans为了所谓的用户隐私<strong>才故意设置了搜素限制</strong>。</p><h2 id="3-如何在Onlyfans上面搜索"><a href="#3-如何在Onlyfans上面搜索" class="headerlink" title="3. 如何在Onlyfans上面搜索"></a><strong>3. 如何在Onlyfans上面搜索</strong></h2><p>这里主要介绍三种在Onlyfans上面搜索博主的方式，分别是官方服务、社媒跳转和第三方搜索引擎。</p><h3 id="3-1-使用Onlyfans官方搜索服务"><a href="#3-1-使用Onlyfans官方搜索服务" class="headerlink" title="3.1 使用Onlyfans官方搜索服务"></a><strong>3.1 使用Onlyfans官方搜索服务</strong></h3><p>我在官网上面找到了如下公告：</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402140304375.png" alt="image.png"></p><p>根据官网公告，如果你<strong>已经关注了某个博主</strong>，那么你可以直接用搜索栏搜素到该博主的信息。</p><p>但是如果你没有关注，那么你只能搜索到博主的帖子内容，而不能搜素到博主的主页。</p><h3 id="3-2-通过社交媒体跳转的方式"><a href="#3-2-通过社交媒体跳转的方式" class="headerlink" title="3.2 通过社交媒体跳转的方式"></a><strong>3.2 通过社交媒体跳转的方式</strong></h3><p>如果你在其他平台上面关注了某个博主，比如p**nhub或者twitter，那么这个博主可能会把ta的onlyfans链接放在某个帖子里面，你可以到相应平台去看一看。</p><p>此外，如果你已经知道某个博主的用户名，那么也可以通过拼接域名的方式来访问，即：onlyfans.com&#x2F;&lt;用户名&gt;，比如hongkongdoll的主页就是onlyfans.com&#x2F;hongkongdoll</p><h3 id="3-3-使用第三方搜索工具"><a href="#3-3-使用第三方搜索工具" class="headerlink" title="3.3 使用第三方搜索工具"></a><strong>3.3 使用第三方搜索工具</strong></h3><p>那如果你既没有关注某个博主，也不知道博主的其他社交媒体，该怎么办呢？</p><p>这里就要向大家介绍今天的重头戏，就是第三方onlyfans搜索引擎。</p><blockquote><p>onlyfans你不是清高不愿意做完整的搜索功能么，没关系，我第三方来帮你做！</p></blockquote><p>onlysearch就是这么一个平台，它爬取了onlyfans上面所有的用户信息，存放在数据库中。然后你就可以用onlysearch提供的搜索服务，来搜索某个博主并跳转到ta的首页啦~</p><p>还是拿hongkongdoll举例，我们先进入<a href="https://onlysearch.co/">onlysearch首页</a>，</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402140304370.png" alt="image.png"></p><p>输入hongkongdoll，然后点击search</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402140304742.png" alt="image.png"></p><p>然后就可以搜索到了，点击左下方的open onlyfans，就能跳转到hongkongdoll的onlyfans首页，接下来就能开始愉快的订阅啦~</p><p>原文链接：<a href="https://anyubenyu.com/onlyfans-how-search.html">【必看】Onlyfans如何使用搜索功能？Onlyfans如何搜索博主？如何在OnlyFans搜索HongkongDoll</a></p><h2 id="4-常见问题"><a href="#4-常见问题" class="headerlink" title="4. 常见问题"></a><strong>4. 常见问题</strong></h2><blockquote><p><strong>探索OnlyFans：指南与技巧</strong></p><hr><p><strong>问：OnlyFans是个啥？</strong></p><p>答：启动于2016年的OnlyFans，是个让创作者跟粉丝直接交流、分享内容（比如图文、视频）的平台，但得先付费订阅才能浏览。它开放给各种创作者，无论你是搞音乐的、健身狂热者还是摄影师，都能在这儿找到自己的一席之地。</p><hr><p><strong>问：为啥有时候在OnlyFans上找人像大海捞针？</strong></p><p>答：这个平台很看重保护用户隐私，所以他们故意限制了搜索功能，想找到某个具体的创作者可能会有点儿难度。</p><hr><p><strong>问：那怎么在OnlyFans上找到某个博主呢？</strong></p><p>答：有三招：利用OnlyFans的官方搜索、从社交媒体直接跳过来，或者用像OnlySearch这样的第三方搜索引擎。如果你已经关注了某位博主，直接搜名字就行；不然，就得借助社交媒体或第三方工具来找了。</p><hr><p><strong>问：官方搜索有啥限制？</strong></p><p>答：主要就是只能搜到你已经关注的人。如果没关注某人，通过搜索找到他们的可能性就很小，最多搜到一些零星的帖子内容。</p><hr><p><strong>问：通过社交媒体链接怎么找OnlyFans博主？</strong></p><p>答：如果你在Twitter或Instagram这类地方关注了他们，他们可能会分享自己的OnlyFans链接。知道用户名的话，直接访问onlyfans.com&#x2F;&lt;用户名&gt;也行。</p><hr><p><strong>问：OnlySearch是啥，怎么用？</strong></p><p>答：OnlySearch是个第三方搜索引擎，专门搜OnlyFans上的公开信息，把它们整理在一起。只要在上面输个关键词，就能找到相关的博主信息，还能直接点过去他们的OnlyFans主页。</p><hr><p><strong>问：用OnlySearch安全吗？</strong></p><p>答：用任何第三方工具时都得小心点，保护好自己的信息。虽然OnlySearch的初衷是帮忙找人，但还是要留意下可能的隐私问题。</p><hr><p><strong>问：怎样确保用OnlyFans搜索时的安全？</strong></p><p>答：不论是用官方的还是第三方的搜索工具，都别透露太多个人信息，小心点未知的链接，还得用VPN这样的网络安全措施，设置复杂点的密码，确保自己的隐私安全。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Onlyfans</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【保姆级教程】如何注册Onlyfans？Onlyfans虚拟卡订阅教程</title>
    <link href="/use_onlyfans.html"/>
    <url>/use_onlyfans.html</url>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li><a href="#1-%E5%BC%95%E8%A8%80">1. 引言</a></li><li><a href="#2-%E6%B3%A8%E5%86%8Conlyfans%E8%B4%A6%E6%88%B7">2. 注册OnlyFans账户</a></li><li><a href="#3-%E6%B5%8F%E8%A7%88onlyfans%E5%86%85%E5%AE%B9">3. 浏览OnlyFans内容</a></li><li><a href="#4-%E9%80%89%E6%8B%A9%E8%AE%A2%E9%98%85%E6%97%B6%E9%95%BF">4. 选择订阅时长</a></li><li><a href="#5-%E5%BC%80%E9%80%9A%E8%99%9A%E6%8B%9F%E5%8D%A1">5. 开通虚拟卡</a><ul><li><a href="#51-%E4%BB%80%E4%B9%88%E6%98%AF%E8%99%9A%E6%8B%9F%E4%BF%A1%E7%94%A8%E5%8D%A1">5.1. 什么是虚拟信用卡</a></li><li><a href="#52-%E5%A6%82%E4%BD%95%E5%BC%80%E9%80%9A%E8%99%9A%E6%8B%9F%E5%8D%A1">5.2. 如何开通虚拟卡</a></li></ul></li><li><a href="#6-%E4%BD%BF%E7%94%A8%E8%99%9A%E6%8B%9F%E5%8D%A1%E8%AE%A2%E9%98%85">6. 使用虚拟卡订阅</a></li><li><a href="#7-%E6%80%BB%E7%BB%93">7. 总结</a></li><li><a href="#8-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98">8. 常见问题</a></li></ul><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h2><ul><li><strong>什么是OnlyFans</strong>：OnlyFans就是2016年弄起来的订阅型的服务，允许内容创作者从用户那里获得资金，用户需要支付订阅费用才能查看他们的内容。这个平台不挑行当，唱歌的、健身的、拍照的，还有搞成人内容的都在上面混得风生水起的。</li><li><strong>目的</strong>：这份指南就是来教你们怎么在OnlyFans上一路顺风地订阅加支付的，细到每一步怎么走，保证大家都能轻轻松松搞定订阅和付款。</li></ul><h2 id="2-注册OnlyFans账户"><a href="#2-注册OnlyFans账户" class="headerlink" title="2. 注册OnlyFans账户"></a>2. 注册OnlyFans账户</h2><ul><li><strong>步骤一</strong>：访问<a href="https://onlyfans.com/">OnlyFans</a>官网。</li><li><strong>步骤二</strong>：创建账户，填写必要的个人信息。</li><li><strong>步骤三</strong>：邮箱验证及账户激活。</li></ul><h2 id="3-浏览OnlyFans内容"><a href="#3-浏览OnlyFans内容" class="headerlink" title="3. 浏览OnlyFans内容"></a>3. 浏览OnlyFans内容</h2><ul><li>在onlyfans上面找到你想要订阅的内容，比如 hongkongdoll</li></ul><h2 id="4-选择订阅时长"><a href="#4-选择订阅时长" class="headerlink" title="4. 选择订阅时长"></a>4. 选择订阅时长</h2><ul><li><p>选择需要的订阅时长，点击进入支付界面</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402140245754.png" alt="image.png"></p><p>选择完订阅时长后，需要你填写虚拟卡信息， 接下来我们看如何开通虚拟卡。</p></li></ul><h2 id="5-开通虚拟卡"><a href="#5-开通虚拟卡" class="headerlink" title="5. 开通虚拟卡"></a>5. 开通虚拟卡</h2><h3 id="5-1-什么是虚拟信用卡"><a href="#5-1-什么是虚拟信用卡" class="headerlink" title="5.1. 什么是虚拟信用卡"></a>5.1. 什么是虚拟信用卡</h3><p>简单的说来，就是如果你需要订阅国外的服务（如chatgpt或者onlyfans）的话，就必须要有国外的信用卡。但是国内不是没有办法开通国外信用卡吗，所以就需要使用虚拟信用卡，然后用这张虚拟卡去订阅服务。</p><p>这里我比较推荐虚拟卡平台WildCard。</p><h3 id="5-2-如何开通虚拟卡"><a href="#5-2-如何开通虚拟卡" class="headerlink" title="5.2. 如何开通虚拟卡"></a>5.2. 如何开通虚拟卡</h3><p>开通步骤如下：</p><p>首先点击链接进入 <a href="https://bewildcard.com/i/GPT009">WildCard 一分钟开卡，轻松订阅海外软件服务</a></p><p>进入网站首页，填写相关信息开卡，中途需要用到支付宝认证，但是只需要扫码即可，不需要上传身份证或者人脸识别。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403232021080.png" alt="img"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403122004666.png" alt="img"></p><p>支付宝认证完之后，选择卡片开通的时长（根据个人需要选择，一年、两年都可以的，看自己需求）。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402140245839.png" alt="image.png"></p><p>支付之后需要几分钟的时间等待开通成功。开通成功之后就可以拿到一张虚拟卡。</p><h2 id="6-使用虚拟卡订阅"><a href="#6-使用虚拟卡订阅" class="headerlink" title="6. 使用虚拟卡订阅"></a>6. 使用虚拟卡订阅</h2><p>接下来详细看如何用购买的虚拟卡订阅onlyfans。</p><p>回到onlyfans，在点击订阅时长之后，提示添加信用卡</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402140245858.png" alt="image.png"></p><p>然后点击添加信用卡，</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402140245804.png" alt="image.png"></p><p>上面需要的每一项信息，都可以直接在虚拟卡网页上看到，直接像下面这样复制过去即可：</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402140250030.png" alt="image-20240202225912838"></p><h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7. 总结"></a>7. 总结</h2><ul><li>总费用：wildcard开卡费 + onlyfans订阅费用</li><li>订阅开通成功之后就可以畅快欣赏onlyfans上面的精彩内容啦</li></ul><h2 id="8-常见问题"><a href="#8-常见问题" class="headerlink" title="8. 常见问题"></a>8. 常见问题</h2><blockquote><p><strong>Q: OnlyFans是什么？</strong></p><p>A: OnlyFans是一个内容订阅服务平台，允许创作者通过粉丝订阅获得收入。</p></blockquote><blockquote><p><strong>Q: 如何在OnlyFans上注册账户？</strong></p><p>A: 访问OnlyFans网站，填写必要信息并进行邮箱验证来注册账户。</p></blockquote><blockquote><p><strong>Q: OnlyFans支持哪些支付方式？</strong></p><p>A: OnlyFans通常接受信用卡和某些国家的借记卡支付。</p></blockquote><blockquote><p><strong>Q: 我可以在OnlyFans上订阅哪些类型的内容？</strong></p><p>A: OnlyFans提供多种类型的内容，包括音乐、健身、摄影和成人内容。</p></blockquote><blockquote><p><strong>Q: 如何使用虚拟信用卡在OnlyFans上支付？</strong></p><p>A: 需要在可靠的虚拟卡平台获取虚拟卡，然后在OnlyFans支付界面使用该卡进行支付。</p></blockquote><blockquote><p><strong>Q: OnlyFans上的内容创作者是否可以设置自己的订阅费用？</strong></p><p>A: 是的，内容创作者可以自行设定其内容的订阅价格。</p></blockquote><blockquote><p><strong>Q: OnlyFans是否保障用户隐私和安全？</strong></p><p>A: OnlyFans声称采取措施保护用户隐私和交易安全，但用户应自行评估风险。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Onlyfans</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Midjourney最新注册、订阅教程（新手小白）</title>
    <link href="/midjourney-register-guide.html"/>
    <url>/midjourney-register-guide.html</url>
    
    <content type="html"><![CDATA[<h1 id="Midjourney注册、订阅教程（新手小白）"><a href="#Midjourney注册、订阅教程（新手小白）" class="headerlink" title="Midjourney注册、订阅教程（新手小白）"></a>Midjourney注册、订阅教程（新手小白）</h1><h2 id="1-Midjourney注册"><a href="#1-Midjourney注册" class="headerlink" title="1.Midjourney注册"></a>1.Midjourney注册</h2><p>Midjourney是基于Discord社区上的一个应用，所以注册时会涉及到Discord账号，跟着下面的注册步骤开始注册吧，需要准备的是外国网络条件，一个邮箱，手机号，中国的也可以。</p><p>1：点击进入<a href="https://www.midjourney.com/home/?callbackUrl=/app/">Midjourney官网</a></p><p>2：进入后点击右下角Sign in（注册）</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701710.png" alt="midjourney注册"></p><p>3：进入discord页面，再点击登录按钮下面的注册</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701745.png"></p><p>准备一个自己的邮箱，不要qq邮箱，其他都可以gmail，outlook，hotmail等，在下面输入信息注册,用户名用英文，然后点继续，，这里是你的discord账号密码，要记住</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701348.png"></p><p>出现验证真人，验证一下就可以，注册这个的过程会经常出现真人验证，验证下就可以了</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701694.png" alt="midjourney注册"></p><p>授权Midjourney 访问discord，鼠标拖到下面点授权就可以</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701230.png" alt="midjourney注册"></p><p>此时出现如下图：让你验证账号才能进行下一步，这时去登录你刚刚注册时填的那个邮箱，邮箱会收到一封验证discord邮件，打开那个邮件，点击verify email（验证邮箱）</p><p>这一步只是证明这个邮箱是你本人的</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701258.png" alt="midjourney注册"></p><p><img src="https://chatgptzhanghao.com/wp-content/uploads/2023/06/midjourney%E6%B3%A8%E5%86%8C-7-1024x274.png" alt="midjourney注册"></p><p><img src="https://chatgptzhanghao.com/wp-content/uploads/2023/06/midjourney%E6%B3%A8%E5%86%8C-8.png" alt="midjourney注册"></p><p>点击邮件里verify email后，后跳转到discord页面，这个过程可能需要十多秒，跳转过去后又是真人验证，点击验证就好</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701941.png" alt="midjourney注册"></p><p>真人验证完就显示你的电子邮件已通过，点击继续使用discord</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701959.png" alt="midjourney注册"></p><p>有可能会一直出现这个机器人旋转加载的界面，出现BUG，跳转不成功。当跳转不成功时，我们直接进入 <a href="https://discord.com/">https://discord.com</a></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701613.png" alt="midjourney注册"></p><p>进入官网后可能会要你手机验证，选中国+86，输入你的手机接验证，手机验证过后就进入一下页面，创建一个自己的服务器，点亲自创建</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701041.png" alt="midjourney注册"></p><p>仅供我和我的朋友使用</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701588.png" alt="midjourney注册"></p><p>给你的服务器随便起个名字，然后点右下角创建</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701584.png" alt="midjourney注册"></p><p>跳过，带我去服务器</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701797.png" alt="midjourney注册"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701177.png" alt="midjourney注册"></p><p>已经进入到discord社区页面了</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701148.png" alt="midjourney注册"></p><p>点击左边那个像指南针的图标，探索新的服务器，如果出现卡顿，或者页面崩溃的情况，就稍微等一下，我也是页面崩了，等了一会就出来了</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701702.png" alt="midjourney注册"></p><p>点那个指南针图标后就出来好多社区，点击第一个Midjourney</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701662.png" alt="midjourney注册"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701326.png"></p><p>此时我们要把Midjourney加入我们刚刚创建的自己的服务器，点击右上角那个成员图标，在出来的列表里点击Midjourney Bot，然后点添加至服务器，选择我们刚刚创建的服务器，授权，步骤截图在下面：</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701767.png" alt="Midjourney 注册教程"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701751.png" alt="Midjourney 注册教程"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701553.png" alt="Midjourney 注册教程"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701059.png" alt="Midjourney 注册教程"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701774.png" alt="Midjourney 注册教程"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701137.png" alt="Midjourney 注册教程"></p><p>此时我们已经成功把Midjourney加入我们自己的服务器，最下面的对话框中输入&#x2F;调出画图指令：&#x2F;image，在prompt里面用英文输入图片描述，就会出来图片了，但是新账户会弹出没有免费的声明，需要付费才可使用。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701888.png" alt="Midjourney 注册教程"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701906.png" alt="Midjourney 注册教程"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701121.png" alt="Midjourney 注册教程"></p><p>以下是如何付费的操作：输入&#x2F;,调出&#x2F;subscrbe指令，点击 open subscription page（打开订阅页面）</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701792.png" alt="Midjourney 注册教程"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701728.png" alt="Midjourney 注册教程"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701374.png" alt="Midjourney 注册教程"></p><p>此时会跳到Midjourney页面，先真人验证</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701276.png" alt="Midjourney 注册教程"></p><p>点击右上角sign in 登录，然后授权</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701067.png" alt="Midjourney 注册教程"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701888.png" alt="Midjourney 注册教程"></p><p>找到订阅页面subscription， 选右边的按月付费（年费有8折，但是大多数人还是选择按月付费），选择30美金的套餐（10美金一个月只有200张图，30美金有无限张，一般人都选30美金，60美金的没必要）点击蓝色按钮订阅</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701681.png"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701271.png"></p><p>以下就出来付款页面，仅支持美国发行的信用卡，自己有美国卡的话绑定付费就可以了，没有的话按照以下内容操作</p><h2 id="2-准备工作"><a href="#2-准备工作" class="headerlink" title="2. 准备工作"></a>2. 准备工作</h2><ol><li>一张虚拟信用充值卡，推荐这个平台，操作简单，用户容易上手</li></ol><p>​<a href="https://bewildcard.com/i/GPT009">WildCard | 一分钟开卡，轻松订阅海外软件服务</a></p><p>（PS：大家可以使用上面我的邀请链接，或者邀请码：GPT009，这样你能有 88 折优惠）</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403232020514.png" alt="img"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403151655050.png" alt="image-20240312200235943"></p><p><strong>填写个人信息后，会跳到支付宝进行身份验证，通过之后。</strong><br>这家国内的公司应该是专门解决这个问题的，有效期2年的美国银行卡，开卡要一次性给两年年费，算下来100元RMB。</p><p>之后想用什么按需求充值，也可随时退订。</p><p>关键是！！随时可以提现，大家不用担心钱充进去就取不出来了，如果没消费成功，亲测可以秒提现到支付宝：</p><p>这个卡片，不仅可以用来订阅 ChatGPT，一些常见的国外付费订阅软件都可以使用，强烈推荐开一个！</p><h2 id="3-登录-Midjourney-进行订阅"><a href="#3-登录-Midjourney-进行订阅" class="headerlink" title="3. 登录 Midjourney 进行订阅"></a>3. 登录 Midjourney 进行订阅</h2><p>登录 Discord 成功后，就可以登录 Midjourney 进行订阅了。在远程浏览器的地址栏输入 <a href="https://www.midjourney.com/login/">https://www.midjourney.com/login/</a><br>在弹出的 Discord 页面点击授权，就可以登录 Midjourney 了。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701499.png" alt="image-20240213165323966"></p><p>点击左边栏的 「Manage Sub」 ，即可选择套餐进行订阅</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131701707.png" alt="image-20240213165254430"></p><p>点击 「Subscribe」，在弹出的绑定支付页面，依次输入卡号、有效月份&#x2F;年份、CVC（即您的 CVV ）、美国的账单地址及姓名便可成功绑定。</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402131703000.png" alt="image-20240213170352926"></p><hr><p>相关文章</p><p><a href="https://anyubenyu.com/chatgpt-update-guide.html">ChatGPT Plus 订阅教程</a></p><p><a href="https://help.bewildcard.com/zh-CN/articles/8714199-midjourney-%E4%BB%98%E8%B4%B9%E5%A4%B1%E8%B4%A5%E5%90%8E%E5%A6%82%E4%BD%95%E5%8F%96%E6%B6%88%E6%88%96%E7%BB%AD%E8%AE%A2">MidJourney 付费失败后如何取消或续订</a></p><p><a href="https://help.bewildcard.com/zh-CN/articles/8925271-wildcard-%E6%9C%89%E5%93%AA%E4%BA%9B%E5%B7%A5%E5%85%B7%E5%92%8C%E5%8A%9F%E8%83%BD">WildCard 有哪些工具和功能？</a></p>]]></content>
    
    
    <categories>
      
      <category>Midjourney</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Onlyfans 注册以及充值、虚拟信用卡订阅教程</title>
    <link href="/onlyfans-sub.html"/>
    <url>/onlyfans-sub.html</url>
    
    <content type="html"><![CDATA[<h1 id="Onlyfans注册、充值、订阅教程"><a href="#Onlyfans注册、充值、订阅教程" class="headerlink" title="Onlyfans注册、充值、订阅教程"></a>Onlyfans注册、充值、订阅教程</h1><h2 id="Onlyfans注册"><a href="#Onlyfans注册" class="headerlink" title="Onlyfans注册"></a>Onlyfans注册</h2><ol><li>登录官网：<a href="https://onlyfans.com/">onlyfans</a>，这里不想使用微软或者谷歌账户可以注册一个。填写昵称、邮箱和密码（密码要包含大小写字母，以及特殊字符）</li></ol><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402022235176.png" alt="image-20240202223553089"></p><ol start="2"><li>注册之后自动登录，先验证电子邮件</li></ol><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402022239015.png" alt="image-20240202223954949"></p><p>点击这里</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402022243605.png" alt="image-20240202224342559"></p><h2 id="Onlyfans充值"><a href="#Onlyfans充值" class="headerlink" title="Onlyfans充值"></a>Onlyfans充值</h2><p>你想订阅一些付费的明星，可以点击按以下步骤来</p><ol><li>注册一张虚拟信用卡：<a href="https://bewildcard.com/i/GPT009">WildCard | 一分钟开卡，轻松订阅海外软件服务</a></li></ol><p>（PS：大家可以使用上面我的邀请链接，或者邀请码：GPT009，这样你能有 88 折优惠）</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403232021938.png" alt="img"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403122002073.png" alt="image-20240312200235943"><br>填写个人信息后，会跳到支付宝进行身份验证，通过之后。</p><ol start="2"><li><p>添加信用卡</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402022250315.png" alt="image-20240202225058253"></p><p>需要的每一项信息，都可以直接在虚拟卡网页上看到，直接复制过去即可：</p></li></ol><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402022259923.png" alt="image-20240202225912838"></p><p>绑定支付信用卡后，就可以去订阅喜欢的博主啦。很方便，而且信用卡里的余额可以随时提取出来。</p>]]></content>
    
    
    <categories>
      
      <category>Onlyfans</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>国内升级ChatGPT-Plus教程，订阅GTP4.0（2024年3月更新）</title>
    <link href="/chatgpt-update-guide.html"/>
    <url>/chatgpt-update-guide.html</url>
    
    <content type="html"><![CDATA[<h1 id="ChatGPT注册以及升级教程"><a href="#ChatGPT注册以及升级教程" class="headerlink" title="ChatGPT注册以及升级教程"></a>ChatGPT注册以及升级教程</h1><h2 id="一-ChatGPT注册"><a href="#一-ChatGPT注册" class="headerlink" title="一.ChatGPT注册"></a>一.ChatGPT注册</h2><p>很多人听说ChatGPT如何如何智能，但是不知道如何注册，可以参考这篇文章：<a href="https://anyubenyu.com/chatgpt-register-guide.html">国内ChatGPT账号注册教程，免费（2024年1月更新）</a></p><p>如果想一键注册的可以采用以下方式</p><p>按下面步骤来：</p><ol><li><p>点击这个链接注册：<a href="https://bewildcard.com/i/GPT009">ChatGPT注册</a>，注册一个虚拟卡账号，用于充值订阅ChatGPT。填写信息，支付后即可开卡。<br>（PS：大家可以使用上面我的邀请链接，或者邀请码：GPT009，这样你能有 88 折优惠）<strong>填写个人信息后，会跳到支付宝进行身份验证，通过之后。</strong><br><strong>它的优势：充值之后去升级GPT-4之后，出现问题了是可以自动退费，然后可以提现的哈</strong></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403232009656.png" alt="image-20240323200914374"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403232011926.png" alt="image-20240323201128821"></p></li><li><p>然后选择一键注册OpenAI</p></li></ol><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402191256804.png" alt="image-20240219125621716"></p><ol start="3"><li><p><strong>这里先进行充值，然后再提现，就可以白嫖一个Open AI的账号啦</strong><br><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403232016225.png" alt="image-20240323201626154"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202401312041115.png" alt="image-20240131204101057"></p><p>然后进行提现，退款</p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403232017246.png" alt="image-20240323201747195"></p></li></ol><p>注册教程可以看网站上的帮助文档，非常详细，有不会的可以实时问客服：</p><p><a href="https://help.bewildcard.com/zh-CN/articles/8073056-chatgpt-plus-%E8%AE%A2%E9%98%85%E6%95%99%E7%A8%8B">openai注册教程</a></p><p>当你把GPT 账号注册好后，可以跟着下面方法升级 GPT 4.0 ：</p><h2 id="二-升级-ChatGPT-Plus-的步骤"><a href="#二-升级-ChatGPT-Plus-的步骤" class="headerlink" title="二.升级 ChatGPT Plus 的步骤"></a>二.升级 ChatGPT Plus 的步骤</h2><h3 id="2-1-准备工作"><a href="#2-1-准备工作" class="headerlink" title="2.1 准备工作"></a>2.1 准备工作</h3><ol><li>注册好的chatgpt账号</li><li>一张虚拟信用充值卡，推荐这个平台，操作简单，用户容易上手</li></ol><p>​<a href="https://bewildcard.com/i/GPT009">WildCard | 一分钟开卡，轻松订阅海外软件服务</a></p><p>（PS：大家可以使用上面我的邀请链接，或者邀请码：GPT009，这样你能有 88 折优惠）</p><p>这家国内的公司应该是专门解决这个问题的，有效期2年的美国银行卡，开卡要一次性给两年年费，算下来100元RMB。</p><p>之后想用什么按需求充值，也可随时退订。</p><p>关键是！！随时可以提现，大家不用担心钱充进去就取不出来了，如果没消费成功，亲测可以秒提现到支付宝：</p><p>这个卡片，不仅可以用来订阅 ChatGPT，一些常见的国外付费订阅软件都可以使用，强烈推荐开一个！</p><h3 id="2-2-升级-Chatgpt"><a href="#2-2-升级-Chatgpt" class="headerlink" title="2.2 升级 Chatgpt"></a>2.2 升级 Chatgpt</h3><ol><li>在浏览器地址栏输入 <a href="https://chat.openai.com/">chat.openai.com&#x2F;</a> 网址访问openai，登录自己的openai帐户后，点击左下角的 Upgrade to Plus，在弹窗中选择 Upgrade plan</li></ol><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202401312104031.png" alt="image-20240131210453957"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202401312106938.png" alt="image-20240131210649875"></p><ol start="2"><li>一键升级ChatGPT Plus，无需理会他的邮箱警告，亲测没问题</li></ol><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202402191256960.png" alt="image-20240219125656910"><br><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202403232019408.png" alt="image-20240323201919343"></p><ol start="3"><li><p>确认自己的邮箱满足要求，这里尽量不要使用微软的邮箱，避免升级失败，选择Plus</p></li><li><p>把第一步的chatgpt的跳转付款界面后，如图选中网址，用「Ctrl+A」全选网址后复制</p></li></ol><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202401312110447.png" alt="image-20240131211033394"></p><p>开始去 GPT4 冲浪吧！</p>]]></content>
    
    
    <categories>
      
      <category>ChatGPT</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>国内ChatGPT账号注册教程，免费（2024年1月更新）</title>
    <link href="/chatgpt-register-guide.html"/>
    <url>/chatgpt-register-guide.html</url>
    
    <content type="html"><![CDATA[<hr><p>本教程指导您注册 ChatGPT，不再需要海外手机号接码，只需科学上网。</p><p>（如果还不会可以试试这个，<a href="https://www.52xcjs.xyz/auth/register?code=LkGTzAo2nzbxQRk4">科学上网</a>）</p><p>注册步骤：</p><p>ChatGPT不允许国内邮箱注册，建议申请一个免费的海外邮箱来注册，这里推荐 Proton，其他海外邮箱，如 Gmail 也可以，但是注册要复杂一些。</p><h2 id="注册-Proton-邮箱"><a href="#注册-Proton-邮箱" class="headerlink" title="注册 Proton 邮箱"></a>注册 Proton 邮箱</h2><h3 id="1-1-访问-Proton"><a href="#1-1-访问-Proton" class="headerlink" title="1.1 访问 Proton:"></a><strong>1.1 访问 Proton</strong>:</h3><ul><li>打开 <a href="https://proton.me/">Proton 官网</a></li><li>点击右上角的「Create a free account」。</li></ul><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202401311109231.png" alt="image-20240131094725842"></p><h3 id="1-2-选择免费套餐"><a href="#1-2-选择免费套餐" class="headerlink" title="1.2 选择免费套餐:"></a><strong>1.2 选择免费套餐</strong>:</h3><ul><li>在 Proton 套餐页面，选择免费的1GB存储空间就足够。</li></ul><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202401311109170.png" alt="image-20240131094913636"></p><h3 id="1-3-设置邮箱"><a href="#1-3-设置邮箱" class="headerlink" title="1.3 设置邮箱:"></a><strong>1.3 设置邮箱</strong>:</h3><ul><li>推荐选择 <code>@proton.me</code> 后缀。</li><li>设置您的用户名和密码。</li></ul><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202401311109781.png" alt="image-20240131095127506"></p><h3 id="1-4-完成验证"><a href="#1-4-完成验证" class="headerlink" title="1.4 完成验证:"></a><strong>1.4 完成验证</strong>:</h3><ul><li>完成真人检验，跳过手机验证。</li><li>拖动验证码，设定显示名称。</li><li>注册完成，直接登录<a href="https://proton.me/">proton</a>，选择一个喜欢的主题。用于一会接收openai验证码。</li></ul><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202401311109869.png" alt="image-20240131095348814"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202401311109898.png" alt="image-20240131095434674"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202401311109934.png" alt="image-20240131095610200"></p><h2 id="注册-OpenAI-账号"><a href="#注册-OpenAI-账号" class="headerlink" title="注册 OpenAI 账号"></a>注册 OpenAI 账号</h2><h3 id="2-1-申请-OpenAI"><a href="#2-1-申请-OpenAI" class="headerlink" title="2.1 申请 OpenAI:"></a><strong>2.1 申请 OpenAI</strong>:</h3><ul><li>访问 <a href="https://chat.openai.com/">OpenAI 注册页面</a></li><li>输入您的 Proton 邮箱。</li><li><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202401311109948.png" alt="image-20240131100310700"></li></ul><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202401311109096.png" alt="image-20240131100026462"></p><h3 id="2-2-邮箱验证"><a href="#2-2-邮箱验证" class="headerlink" title="2.2 邮箱验证:"></a><strong>2.2 邮箱验证</strong>:</h3><ul><li>前往 Proton.me 收件箱，点击「Verify email address」进行邮箱验证。</li></ul><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202401311109161.png" alt="image-20240131100416257"></p><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202401311109588.png" alt="image-20240131100449520"></p><h3 id="2-3-提供基本信息"><a href="#2-3-提供基本信息" class="headerlink" title="2.3 提供基本信息:"></a><strong>2.3 提供基本信息</strong>:</h3><ul><li>填写名字、姓氏和生日。</li></ul><h3 id="2-4-选择账户类型"><a href="#2-4-选择账户类型" class="headerlink" title="2.4 选择账户类型:"></a><strong>2.4 选择账户类型</strong>:</h3><ul><li>个人用户一般选择 ChatGPT 账户。</li><li>OpenAI 用户体系分为 ChatGPT 用户和 API 开发者，两者账户独立但用户名密码一致。</li></ul><p><img src="https://anyubenyu.oss-cn-shanghai.aliyuncs.com/img202401311109110.png" alt="image-20240131100622194"></p><h2 id="升级至-ChatGPT-Plus"><a href="#升级至-ChatGPT-Plus" class="headerlink" title="升级至 ChatGPT Plus"></a><strong>升级至 ChatGPT Plus</strong></h2><ul><li>购买 GPT Plus 会员获取 GPT-4 使用权限，费用为 20 美元&#x2F;月。</li><li>登录后，在 Chat 界面选择 GPT4 进行聊天。</li><li>购买教程在这：<a href="https://anyubenyu.com/chatgpt-update-guide.html">国内升级ChatGPT-Plus教程，订阅GTP4-0（2024年1月更新）</a></li></ul><p>登录入口：</p><ul><li>ChatGPT 用户：<a href="https://chat.openai.com/">https://chat.openai.com</a></li><li>API 开发者用户：<a href="https://platform.openai.com/">https://platform.openai.com</a></li></ul><p>此教程适用于希望快速注册并使用 ChatGPT 服务的用户，特别是在需要科学上网的地区。</p>]]></content>
    
    
    <categories>
      
      <category>ChatGPT</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
